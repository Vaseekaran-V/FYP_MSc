{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('../../data/initial_modelling/train_X_data_last_month.parquet').drop(columns=['S_2'])\n",
    "val_data = pd.read_parquet('../../data/initial_modelling/val_X_data_last_month.parquet').drop(columns=['S_2'])\n",
    "test_data = pd.read_parquet('../../data/initial_modelling/test_X_data_last_month.parquet').drop(columns=['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['target'].values\n",
    "y_val = val_data['target'].values\n",
    "y_test = test_data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_63</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_126</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "      <th>target</th>\n",
       "      <th>end_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6bce6027f34a537dd3791ede37dcd3bf7017d571e3b8a...</td>\n",
       "      <td>0.295018</td>\n",
       "      <td>0.094310</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.170079</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.127707</td>\n",
       "      <td>0.341604</td>\n",
       "      <td>0.125312</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.235043</td>\n",
       "      <td>0.078684</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.601257</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.345972</td>\n",
       "      <td>0.105318</td>\n",
       "      <td>0.251269</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.021786</td>\n",
       "      <td>0.102641</td>\n",
       "      <td>0.121351</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.273959</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>1.001456</td>\n",
       "      <td>0.191578</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.107051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22b6b23f06a467df6633cbcf3e3fb7e8a99c692e19d500...</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.058616</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.322846</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.343203</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.263159</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.473390</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.076971</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.057779</td>\n",
       "      <td>0.366408</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.689683</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.200859</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>1.006366</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.041467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baac3615b0e82e210320261b87b2e8e552805f5b66f0d2...</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.104074</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.330256</td>\n",
       "      <td>0.104061</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.017091</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.033083</td>\n",
       "      <td>0.601631</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>1.000364</td>\n",
       "      <td>0.169808</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>1.003902</td>\n",
       "      <td>0.287095</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.102527</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.316072</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca8cba88feeed4b3759eba6f32c12192025691826cdeff...</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.161946</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.241943</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.055979</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>1.000362</td>\n",
       "      <td>0.281841</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>1.000472</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.502531</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>1.008704</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.007908</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>834dfa4bb957dabcbc2d9e90f8998b9cf40bcc35f38536...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.046676</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.698026</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.302109</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.004870</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.282537</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>1.007565</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.505820</td>\n",
       "      <td>0.020652</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>1.001936</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID      D_39       B_1  \\\n",
       "0  a6bce6027f34a537dd3791ede37dcd3bf7017d571e3b8a...  0.295018  0.094310   \n",
       "1  22b6b23f06a467df6633cbcf3e3fb7e8a99c692e19d500...  0.007106  0.013758   \n",
       "2  baac3615b0e82e210320261b87b2e8e552805f5b66f0d2...  0.005607  0.008563   \n",
       "3  ca8cba88feeed4b3759eba6f32c12192025691826cdeff...  0.005659  0.000993   \n",
       "4  834dfa4bb957dabcbc2d9e90f8998b9cf40bcc35f38536...  0.000834  0.005034   \n",
       "\n",
       "        R_1       B_4       B_5       R_2      D_47       B_7      D_51  \\\n",
       "0  0.005200  0.170079  0.017262  0.003640  0.422436  0.127707  0.341604   \n",
       "1  0.000326  0.058616  0.018488  0.008559  0.322846  0.028203  0.343203   \n",
       "2  0.004398  0.000113  0.015878  0.002745  0.104074  0.013242  0.006555   \n",
       "3  0.000691  0.008777  0.005575  0.003091  0.161946  0.001729  0.002436   \n",
       "4  0.005587  0.046676  0.000355  0.008184  0.698026  0.031777  0.003444   \n",
       "\n",
       "        B_9       R_3      B_10       S_5      B_11       S_6       R_4  \\\n",
       "0  0.125312  0.004692  0.071775  0.235043  0.078684  0.004515  0.006753   \n",
       "1  0.012959  0.004589  0.263159  0.011265  0.009033  0.001358  0.002491   \n",
       "2  0.330256  0.104061  0.295833  0.017091  0.008180  0.001898  0.003361   \n",
       "3  0.003744  0.104539  0.241943  0.004174  0.002968  0.005034  0.006416   \n",
       "4  0.006110  0.002101  0.302109  0.009895  0.002688  1.004870  0.004282   \n",
       "\n",
       "       B_12       S_8       R_5      D_58      B_14      D_60      S_11 D_63  \\\n",
       "0  0.058883  0.601257  0.003425  0.345972  0.105318  0.251269  0.247217   CO   \n",
       "1  0.041200  0.473390  0.009546  0.076971  0.007563  0.057779  0.366408   CO   \n",
       "2  0.033083  0.601631  0.000359  0.004538  0.004191  1.000364  0.169808   CO   \n",
       "3  0.055979  0.000049  0.005212  0.000319  0.006942  1.000362  0.281841   CO   \n",
       "4  0.013202  0.000988  0.006162  0.000046  0.008121  0.001122  0.282537   CO   \n",
       "\n",
       "       D_65      B_18      S_12       R_6      S_13      B_21      D_71  \\\n",
       "0  0.004360  0.154858  0.186974  0.000019  0.005839  0.009161  0.021786   \n",
       "1  0.000119  0.689683  0.186860  0.002666  0.004748  0.007384  0.010354   \n",
       "2  0.008948  1.003902  0.287095  0.006800  0.005356  0.005840  0.007722   \n",
       "3  0.005681  1.000472  0.184539  0.003959  0.009599  0.008062  0.017003   \n",
       "4  0.007983  1.007565  0.192542  0.008761  0.007706  0.006156  0.013267   \n",
       "\n",
       "       S_15      B_23       P_4      D_75      B_24       R_7       R_8  \\\n",
       "0  0.102641  0.121351  0.007689  0.273959  0.005502  0.005441  0.007421   \n",
       "1  0.200859  0.022039  0.007445  0.068089  0.003663  0.008071  0.006521   \n",
       "2  0.102527  0.007286  0.999273  0.004058  0.009057  0.006252  0.008540   \n",
       "3  0.502531  0.001163  0.005453  0.004132  0.006190  0.005042  0.004440   \n",
       "4  0.505820  0.020652  0.006029  0.002928  0.005833  0.003131  0.000861   \n",
       "\n",
       "       S_16      R_10      R_11      S_17      R_12      B_28      R_13  \\\n",
       "0  0.009395  0.005316  0.005898  0.000883  1.001456  0.191578  0.008755   \n",
       "1  0.001118  0.000364  0.001478  0.000421  1.006366  0.033385  0.008700   \n",
       "2  0.005612  0.007738  0.004642  0.005338  1.008499  0.002226  0.002190   \n",
       "3  0.002743  0.003000  0.006849  0.008812  1.008704  0.003923  0.009735   \n",
       "4  0.001115  0.002127  0.004550  0.008325  1.001936  0.015701  0.009775   \n",
       "\n",
       "       R_14      R_15      R_16      S_18      D_86      R_17      R_18  B_31  \\\n",
       "0  0.009521  0.005977  0.003511  0.009176  0.007875  0.000052  0.006334     1   \n",
       "1  0.004947  0.004894  0.009017  0.002797  0.007823  0.000741  0.000220     1   \n",
       "2  0.006216  0.002994  0.006577  0.003979  0.001129  0.009506  0.006459     1   \n",
       "3  0.004162  0.003434  0.009959  0.004921  0.003618  0.002154  0.001943     1   \n",
       "4  0.000839  0.000164  0.002851  0.005621  0.006739  0.004563  0.000310     1   \n",
       "\n",
       "       S_19      R_19      B_32      S_20      R_20      R_21      R_22  \\\n",
       "0  0.008895  0.001252  0.002409  0.008441  0.001943  0.005561  0.002614   \n",
       "1  0.007795  0.000372  0.008684  0.004150  0.002847  0.001371  0.003795   \n",
       "2  0.008492  0.004421  0.007168  0.007949  0.004306  0.001701  0.005752   \n",
       "3  0.001330  0.008947  0.002850  0.002231  0.005219  0.008728  0.009430   \n",
       "4  0.006139  0.009859  0.006603  0.004136  0.005951  0.007638  0.003829   \n",
       "\n",
       "       R_23      D_92      D_93      D_94      R_24      R_25      D_96  \\\n",
       "0  0.008909  0.009994  0.000964  0.003467  0.005961  0.007027  0.009298   \n",
       "1  0.009797  0.006759  0.004067  0.009560  0.001706  0.000086  0.001236   \n",
       "2  0.003761  0.003694  0.000407  0.003953  0.004679  0.002599  0.002287   \n",
       "3  0.003600  0.004968  0.007001  0.005342  0.000502  0.008984  0.007908   \n",
       "4  0.005229  0.005499  0.003417  0.009155  0.007836  0.008184  0.008785   \n",
       "\n",
       "       S_26     D_102      B_36      B_37      B_40  D_126     D_127  \\\n",
       "0  0.013673  0.007749  0.008019  0.093438  0.107051    1.0  0.005854   \n",
       "1  0.000889  0.006854  0.001334  0.012753  0.041467    1.0  0.006169   \n",
       "2  0.005127  0.316072  0.009153  0.012228  0.005069    0.0  0.001408   \n",
       "3  0.004083  0.004144  0.009074  0.007877  0.006503    0.0  0.006878   \n",
       "4  0.009288  0.505266  0.008412  0.000782  0.035965    1.0  0.008331   \n",
       "\n",
       "       B_41     D_133      R_28     D_140     D_144  target end_of_month  \n",
       "0  0.009274  0.006256  0.007657  0.003406  0.004150       0   2018-03-31  \n",
       "1  0.003988  0.006433  0.006456  0.006752  0.000011       0   2018-03-31  \n",
       "2  0.007990  0.004747  0.003762  0.008673  0.004924       0   2018-03-31  \n",
       "3  0.004739  0.009892  0.007765  0.003798  0.008975       0   2018-03-31  \n",
       "4  0.000707  0.007553  0.004204  0.009497  0.002808       0   2018-03-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 82), (32124, 82), (137674, 82))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['D_126', 'D_63']\n",
    "train_data[cat_cols] = train_data[cat_cols].astype('category')\n",
    "test_data[cat_cols] = test_data[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 289115 entries, 0 to 289114\n",
      "Data columns (total 82 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   customer_ID   289115 non-null  string        \n",
      " 1   D_39          289115 non-null  float32       \n",
      " 2   B_1           289115 non-null  float32       \n",
      " 3   R_1           289115 non-null  float32       \n",
      " 4   B_4           289115 non-null  float32       \n",
      " 5   B_5           289115 non-null  float32       \n",
      " 6   R_2           289115 non-null  float32       \n",
      " 7   D_47          289115 non-null  float32       \n",
      " 8   B_7           289115 non-null  float32       \n",
      " 9   D_51          289115 non-null  float32       \n",
      " 10  B_9           289115 non-null  float32       \n",
      " 11  R_3           289115 non-null  float32       \n",
      " 12  B_10          289115 non-null  float32       \n",
      " 13  S_5           289115 non-null  float32       \n",
      " 14  B_11          289115 non-null  float32       \n",
      " 15  S_6           289115 non-null  float32       \n",
      " 16  R_4           289115 non-null  float32       \n",
      " 17  B_12          289115 non-null  float32       \n",
      " 18  S_8           289115 non-null  float32       \n",
      " 19  R_5           289115 non-null  float32       \n",
      " 20  D_58          289115 non-null  float32       \n",
      " 21  B_14          289115 non-null  float32       \n",
      " 22  D_60          289115 non-null  float32       \n",
      " 23  S_11          289115 non-null  float32       \n",
      " 24  D_63          289115 non-null  category      \n",
      " 25  D_65          289115 non-null  float32       \n",
      " 26  B_18          289115 non-null  float32       \n",
      " 27  S_12          289115 non-null  float32       \n",
      " 28  R_6           289115 non-null  float32       \n",
      " 29  S_13          289115 non-null  float32       \n",
      " 30  B_21          289115 non-null  float32       \n",
      " 31  D_71          289115 non-null  float32       \n",
      " 32  S_15          289115 non-null  float32       \n",
      " 33  B_23          289115 non-null  float32       \n",
      " 34  P_4           289115 non-null  float32       \n",
      " 35  D_75          289115 non-null  float32       \n",
      " 36  B_24          289115 non-null  float32       \n",
      " 37  R_7           289115 non-null  float32       \n",
      " 38  R_8           289115 non-null  float32       \n",
      " 39  S_16          289115 non-null  float32       \n",
      " 40  R_10          289115 non-null  float32       \n",
      " 41  R_11          289115 non-null  float32       \n",
      " 42  S_17          289115 non-null  float32       \n",
      " 43  R_12          289115 non-null  float32       \n",
      " 44  B_28          289115 non-null  float32       \n",
      " 45  R_13          289115 non-null  float32       \n",
      " 46  R_14          289115 non-null  float32       \n",
      " 47  R_15          289115 non-null  float32       \n",
      " 48  R_16          289115 non-null  float32       \n",
      " 49  S_18          289115 non-null  float32       \n",
      " 50  D_86          289115 non-null  float32       \n",
      " 51  R_17          289115 non-null  float32       \n",
      " 52  R_18          289115 non-null  float32       \n",
      " 53  B_31          289115 non-null  int64         \n",
      " 54  S_19          289115 non-null  float32       \n",
      " 55  R_19          289115 non-null  float32       \n",
      " 56  B_32          289115 non-null  float32       \n",
      " 57  S_20          289115 non-null  float32       \n",
      " 58  R_20          289115 non-null  float32       \n",
      " 59  R_21          289115 non-null  float32       \n",
      " 60  R_22          289115 non-null  float32       \n",
      " 61  R_23          289115 non-null  float32       \n",
      " 62  D_92          289115 non-null  float32       \n",
      " 63  D_93          289115 non-null  float32       \n",
      " 64  D_94          289115 non-null  float32       \n",
      " 65  R_24          289115 non-null  float32       \n",
      " 66  R_25          289115 non-null  float32       \n",
      " 67  D_96          289115 non-null  float32       \n",
      " 68  S_26          289115 non-null  float32       \n",
      " 69  D_102         289115 non-null  float32       \n",
      " 70  B_36          289115 non-null  float32       \n",
      " 71  B_37          289115 non-null  float32       \n",
      " 72  B_40          289115 non-null  float32       \n",
      " 73  D_126         289115 non-null  category      \n",
      " 74  D_127         289115 non-null  float32       \n",
      " 75  B_41          289115 non-null  float32       \n",
      " 76  D_133         289115 non-null  float32       \n",
      " 77  R_28          289115 non-null  float32       \n",
      " 78  D_140         289115 non-null  float32       \n",
      " 79  D_144         289115 non-null  float32       \n",
      " 80  target        289115 non-null  int64         \n",
      " 81  end_of_month  289115 non-null  datetime64[ns]\n",
      "dtypes: category(2), datetime64[ns](1), float32(76), int64(2), string(1)\n",
      "memory usage: 93.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def one_hot_encode_categories(df, categorical_columns=None, drop_original=True, handle_unknown='error'):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing categorical columns\n",
    "    categorical_columns : list or None\n",
    "        List of categorical column names to encode. If None, automatically detects categorical columns.\n",
    "    drop_original : bool\n",
    "        Whether to drop the original categorical columns\n",
    "    handle_unknown : str\n",
    "        Strategy for handling unknown categories in new data: 'error', 'ignore' or 'infrequent_if_exist'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with one-hot encoded columns\n",
    "    OneHotEncoder\n",
    "        Fitted encoder for future transformations\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Automatically detect categorical columns if not specified\n",
    "    if categorical_columns is None:\n",
    "        categorical_columns = result_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    if not categorical_columns:\n",
    "        print(\"No categorical columns found to encode.\")\n",
    "        return result_df, None\n",
    "        \n",
    "    # Initialize the encoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown=handle_unknown, drop='if_binary')\n",
    "    \n",
    "    # Fit and transform the categorical columns\n",
    "    encoded_array = encoder.fit_transform(result_df[categorical_columns])\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    \n",
    "    # Create a DataFrame with the encoded features\n",
    "    encoded_df = pd.DataFrame(encoded_array, columns=feature_names, index=result_df.index)\n",
    "    \n",
    "    # Combine with the original DataFrame\n",
    "    if drop_original:\n",
    "        # Drop the original categorical columns\n",
    "        result_df = result_df.drop(columns=categorical_columns)\n",
    "    \n",
    "    # Concatenate the encoded columns with the original DataFrame\n",
    "    result_df = pd.concat([result_df, encoded_df], axis=1)\n",
    "    \n",
    "    print(f\"One-hot encoded {len(categorical_columns)} categorical columns into {len(feature_names)} binary features.\")\n",
    "    \n",
    "    return result_df, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded 2 categorical columns into 7 binary features.\n"
     ]
    }
   ],
   "source": [
    "# Apply to your training data\n",
    "train_data_oh, encoder = one_hot_encode_categories(train_data, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "      <th>target</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_126_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6bce6027f34a537dd3791ede37dcd3bf7017d571e3b8a...</td>\n",
       "      <td>0.295018</td>\n",
       "      <td>0.094310</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.170079</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.127707</td>\n",
       "      <td>0.341604</td>\n",
       "      <td>0.125312</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.071775</td>\n",
       "      <td>0.235043</td>\n",
       "      <td>0.078684</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.058883</td>\n",
       "      <td>0.601257</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.345972</td>\n",
       "      <td>0.105318</td>\n",
       "      <td>0.251269</td>\n",
       "      <td>0.247217</td>\n",
       "      <td>0.004360</td>\n",
       "      <td>0.154858</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.021786</td>\n",
       "      <td>0.102641</td>\n",
       "      <td>0.121351</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.273959</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>1.001456</td>\n",
       "      <td>0.191578</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.007027</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.007749</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.107051</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22b6b23f06a467df6633cbcf3e3fb7e8a99c692e19d500...</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.058616</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>0.322846</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.343203</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.263159</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.009033</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.473390</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.076971</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.057779</td>\n",
       "      <td>0.366408</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.689683</td>\n",
       "      <td>0.186860</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.200859</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.068089</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>1.006366</td>\n",
       "      <td>0.033385</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>0.007823</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.041467</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baac3615b0e82e210320261b87b2e8e552805f5b66f0d2...</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.104074</td>\n",
       "      <td>0.013242</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.330256</td>\n",
       "      <td>0.104061</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.017091</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.033083</td>\n",
       "      <td>0.601631</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>1.000364</td>\n",
       "      <td>0.169808</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>1.003902</td>\n",
       "      <td>0.287095</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.102527</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.007168</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.316072</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca8cba88feeed4b3759eba6f32c12192025691826cdeff...</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.161946</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.104539</td>\n",
       "      <td>0.241943</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.055979</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>1.000362</td>\n",
       "      <td>0.281841</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>1.000472</td>\n",
       "      <td>0.184539</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.502531</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>1.008704</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.008947</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.007908</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>834dfa4bb957dabcbc2d9e90f8998b9cf40bcc35f38536...</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.046676</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.698026</td>\n",
       "      <td>0.031777</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.302109</td>\n",
       "      <td>0.009895</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>1.004870</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.282537</td>\n",
       "      <td>0.007983</td>\n",
       "      <td>1.007565</td>\n",
       "      <td>0.192542</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.505820</td>\n",
       "      <td>0.020652</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>1.001936</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID      D_39       B_1  \\\n",
       "0  a6bce6027f34a537dd3791ede37dcd3bf7017d571e3b8a...  0.295018  0.094310   \n",
       "1  22b6b23f06a467df6633cbcf3e3fb7e8a99c692e19d500...  0.007106  0.013758   \n",
       "2  baac3615b0e82e210320261b87b2e8e552805f5b66f0d2...  0.005607  0.008563   \n",
       "3  ca8cba88feeed4b3759eba6f32c12192025691826cdeff...  0.005659  0.000993   \n",
       "4  834dfa4bb957dabcbc2d9e90f8998b9cf40bcc35f38536...  0.000834  0.005034   \n",
       "\n",
       "        R_1       B_4       B_5       R_2      D_47       B_7      D_51  \\\n",
       "0  0.005200  0.170079  0.017262  0.003640  0.422436  0.127707  0.341604   \n",
       "1  0.000326  0.058616  0.018488  0.008559  0.322846  0.028203  0.343203   \n",
       "2  0.004398  0.000113  0.015878  0.002745  0.104074  0.013242  0.006555   \n",
       "3  0.000691  0.008777  0.005575  0.003091  0.161946  0.001729  0.002436   \n",
       "4  0.005587  0.046676  0.000355  0.008184  0.698026  0.031777  0.003444   \n",
       "\n",
       "        B_9       R_3      B_10       S_5      B_11       S_6       R_4  \\\n",
       "0  0.125312  0.004692  0.071775  0.235043  0.078684  0.004515  0.006753   \n",
       "1  0.012959  0.004589  0.263159  0.011265  0.009033  0.001358  0.002491   \n",
       "2  0.330256  0.104061  0.295833  0.017091  0.008180  0.001898  0.003361   \n",
       "3  0.003744  0.104539  0.241943  0.004174  0.002968  0.005034  0.006416   \n",
       "4  0.006110  0.002101  0.302109  0.009895  0.002688  1.004870  0.004282   \n",
       "\n",
       "       B_12       S_8       R_5      D_58      B_14      D_60      S_11  \\\n",
       "0  0.058883  0.601257  0.003425  0.345972  0.105318  0.251269  0.247217   \n",
       "1  0.041200  0.473390  0.009546  0.076971  0.007563  0.057779  0.366408   \n",
       "2  0.033083  0.601631  0.000359  0.004538  0.004191  1.000364  0.169808   \n",
       "3  0.055979  0.000049  0.005212  0.000319  0.006942  1.000362  0.281841   \n",
       "4  0.013202  0.000988  0.006162  0.000046  0.008121  0.001122  0.282537   \n",
       "\n",
       "       D_65      B_18      S_12       R_6      S_13      B_21      D_71  \\\n",
       "0  0.004360  0.154858  0.186974  0.000019  0.005839  0.009161  0.021786   \n",
       "1  0.000119  0.689683  0.186860  0.002666  0.004748  0.007384  0.010354   \n",
       "2  0.008948  1.003902  0.287095  0.006800  0.005356  0.005840  0.007722   \n",
       "3  0.005681  1.000472  0.184539  0.003959  0.009599  0.008062  0.017003   \n",
       "4  0.007983  1.007565  0.192542  0.008761  0.007706  0.006156  0.013267   \n",
       "\n",
       "       S_15      B_23       P_4      D_75      B_24       R_7       R_8  \\\n",
       "0  0.102641  0.121351  0.007689  0.273959  0.005502  0.005441  0.007421   \n",
       "1  0.200859  0.022039  0.007445  0.068089  0.003663  0.008071  0.006521   \n",
       "2  0.102527  0.007286  0.999273  0.004058  0.009057  0.006252  0.008540   \n",
       "3  0.502531  0.001163  0.005453  0.004132  0.006190  0.005042  0.004440   \n",
       "4  0.505820  0.020652  0.006029  0.002928  0.005833  0.003131  0.000861   \n",
       "\n",
       "       S_16      R_10      R_11      S_17      R_12      B_28      R_13  \\\n",
       "0  0.009395  0.005316  0.005898  0.000883  1.001456  0.191578  0.008755   \n",
       "1  0.001118  0.000364  0.001478  0.000421  1.006366  0.033385  0.008700   \n",
       "2  0.005612  0.007738  0.004642  0.005338  1.008499  0.002226  0.002190   \n",
       "3  0.002743  0.003000  0.006849  0.008812  1.008704  0.003923  0.009735   \n",
       "4  0.001115  0.002127  0.004550  0.008325  1.001936  0.015701  0.009775   \n",
       "\n",
       "       R_14      R_15      R_16      S_18      D_86      R_17      R_18  B_31  \\\n",
       "0  0.009521  0.005977  0.003511  0.009176  0.007875  0.000052  0.006334     1   \n",
       "1  0.004947  0.004894  0.009017  0.002797  0.007823  0.000741  0.000220     1   \n",
       "2  0.006216  0.002994  0.006577  0.003979  0.001129  0.009506  0.006459     1   \n",
       "3  0.004162  0.003434  0.009959  0.004921  0.003618  0.002154  0.001943     1   \n",
       "4  0.000839  0.000164  0.002851  0.005621  0.006739  0.004563  0.000310     1   \n",
       "\n",
       "       S_19      R_19      B_32      S_20      R_20      R_21      R_22  \\\n",
       "0  0.008895  0.001252  0.002409  0.008441  0.001943  0.005561  0.002614   \n",
       "1  0.007795  0.000372  0.008684  0.004150  0.002847  0.001371  0.003795   \n",
       "2  0.008492  0.004421  0.007168  0.007949  0.004306  0.001701  0.005752   \n",
       "3  0.001330  0.008947  0.002850  0.002231  0.005219  0.008728  0.009430   \n",
       "4  0.006139  0.009859  0.006603  0.004136  0.005951  0.007638  0.003829   \n",
       "\n",
       "       R_23      D_92      D_93      D_94      R_24      R_25      D_96  \\\n",
       "0  0.008909  0.009994  0.000964  0.003467  0.005961  0.007027  0.009298   \n",
       "1  0.009797  0.006759  0.004067  0.009560  0.001706  0.000086  0.001236   \n",
       "2  0.003761  0.003694  0.000407  0.003953  0.004679  0.002599  0.002287   \n",
       "3  0.003600  0.004968  0.007001  0.005342  0.000502  0.008984  0.007908   \n",
       "4  0.005229  0.005499  0.003417  0.009155  0.007836  0.008184  0.008785   \n",
       "\n",
       "       S_26     D_102      B_36      B_37      B_40     D_127      B_41  \\\n",
       "0  0.013673  0.007749  0.008019  0.093438  0.107051  0.005854  0.009274   \n",
       "1  0.000889  0.006854  0.001334  0.012753  0.041467  0.006169  0.003988   \n",
       "2  0.005127  0.316072  0.009153  0.012228  0.005069  0.001408  0.007990   \n",
       "3  0.004083  0.004144  0.009074  0.007877  0.006503  0.006878  0.004739   \n",
       "4  0.009288  0.505266  0.008412  0.000782  0.035965  0.008331  0.000707   \n",
       "\n",
       "      D_133      R_28     D_140     D_144  target end_of_month  D_63_CL  \\\n",
       "0  0.006256  0.007657  0.003406  0.004150       0   2018-03-31      0.0   \n",
       "1  0.006433  0.006456  0.006752  0.000011       0   2018-03-31      0.0   \n",
       "2  0.004747  0.003762  0.008673  0.004924       0   2018-03-31      0.0   \n",
       "3  0.009892  0.007765  0.003798  0.008975       0   2018-03-31      0.0   \n",
       "4  0.007553  0.004204  0.009497  0.002808       0   2018-03-31      0.0   \n",
       "\n",
       "   D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_126_1.0  \n",
       "0      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "1      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "2      1.0      0.0      0.0      0.0      0.0        0.0  \n",
       "3      1.0      0.0      0.0      0.0      0.0        0.0  \n",
       "4      1.0      0.0      0.0      0.0      0.0        1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_oh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D_63', 'D_126'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(test_data[encoder.feature_names_in_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_oh = pd.concat([val_data.drop(columns=encoder.feature_names_in_),pd.DataFrame(encoder.transform(val_data[encoder.feature_names_in_]), columns=encoder.get_feature_names_out(),index=val_data.index)], axis=1)\n",
    "test_data_oh = pd.concat([test_data.drop(columns=encoder.feature_names_in_),pd.DataFrame(encoder.transform(test_data[encoder.feature_names_in_]), columns=encoder.get_feature_names_out(),index=test_data.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137674, 87), (32124, 87), (289115, 87))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_oh.shape, val_data_oh.shape, train_data_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['customer_ID', 'target', 'end_of_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_oh.drop(columns = drop_cols)\n",
    "X_val = val_data_oh.drop(columns = drop_cols)\n",
    "X_test = test_data_oh.drop(columns = drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_126_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.242734</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.007989</td>\n",
       "      <td>0.237095</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>1.009418</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>1.001973</td>\n",
       "      <td>0.281232</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>1.007102</td>\n",
       "      <td>0.188369</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.007862</td>\n",
       "      <td>0.504451</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.001477</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>1.007436</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006517</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.009732</td>\n",
       "      <td>0.205211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420352</td>\n",
       "      <td>0.031960</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.035561</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>0.034316</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.300955</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>0.408114</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.092397</td>\n",
       "      <td>0.963752</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>1.004892</td>\n",
       "      <td>0.288702</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.403595</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>0.300412</td>\n",
       "      <td>0.025808</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>1.005649</td>\n",
       "      <td>0.066157</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.009049</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>0.035614</td>\n",
       "      <td>1.005013</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.008073</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.443533</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>1.007340</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>1.002455</td>\n",
       "      <td>0.281869</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>1.005817</td>\n",
       "      <td>0.190173</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.505617</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.004511</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>1.000497</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.005709</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.529828</td>\n",
       "      <td>0.038727</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>0.022461</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.435676</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.667846</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>0.274815</td>\n",
       "      <td>0.091648</td>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.258967</td>\n",
       "      <td>0.758735</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.936297</td>\n",
       "      <td>0.763797</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>1.002396</td>\n",
       "      <td>0.204809</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>1.006915</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.219332</td>\n",
       "      <td>0.204772</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>1.004322</td>\n",
       "      <td>0.086685</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.064853</td>\n",
       "      <td>0.053221</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.034632</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>1.004507</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.507276</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>0.009805</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.295251</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.284533</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>1.004475</td>\n",
       "      <td>0.192104</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.502595</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>1.001148</td>\n",
       "      <td>0.020891</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.022032</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.706807</td>\n",
       "      <td>0.097944</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.294889</td>\n",
       "      <td>0.014902</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>0.569377</td>\n",
       "      <td>0.406718</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>0.146224</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.085035</td>\n",
       "      <td>0.079573</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>0.706907</td>\n",
       "      <td>0.008252</td>\n",
       "      <td>0.616480</td>\n",
       "      <td>0.116030</td>\n",
       "      <td>0.123622</td>\n",
       "      <td>0.768288</td>\n",
       "      <td>0.026604</td>\n",
       "      <td>0.058406</td>\n",
       "      <td>0.190605</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.689169</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.202554</td>\n",
       "      <td>0.403445</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.735829</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>1.004107</td>\n",
       "      <td>0.423878</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.918771</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.095006</td>\n",
       "      <td>0.431283</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.446819</td>\n",
       "      <td>0.796427</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>0.759947</td>\n",
       "      <td>0.078292</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>0.449862</td>\n",
       "      <td>0.370959</td>\n",
       "      <td>0.335084</td>\n",
       "      <td>0.635597</td>\n",
       "      <td>0.205013</td>\n",
       "      <td>0.036162</td>\n",
       "      <td>0.561122</td>\n",
       "      <td>0.847229</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.317623</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.574951</td>\n",
       "      <td>0.508468</td>\n",
       "      <td>0.521079</td>\n",
       "      <td>0.204382</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.102088</td>\n",
       "      <td>0.626483</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.429685</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>0.400674</td>\n",
       "      <td>0.372510</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>0.534819</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>1.009385</td>\n",
       "      <td>0.447739</td>\n",
       "      <td>0.006553</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.005977</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>0.218346</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.300366</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.608136</td>\n",
       "      <td>0.263778</td>\n",
       "      <td>0.336268</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>1.001837</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.456283</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.288003</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.593454</td>\n",
       "      <td>0.193278</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.501356</td>\n",
       "      <td>0.229586</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.203335</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>1.009776</td>\n",
       "      <td>0.121156</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.006788</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.004851</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.507379</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.045394</td>\n",
       "      <td>0.123405</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.378535</td>\n",
       "      <td>0.038289</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.097810</td>\n",
       "      <td>0.106539</td>\n",
       "      <td>0.297596</td>\n",
       "      <td>0.182459</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.107473</td>\n",
       "      <td>0.495261</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.083709</td>\n",
       "      <td>1.002530</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>1.002355</td>\n",
       "      <td>0.186494</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.427128</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.301002</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.007508</td>\n",
       "      <td>1.008680</td>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.004480</td>\n",
       "      <td>0.008231</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.862593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.046205</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>0.123268</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.536119</td>\n",
       "      <td>0.340992</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.040729</td>\n",
       "      <td>0.106062</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.024482</td>\n",
       "      <td>1.004593</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.595539</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.255453</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.016863</td>\n",
       "      <td>0.449918</td>\n",
       "      <td>0.007119</td>\n",
       "      <td>0.527820</td>\n",
       "      <td>0.190847</td>\n",
       "      <td>0.003164</td>\n",
       "      <td>0.289363</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.206111</td>\n",
       "      <td>0.335252</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.072676</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.009435</td>\n",
       "      <td>0.263368</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.039319</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.007434</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       D_39       B_1       R_1       B_4       B_5       R_2      D_47  \\\n",
       "0  0.001672  0.005188  0.009366  0.001294  0.008911  0.008567  0.242734   \n",
       "1  0.420352  0.031960  0.002225  0.035561  0.010599  0.000942  0.101764   \n",
       "2  0.000878  0.008073  0.000128  0.007653  0.006406  0.006176  0.443533   \n",
       "3  0.529828  0.038727  0.000890  0.041217  0.022461  0.003035  0.435676   \n",
       "4  0.006940  0.003159  0.006937  0.018499  0.008317  0.001423  0.507276   \n",
       "5  0.706807  0.097944  0.006336  0.294889  0.014902  0.007377  0.569377   \n",
       "6  0.446819  0.796427  0.009286  0.759947  0.078292  0.007616  0.449862   \n",
       "7  0.005217  0.005625  0.001559  0.067799  0.008333  0.004777  0.608136   \n",
       "8  0.507379  0.042568  0.002726  0.045394  0.123405  0.006364  0.378535   \n",
       "9  0.008552  0.046205  0.008397  0.123268  0.005010  0.004908  0.536119   \n",
       "\n",
       "        B_7      D_51       B_9       R_3      B_10       S_5      B_11  \\\n",
       "0  0.009670  0.004676  0.006376  0.007989  0.237095  0.004696  0.007281   \n",
       "1  0.034316  0.006136  0.016160  0.005280  0.300955  0.008938  0.013443   \n",
       "2  0.002133  0.002377  0.004103  0.008911  0.239413  0.006378  0.002042   \n",
       "3  0.030277  0.667846  0.004425  0.102747  0.274815  0.091648  0.032522   \n",
       "4  0.028936  0.009805  0.007681  0.002347  0.295251  0.002243  0.006396   \n",
       "5  0.406718  0.009277  0.146224  0.007283  0.023075  0.085035  0.079573   \n",
       "6  0.370959  0.335084  0.635597  0.205013  0.036162  0.561122  0.847229   \n",
       "7  0.263778  0.336268  0.003352  0.009174  0.029523  0.003595  0.009057   \n",
       "8  0.038289  0.004010  0.097810  0.106539  0.297596  0.182459  0.033100   \n",
       "9  0.340992  0.001618  0.040729  0.106062  0.016285  0.006120  0.024482   \n",
       "\n",
       "        S_6       R_4      B_12       S_8       R_5      D_58      B_14  \\\n",
       "0  1.009418  0.009051  0.009762  0.005873  0.009246  0.003226  0.008212   \n",
       "1  0.005331  0.002911  0.027829  0.408114  0.008509  0.007167  0.019749   \n",
       "2  1.007340  0.002030  0.007067  0.003666  0.005364  0.009714  0.009541   \n",
       "3  0.008830  0.009739  0.258967  0.758735  0.007153  0.002495  0.167203   \n",
       "4  0.007627  0.007836  0.013639  0.005341  0.002735  0.008159  0.009469   \n",
       "5  0.005938  0.003301  0.068463  0.706907  0.008252  0.616480  0.116030   \n",
       "6  0.007907  0.002504  0.032668  0.317623  0.002323  0.574951  0.508468   \n",
       "7  1.001837  0.001318  0.008636  0.004412  0.006859  0.456283  0.007804   \n",
       "8  0.000770  0.007017  0.107473  0.495261  0.000364  0.003885  0.083709   \n",
       "9  1.004593  0.000142  0.007848  0.595539  0.009501  0.255453  0.013628   \n",
       "\n",
       "       D_60      S_11      D_65      B_18      S_12       R_6      S_13  \\\n",
       "0  1.001973  0.281232  0.005724  1.007102  0.188369  0.008953  0.006374   \n",
       "1  0.092397  0.963752  0.002052  1.004892  0.288702  0.005012  0.403595   \n",
       "2  1.002455  0.281869  0.005645  1.005817  0.190173  0.008147  0.002074   \n",
       "3  0.936297  0.763797  0.007458  1.002396  0.204809  0.004471  1.006915   \n",
       "4  0.005135  0.284533  0.007304  1.004475  0.192104  0.001679  0.003331   \n",
       "5  0.123622  0.768288  0.026604  0.058406  0.190605  0.001140  0.689169   \n",
       "6  0.521079  0.204382  0.008607  0.102088  0.626483  0.004043  0.429685   \n",
       "7  0.004811  0.288003  0.002542  0.593454  0.193278  0.002362  0.000305   \n",
       "8  1.002530  0.163716  0.008328  1.002355  0.186494  0.003511  0.427128   \n",
       "9  0.016863  0.449918  0.007119  0.527820  0.190847  0.003164  0.289363   \n",
       "\n",
       "       B_21      D_71      S_15      B_23       P_4      D_75      B_24  \\\n",
       "0  0.001793  0.007862  0.504451  0.008021  0.007900  0.001477  0.002503   \n",
       "1  0.006960  0.008535  0.300412  0.025808  0.002919  0.003856  0.005936   \n",
       "2  0.004706  0.014830  0.505617  0.008820  0.007738  0.006817  0.007049   \n",
       "3  0.005196  0.219332  0.204772  0.020955  0.004579  0.006176  0.008057   \n",
       "4  0.008301  0.007452  0.502595  0.013044  0.002598  0.002524  0.007842   \n",
       "5  0.004451  0.060651  0.202554  0.403445  0.002119  0.735829  0.005307   \n",
       "6  0.000508  0.003820  0.400674  0.372510  0.006223  0.534819  0.004840   \n",
       "7  0.004478  0.016369  0.501356  0.229586  0.008617  0.203335  0.009744   \n",
       "8  0.004353  0.007851  0.301002  0.026520  0.007863  0.005261  0.005810   \n",
       "9  0.004691  0.009113  0.206111  0.335252  0.008808  0.072676  0.004738   \n",
       "\n",
       "        R_7       R_8      S_16      R_10      R_11      S_17      R_12  \\\n",
       "0  0.000712  0.005783  0.007029  0.001301  0.006079  0.002086  1.007436   \n",
       "1  0.006340  0.000275  0.005439  0.008588  0.008227  0.002646  1.005649   \n",
       "2  0.002470  0.004511  0.000380  0.000334  0.001390  0.001924  1.000497   \n",
       "3  0.007901  0.009587  0.002750  0.005753  0.008312  0.002256  1.004322   \n",
       "4  0.002321  0.000542  0.001532  0.003014  0.000324  0.004999  1.001148   \n",
       "5  0.004147  0.004626  0.004910  0.001411  0.006681  0.003862  1.004107   \n",
       "6  0.003087  0.007173  0.003601  0.003274  0.006985  0.008293  1.009385   \n",
       "7  0.003491  0.002508  0.003724  0.000106  0.005572  0.008713  1.009776   \n",
       "8  0.002716  0.009866  0.002394  0.009713  0.002024  0.007508  1.008680   \n",
       "9  0.009709  0.002602  0.007640  0.000233  0.000913  0.001486  1.009435   \n",
       "\n",
       "       B_28      R_13      R_14      R_15      R_16      S_18      D_86  \\\n",
       "0  0.004593  0.009583  0.002098  0.004590  0.002258  0.007122  0.002242   \n",
       "1  0.066157  0.000337  0.001202  0.007498  0.000040  0.009766  0.005014   \n",
       "2  0.008246  0.000481  0.007424  0.009645  0.006573  0.004153  0.004596   \n",
       "3  0.086685  0.003097  0.002377  0.005961  0.008897  0.005132  0.005017   \n",
       "4  0.020891  0.000936  0.000047  0.000375  0.007608  0.005749  0.005104   \n",
       "5  0.423878  0.008258  0.002527  0.005319  0.000527  0.009059  0.007632   \n",
       "6  0.447739  0.006553  0.000508  0.005506  0.009524  0.004932  0.005276   \n",
       "7  0.121156  0.004028  0.005913  0.008681  0.006788  0.007834  0.002848   \n",
       "8  0.041915  0.000142  0.001527  0.005872  0.006570  0.000286  0.001718   \n",
       "9  0.263368  0.000177  0.004570  0.006934  0.000172  0.001184  0.002813   \n",
       "\n",
       "       R_17      R_18  B_31      S_19      R_19      B_32      S_20      R_20  \\\n",
       "0  0.004192  0.006156     1  0.006517  0.001882  0.001362  0.001446  0.006670   \n",
       "1  0.000123  0.003355     1  0.006528  0.004266  0.003619  0.001605  0.008023   \n",
       "2  0.004586  0.009678     1  0.004827  0.002394  0.007624  0.002087  0.006155   \n",
       "3  0.001318  0.002823     1  0.002769  0.000164  0.008734  0.006459  0.009269   \n",
       "4  0.000973  0.007127     1  0.009697  0.009438  0.007518  0.005745  0.004426   \n",
       "5  0.009613  0.006514     1  0.001113  0.003418  0.001878  0.001274  0.000625   \n",
       "6  0.002958  0.001276     1  0.005680  0.001249  0.001577  0.000882  0.007638   \n",
       "7  0.007683  0.001531     1  0.006286  0.001519  0.002592  0.009522  0.004091   \n",
       "8  0.006269  0.007230     1  0.003203  0.004334  0.007902  0.007089  0.000847   \n",
       "9  0.009682  0.004786     1  0.005005  0.004805  0.003099  0.005265  0.002581   \n",
       "\n",
       "       R_21      R_22      R_23      D_92      D_93      D_94      R_24  \\\n",
       "0  0.008678  0.005204  0.000209  0.003262  0.008084  0.009534  0.003434   \n",
       "1  0.004698  0.004154  0.001158  0.006590  0.005622  0.009932  0.003718   \n",
       "2  0.005621  0.008221  0.000974  0.001925  0.004971  0.001411  0.005709   \n",
       "3  0.005878  0.009712  0.009635  0.008817  0.005246  0.009540  0.002278   \n",
       "4  0.009310  0.004664  0.004131  0.003961  0.000913  0.004211  0.003525   \n",
       "5  0.007834  0.002213  0.001481  0.000117  0.002387  0.002047  0.005379   \n",
       "6  0.009842  0.003997  0.006217  0.006563  0.009388  0.003312  0.000213   \n",
       "7  0.008146  0.002688  0.008576  0.003876  0.007624  0.005669  0.002614   \n",
       "8  0.000689  0.004480  0.008231  0.001196  0.006509  0.004642  0.001977   \n",
       "9  0.009228  0.004009  0.004146  0.007674  0.000486  0.003094  0.008379   \n",
       "\n",
       "       R_25      D_96      S_26     D_102      B_36      B_37      B_40  \\\n",
       "0  0.005336  0.001590  0.009988  0.005251  0.002806  0.008213  0.001515   \n",
       "1  0.000948  0.009049  0.008403  0.000434  0.009865  0.029769  0.035614   \n",
       "2  0.006304  0.007041  0.005836  0.003651  0.009048  0.007224  0.004003   \n",
       "3  0.001237  0.006665  0.064853  0.053221  0.001982  0.034632  0.019351   \n",
       "4  0.009630  0.005031  0.000060  0.002074  0.007133  0.005231  0.022032   \n",
       "5  0.007713  0.006211  0.066707  0.918771  0.005352  0.095006  0.431283   \n",
       "6  0.004613  0.003770  0.006512  0.009521  0.005977  0.794705  0.218346   \n",
       "7  0.008587  0.009932  0.001565  0.004851  0.008764  0.003775  0.027502   \n",
       "8  0.009817  0.002679  0.009463  0.007501  0.003410  0.043659  0.007527   \n",
       "9  0.000822  0.007149  0.008315  0.003731  0.006776  0.039319  0.124566   \n",
       "\n",
       "      D_127      B_41     D_133      R_28     D_140     D_144  D_63_CL  \\\n",
       "0  0.009355  0.004026  0.005988  0.004742  0.009732  0.205211      0.0   \n",
       "1  1.005013  0.002145  0.006932  0.001429  0.003010  0.006592      0.0   \n",
       "2  0.000791  0.008579  0.006732  0.002660  0.004114  0.008290      0.0   \n",
       "3  1.004507  0.001464  0.005564  0.008338  0.001805  0.003789      0.0   \n",
       "4  0.006107  0.009125  0.009787  0.002277  0.006071  0.008059      0.0   \n",
       "5  0.003851  0.009351  0.000324  0.002829  0.008764  0.001106      1.0   \n",
       "6  0.009099  0.003094  0.300366  0.006511  0.006612  0.002056      0.0   \n",
       "7  0.004388  0.000191  0.006534  0.009668  0.008949  0.006815      0.0   \n",
       "8  0.001542  0.001447  0.004595  0.001272  0.002926  0.862593      0.0   \n",
       "9  0.001933  0.001807  0.007434  0.001858  0.009922  0.007199      0.0   \n",
       "\n",
       "   D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_126_1.0  \n",
       "0      1.0      0.0      0.0      0.0      0.0        0.0  \n",
       "1      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "2      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "3      0.0      1.0      0.0      0.0      0.0        0.0  \n",
       "4      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "5      0.0      0.0      0.0      0.0      0.0        1.0  \n",
       "6      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "7      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "8      1.0      0.0      0.0      0.0      0.0        1.0  \n",
       "9      1.0      0.0      0.0      0.0      0.0        1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D_63_CL', 'D_63_CO', 'D_63_CR', 'D_63_XL', 'D_63_XM', 'D_63_XZ', 'D_126_1.0']\n"
     ]
    }
   ],
   "source": [
    "num_scale_drop_cols = encoder.get_feature_names_out().tolist()\n",
    "print(num_scale_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RobustScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RobustScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.RobustScaler.html\">?<span>Documentation for RobustScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RobustScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train.drop(columns=num_scale_drop_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train.drop(columns=num_scale_drop_cols)), columns=X_train.drop(columns=num_scale_drop_cols).columns, index=X_train.index)\n",
    "X_train_scaled = pd.concat([X_train[num_scale_drop_cols], X_train_scaled], axis=1)\n",
    "\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val.drop(columns=num_scale_drop_cols)), columns=X_val.drop(columns=num_scale_drop_cols).columns, index=X_val.index)\n",
    "X_val_scaled = pd.concat([X_val[num_scale_drop_cols], X_val_scaled], axis=1)\n",
    "\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test.drop(columns=num_scale_drop_cols)), columns=X_test.drop(columns=num_scale_drop_cols).columns, index=X_test.index)\n",
    "X_test_scaled = pd.concat([X_test[num_scale_drop_cols], X_test_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_126_1.0</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.088670</td>\n",
       "      <td>0.422883</td>\n",
       "      <td>-0.123533</td>\n",
       "      <td>0.330714</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>-0.327319</td>\n",
       "      <td>0.162116</td>\n",
       "      <td>0.153997</td>\n",
       "      <td>1.006030</td>\n",
       "      <td>0.231699</td>\n",
       "      <td>-0.043217</td>\n",
       "      <td>-0.089483</td>\n",
       "      <td>3.638024</td>\n",
       "      <td>0.478876</td>\n",
       "      <td>-0.311477</td>\n",
       "      <td>0.284984</td>\n",
       "      <td>0.745897</td>\n",
       "      <td>0.582049</td>\n",
       "      <td>-0.354592</td>\n",
       "      <td>0.574823</td>\n",
       "      <td>0.757507</td>\n",
       "      <td>0.044970</td>\n",
       "      <td>-0.383791</td>\n",
       "      <td>-0.190572</td>\n",
       "      <td>-0.545462</td>\n",
       "      <td>-0.304223</td>\n",
       "      <td>-0.996249</td>\n",
       "      <td>-0.008294</td>\n",
       "      <td>0.794719</td>\n",
       "      <td>0.451037</td>\n",
       "      <td>-1.012926</td>\n",
       "      <td>0.201219</td>\n",
       "      <td>0.335225</td>\n",
       "      <td>0.747442</td>\n",
       "      <td>0.054414</td>\n",
       "      <td>0.033041</td>\n",
       "      <td>0.423007</td>\n",
       "      <td>0.839197</td>\n",
       "      <td>-0.003552</td>\n",
       "      <td>0.094757</td>\n",
       "      <td>-0.836871</td>\n",
       "      <td>-0.650364</td>\n",
       "      <td>0.583116</td>\n",
       "      <td>0.714527</td>\n",
       "      <td>0.862570</td>\n",
       "      <td>0.167428</td>\n",
       "      <td>-0.351155</td>\n",
       "      <td>0.831049</td>\n",
       "      <td>0.531626</td>\n",
       "      <td>-0.992781</td>\n",
       "      <td>0.267686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.775236</td>\n",
       "      <td>-0.754435</td>\n",
       "      <td>-0.530806</td>\n",
       "      <td>0.669845</td>\n",
       "      <td>-0.618786</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>-0.477925</td>\n",
       "      <td>0.780788</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>-0.808936</td>\n",
       "      <td>-0.317926</td>\n",
       "      <td>0.163805</td>\n",
       "      <td>0.401359</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>1.079796</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>0.590360</td>\n",
       "      <td>0.430429</td>\n",
       "      <td>0.161425</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>0.808855</td>\n",
       "      <td>0.131938</td>\n",
       "      <td>0.532728</td>\n",
       "      <td>-0.332968</td>\n",
       "      <td>-0.244970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>-0.135002</td>\n",
       "      <td>-0.945277</td>\n",
       "      <td>-0.141814</td>\n",
       "      <td>0.086966</td>\n",
       "      <td>0.579557</td>\n",
       "      <td>-0.145716</td>\n",
       "      <td>-0.204815</td>\n",
       "      <td>1.010842</td>\n",
       "      <td>-0.037068</td>\n",
       "      <td>-0.044199</td>\n",
       "      <td>0.621777</td>\n",
       "      <td>-0.020577</td>\n",
       "      <td>-0.102654</td>\n",
       "      <td>-0.792032</td>\n",
       "      <td>-0.522592</td>\n",
       "      <td>0.426698</td>\n",
       "      <td>0.318758</td>\n",
       "      <td>0.807574</td>\n",
       "      <td>-0.105164</td>\n",
       "      <td>-0.227537</td>\n",
       "      <td>-0.264075</td>\n",
       "      <td>0.211278</td>\n",
       "      <td>-0.973053</td>\n",
       "      <td>0.120966</td>\n",
       "      <td>-0.313650</td>\n",
       "      <td>-0.500436</td>\n",
       "      <td>-0.010874</td>\n",
       "      <td>0.446834</td>\n",
       "      <td>-0.110781</td>\n",
       "      <td>-0.682462</td>\n",
       "      <td>-0.174941</td>\n",
       "      <td>0.292785</td>\n",
       "      <td>-0.028178</td>\n",
       "      <td>-0.298784</td>\n",
       "      <td>0.532287</td>\n",
       "      <td>0.250505</td>\n",
       "      <td>-0.777465</td>\n",
       "      <td>-0.932566</td>\n",
       "      <td>-0.728273</td>\n",
       "      <td>-0.923484</td>\n",
       "      <td>0.297105</td>\n",
       "      <td>-0.283309</td>\n",
       "      <td>0.703677</td>\n",
       "      <td>-0.031958</td>\n",
       "      <td>-0.043347</td>\n",
       "      <td>0.665378</td>\n",
       "      <td>-0.446564</td>\n",
       "      <td>0.521436</td>\n",
       "      <td>-0.856685</td>\n",
       "      <td>-0.957945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>-0.926871</td>\n",
       "      <td>0.693469</td>\n",
       "      <td>-0.180441</td>\n",
       "      <td>-0.442285</td>\n",
       "      <td>-0.728532</td>\n",
       "      <td>-0.242978</td>\n",
       "      <td>0.958416</td>\n",
       "      <td>0.248877</td>\n",
       "      <td>-0.193481</td>\n",
       "      <td>0.880665</td>\n",
       "      <td>-0.667898</td>\n",
       "      <td>-0.987678</td>\n",
       "      <td>-0.761791</td>\n",
       "      <td>-0.878604</td>\n",
       "      <td>-0.006589</td>\n",
       "      <td>-0.734539</td>\n",
       "      <td>-0.143569</td>\n",
       "      <td>-0.095629</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>-0.223163</td>\n",
       "      <td>0.164071</td>\n",
       "      <td>0.292014</td>\n",
       "      <td>0.319202</td>\n",
       "      <td>-0.997646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015073</td>\n",
       "      <td>-0.170979</td>\n",
       "      <td>-0.258682</td>\n",
       "      <td>-0.389827</td>\n",
       "      <td>0.024327</td>\n",
       "      <td>-0.492363</td>\n",
       "      <td>-0.821940</td>\n",
       "      <td>-0.258762</td>\n",
       "      <td>-0.002134</td>\n",
       "      <td>0.721955</td>\n",
       "      <td>0.900807</td>\n",
       "      <td>0.743205</td>\n",
       "      <td>0.074672</td>\n",
       "      <td>-0.109776</td>\n",
       "      <td>-0.709898</td>\n",
       "      <td>-0.357747</td>\n",
       "      <td>0.280176</td>\n",
       "      <td>0.582819</td>\n",
       "      <td>-0.936657</td>\n",
       "      <td>-0.288263</td>\n",
       "      <td>-0.261517</td>\n",
       "      <td>1.241431</td>\n",
       "      <td>-0.770256</td>\n",
       "      <td>0.655815</td>\n",
       "      <td>0.512504</td>\n",
       "      <td>7.950641</td>\n",
       "      <td>0.273920</td>\n",
       "      <td>-0.009436</td>\n",
       "      <td>0.144507</td>\n",
       "      <td>-0.240139</td>\n",
       "      <td>-1.013311</td>\n",
       "      <td>-0.230821</td>\n",
       "      <td>172.259390</td>\n",
       "      <td>-0.269416</td>\n",
       "      <td>0.737110</td>\n",
       "      <td>0.186946</td>\n",
       "      <td>0.637384</td>\n",
       "      <td>0.100231</td>\n",
       "      <td>0.450799</td>\n",
       "      <td>-0.139133</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>0.708681</td>\n",
       "      <td>-0.453971</td>\n",
       "      <td>-0.567493</td>\n",
       "      <td>0.216251</td>\n",
       "      <td>-0.413277</td>\n",
       "      <td>0.214913</td>\n",
       "      <td>-0.209690</td>\n",
       "      <td>-0.780781</td>\n",
       "      <td>0.874721</td>\n",
       "      <td>0.292753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694647</td>\n",
       "      <td>-0.133293</td>\n",
       "      <td>0.397529</td>\n",
       "      <td>0.572277</td>\n",
       "      <td>-0.157337</td>\n",
       "      <td>-0.663548</td>\n",
       "      <td>0.146571</td>\n",
       "      <td>-0.249689</td>\n",
       "      <td>-0.316950</td>\n",
       "      <td>-0.919391</td>\n",
       "      <td>-0.222258</td>\n",
       "      <td>-0.086815</td>\n",
       "      <td>-0.484734</td>\n",
       "      <td>-0.557958</td>\n",
       "      <td>-0.229440</td>\n",
       "      <td>0.934155</td>\n",
       "      <td>0.815258</td>\n",
       "      <td>-0.147299</td>\n",
       "      <td>-0.238291</td>\n",
       "      <td>-0.746571</td>\n",
       "      <td>0.558312</td>\n",
       "      <td>-0.142226</td>\n",
       "      <td>-0.248045</td>\n",
       "      <td>0.693572</td>\n",
       "      <td>-0.104327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014873</td>\n",
       "      <td>-0.223407</td>\n",
       "      <td>-0.883683</td>\n",
       "      <td>-0.353099</td>\n",
       "      <td>-0.223005</td>\n",
       "      <td>-0.428510</td>\n",
       "      <td>-0.643058</td>\n",
       "      <td>-0.300280</td>\n",
       "      <td>-0.014527</td>\n",
       "      <td>-0.059112</td>\n",
       "      <td>0.905350</td>\n",
       "      <td>0.542930</td>\n",
       "      <td>-0.136505</td>\n",
       "      <td>-0.153291</td>\n",
       "      <td>-0.232473</td>\n",
       "      <td>0.221122</td>\n",
       "      <td>0.693485</td>\n",
       "      <td>-0.655890</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>-0.298928</td>\n",
       "      <td>-0.233798</td>\n",
       "      <td>1.241429</td>\n",
       "      <td>-0.210928</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.508230</td>\n",
       "      <td>-0.505015</td>\n",
       "      <td>-0.258240</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.579612</td>\n",
       "      <td>0.215973</td>\n",
       "      <td>0.332545</td>\n",
       "      <td>-0.254013</td>\n",
       "      <td>-0.052569</td>\n",
       "      <td>-0.269139</td>\n",
       "      <td>0.186481</td>\n",
       "      <td>-0.042703</td>\n",
       "      <td>-0.148317</td>\n",
       "      <td>-0.460127</td>\n",
       "      <td>-0.438068</td>\n",
       "      <td>0.271815</td>\n",
       "      <td>0.650425</td>\n",
       "      <td>0.748226</td>\n",
       "      <td>-0.444675</td>\n",
       "      <td>0.905898</td>\n",
       "      <td>-0.185451</td>\n",
       "      <td>-0.327616</td>\n",
       "      <td>0.839341</td>\n",
       "      <td>-0.021021</td>\n",
       "      <td>-0.296522</td>\n",
       "      <td>-0.577510</td>\n",
       "      <td>-0.612577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.735841</td>\n",
       "      <td>0.753719</td>\n",
       "      <td>-0.444878</td>\n",
       "      <td>-0.560667</td>\n",
       "      <td>0.020916</td>\n",
       "      <td>0.718757</td>\n",
       "      <td>0.878509</td>\n",
       "      <td>-0.281785</td>\n",
       "      <td>-0.081803</td>\n",
       "      <td>0.388113</td>\n",
       "      <td>0.050858</td>\n",
       "      <td>-0.903229</td>\n",
       "      <td>0.792877</td>\n",
       "      <td>0.532444</td>\n",
       "      <td>-0.389322</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>0.799593</td>\n",
       "      <td>-0.178254</td>\n",
       "      <td>-0.232669</td>\n",
       "      <td>0.236212</td>\n",
       "      <td>-0.076542</td>\n",
       "      <td>0.792279</td>\n",
       "      <td>0.554352</td>\n",
       "      <td>-0.256709</td>\n",
       "      <td>0.632331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.033273</td>\n",
       "      <td>-0.195419</td>\n",
       "      <td>-0.058354</td>\n",
       "      <td>-0.192431</td>\n",
       "      <td>-0.348331</td>\n",
       "      <td>0.510546</td>\n",
       "      <td>1.013961</td>\n",
       "      <td>-0.191926</td>\n",
       "      <td>-0.011494</td>\n",
       "      <td>-0.053452</td>\n",
       "      <td>-0.067831</td>\n",
       "      <td>0.766531</td>\n",
       "      <td>-0.042975</td>\n",
       "      <td>-0.155627</td>\n",
       "      <td>151.980436</td>\n",
       "      <td>-0.183302</td>\n",
       "      <td>-0.078702</td>\n",
       "      <td>-0.653955</td>\n",
       "      <td>0.164959</td>\n",
       "      <td>-0.299617</td>\n",
       "      <td>-0.221912</td>\n",
       "      <td>-0.354567</td>\n",
       "      <td>-0.207450</td>\n",
       "      <td>0.477755</td>\n",
       "      <td>0.517069</td>\n",
       "      <td>0.154848</td>\n",
       "      <td>0.641112</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.206477</td>\n",
       "      <td>0.032392</td>\n",
       "      <td>0.343609</td>\n",
       "      <td>-0.180194</td>\n",
       "      <td>0.047355</td>\n",
       "      <td>-0.273675</td>\n",
       "      <td>0.118052</td>\n",
       "      <td>-0.405498</td>\n",
       "      <td>-0.834055</td>\n",
       "      <td>-0.778098</td>\n",
       "      <td>-0.601903</td>\n",
       "      <td>-0.156164</td>\n",
       "      <td>0.559099</td>\n",
       "      <td>-0.557724</td>\n",
       "      <td>-0.380166</td>\n",
       "      <td>0.913617</td>\n",
       "      <td>-0.835234</td>\n",
       "      <td>-0.964208</td>\n",
       "      <td>-0.473012</td>\n",
       "      <td>0.119153</td>\n",
       "      <td>0.310637</td>\n",
       "      <td>-0.101731</td>\n",
       "      <td>-0.939846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224778</td>\n",
       "      <td>0.932417</td>\n",
       "      <td>0.287468</td>\n",
       "      <td>-0.183209</td>\n",
       "      <td>0.163799</td>\n",
       "      <td>0.504434</td>\n",
       "      <td>-0.236152</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>-0.322540</td>\n",
       "      <td>0.800911</td>\n",
       "      <td>0.530087</td>\n",
       "      <td>0.632804</td>\n",
       "      <td>0.702489</td>\n",
       "      <td>0.408062</td>\n",
       "      <td>1.509746</td>\n",
       "      <td>0.668401</td>\n",
       "      <td>-0.228728</td>\n",
       "      <td>-0.117194</td>\n",
       "      <td>0.497304</td>\n",
       "      <td>-0.863557</td>\n",
       "      <td>0.367536</td>\n",
       "      <td>-0.159272</td>\n",
       "      <td>0.854168</td>\n",
       "      <td>-0.488993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.033959</td>\n",
       "      <td>-0.065408</td>\n",
       "      <td>-0.367628</td>\n",
       "      <td>-0.383324</td>\n",
       "      <td>1.847961</td>\n",
       "      <td>0.523478</td>\n",
       "      <td>0.641964</td>\n",
       "      <td>-0.228026</td>\n",
       "      <td>-0.004001</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>-0.083173</td>\n",
       "      <td>0.757617</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>-0.108064</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.301183</td>\n",
       "      <td>0.494892</td>\n",
       "      <td>0.297002</td>\n",
       "      <td>0.558112</td>\n",
       "      <td>-0.287839</td>\n",
       "      <td>-0.113335</td>\n",
       "      <td>0.971279</td>\n",
       "      <td>-0.409977</td>\n",
       "      <td>-0.614616</td>\n",
       "      <td>0.514596</td>\n",
       "      <td>-2.578471</td>\n",
       "      <td>0.669237</td>\n",
       "      <td>0.977716</td>\n",
       "      <td>0.843779</td>\n",
       "      <td>0.059112</td>\n",
       "      <td>-0.344836</td>\n",
       "      <td>-0.225360</td>\n",
       "      <td>-0.512758</td>\n",
       "      <td>-0.275786</td>\n",
       "      <td>-0.684749</td>\n",
       "      <td>0.140870</td>\n",
       "      <td>-0.128991</td>\n",
       "      <td>-0.603364</td>\n",
       "      <td>0.804499</td>\n",
       "      <td>-0.582640</td>\n",
       "      <td>-0.916404</td>\n",
       "      <td>-0.713558</td>\n",
       "      <td>-0.396513</td>\n",
       "      <td>0.683074</td>\n",
       "      <td>-0.928714</td>\n",
       "      <td>0.088619</td>\n",
       "      <td>-0.727746</td>\n",
       "      <td>-0.176926</td>\n",
       "      <td>-0.869537</td>\n",
       "      <td>-0.311417</td>\n",
       "      <td>0.046633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188313</td>\n",
       "      <td>-0.564191</td>\n",
       "      <td>0.814412</td>\n",
       "      <td>-0.283820</td>\n",
       "      <td>-0.777557</td>\n",
       "      <td>-0.669366</td>\n",
       "      <td>0.374531</td>\n",
       "      <td>-0.913155</td>\n",
       "      <td>-0.746813</td>\n",
       "      <td>0.157101</td>\n",
       "      <td>0.426296</td>\n",
       "      <td>0.230793</td>\n",
       "      <td>-0.300751</td>\n",
       "      <td>0.902265</td>\n",
       "      <td>-0.909136</td>\n",
       "      <td>-0.027127</td>\n",
       "      <td>0.317457</td>\n",
       "      <td>-0.068319</td>\n",
       "      <td>-0.209274</td>\n",
       "      <td>0.133024</td>\n",
       "      <td>-0.065377</td>\n",
       "      <td>0.387876</td>\n",
       "      <td>-0.552725</td>\n",
       "      <td>0.341766</td>\n",
       "      <td>-0.691941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>1.910754</td>\n",
       "      <td>0.348825</td>\n",
       "      <td>1.852588</td>\n",
       "      <td>-0.054349</td>\n",
       "      <td>-0.390543</td>\n",
       "      <td>0.376058</td>\n",
       "      <td>1.144288</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>0.723240</td>\n",
       "      <td>-0.003207</td>\n",
       "      <td>-0.256594</td>\n",
       "      <td>-0.199341</td>\n",
       "      <td>2.114731</td>\n",
       "      <td>0.134970</td>\n",
       "      <td>-0.425366</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.568502</td>\n",
       "      <td>-0.477325</td>\n",
       "      <td>1.737608</td>\n",
       "      <td>0.779787</td>\n",
       "      <td>-0.120332</td>\n",
       "      <td>0.613925</td>\n",
       "      <td>-0.269985</td>\n",
       "      <td>-0.611844</td>\n",
       "      <td>0.138682</td>\n",
       "      <td>-0.952198</td>\n",
       "      <td>0.662183</td>\n",
       "      <td>-0.619526</td>\n",
       "      <td>-0.186159</td>\n",
       "      <td>-0.659381</td>\n",
       "      <td>1.273408</td>\n",
       "      <td>-0.523700</td>\n",
       "      <td>3.241703</td>\n",
       "      <td>-0.279179</td>\n",
       "      <td>0.349923</td>\n",
       "      <td>-0.143452</td>\n",
       "      <td>-0.598497</td>\n",
       "      <td>-0.629213</td>\n",
       "      <td>93.581049</td>\n",
       "      <td>-0.526925</td>\n",
       "      <td>-0.301315</td>\n",
       "      <td>1.400412</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.491498</td>\n",
       "      <td>-0.037262</td>\n",
       "      <td>-0.610211</td>\n",
       "      <td>0.859834</td>\n",
       "      <td>0.329066</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>-0.559712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.541884</td>\n",
       "      <td>0.536968</td>\n",
       "      <td>-0.688138</td>\n",
       "      <td>-0.538365</td>\n",
       "      <td>0.644121</td>\n",
       "      <td>0.370828</td>\n",
       "      <td>-0.264401</td>\n",
       "      <td>-0.792298</td>\n",
       "      <td>0.301140</td>\n",
       "      <td>-0.544563</td>\n",
       "      <td>0.151110</td>\n",
       "      <td>0.836944</td>\n",
       "      <td>0.455373</td>\n",
       "      <td>-0.814104</td>\n",
       "      <td>-0.850202</td>\n",
       "      <td>-0.027438</td>\n",
       "      <td>0.268026</td>\n",
       "      <td>1.950424</td>\n",
       "      <td>1.187604</td>\n",
       "      <td>-0.545737</td>\n",
       "      <td>0.207217</td>\n",
       "      <td>-0.897264</td>\n",
       "      <td>-0.462191</td>\n",
       "      <td>-0.181095</td>\n",
       "      <td>0.170142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.328384</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.572702</td>\n",
       "      <td>-0.189329</td>\n",
       "      <td>10.347930</td>\n",
       "      <td>-0.784146</td>\n",
       "      <td>0.073841</td>\n",
       "      <td>-0.211080</td>\n",
       "      <td>-0.009833</td>\n",
       "      <td>0.253116</td>\n",
       "      <td>-0.080337</td>\n",
       "      <td>0.670136</td>\n",
       "      <td>1.239760</td>\n",
       "      <td>-0.013591</td>\n",
       "      <td>0.454343</td>\n",
       "      <td>0.781253</td>\n",
       "      <td>5.886662</td>\n",
       "      <td>0.357607</td>\n",
       "      <td>-0.684848</td>\n",
       "      <td>-0.073630</td>\n",
       "      <td>1.499211</td>\n",
       "      <td>0.913269</td>\n",
       "      <td>2.791333</td>\n",
       "      <td>-0.836904</td>\n",
       "      <td>0.129061</td>\n",
       "      <td>18.108978</td>\n",
       "      <td>0.407863</td>\n",
       "      <td>2.357697</td>\n",
       "      <td>-0.483538</td>\n",
       "      <td>1.524913</td>\n",
       "      <td>-0.339626</td>\n",
       "      <td>-0.193146</td>\n",
       "      <td>-0.358642</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>0.425611</td>\n",
       "      <td>0.099369</td>\n",
       "      <td>-0.554045</td>\n",
       "      <td>-0.668458</td>\n",
       "      <td>-0.871837</td>\n",
       "      <td>0.131746</td>\n",
       "      <td>0.858274</td>\n",
       "      <td>-0.586089</td>\n",
       "      <td>0.116368</td>\n",
       "      <td>-0.603662</td>\n",
       "      <td>0.912236</td>\n",
       "      <td>-0.996071</td>\n",
       "      <td>-0.626542</td>\n",
       "      <td>0.896683</td>\n",
       "      <td>-0.638769</td>\n",
       "      <td>-0.850323</td>\n",
       "      <td>0.911160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.101937</td>\n",
       "      <td>0.196178</td>\n",
       "      <td>0.600394</td>\n",
       "      <td>-0.949445</td>\n",
       "      <td>-0.023875</td>\n",
       "      <td>-0.114598</td>\n",
       "      <td>0.204908</td>\n",
       "      <td>0.733496</td>\n",
       "      <td>0.704320</td>\n",
       "      <td>-0.359874</td>\n",
       "      <td>-0.080273</td>\n",
       "      <td>-0.853068</td>\n",
       "      <td>-0.405682</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>0.177160</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>-0.349365</td>\n",
       "      <td>-0.026091</td>\n",
       "      <td>-0.214251</td>\n",
       "      <td>178.695210</td>\n",
       "      <td>0.917482</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.537940</td>\n",
       "      <td>-0.758068</td>\n",
       "      <td>0.223687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423830</td>\n",
       "      <td>1.371426</td>\n",
       "      <td>-0.978761</td>\n",
       "      <td>0.444971</td>\n",
       "      <td>1.671162</td>\n",
       "      <td>-0.992471</td>\n",
       "      <td>-0.171064</td>\n",
       "      <td>0.456671</td>\n",
       "      <td>2.001720</td>\n",
       "      <td>1.251933</td>\n",
       "      <td>-0.054729</td>\n",
       "      <td>-0.133260</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>1.915337</td>\n",
       "      <td>-0.490060</td>\n",
       "      <td>-0.963956</td>\n",
       "      <td>2.540084</td>\n",
       "      <td>0.797687</td>\n",
       "      <td>0.218684</td>\n",
       "      <td>0.184618</td>\n",
       "      <td>6.875262</td>\n",
       "      <td>0.325715</td>\n",
       "      <td>1.603298</td>\n",
       "      <td>0.801118</td>\n",
       "      <td>-0.669607</td>\n",
       "      <td>1.184640</td>\n",
       "      <td>-0.628633</td>\n",
       "      <td>1.603906</td>\n",
       "      <td>-0.903933</td>\n",
       "      <td>1.547623</td>\n",
       "      <td>-0.657538</td>\n",
       "      <td>0.593146</td>\n",
       "      <td>-0.185924</td>\n",
       "      <td>0.502306</td>\n",
       "      <td>-0.395392</td>\n",
       "      <td>0.436674</td>\n",
       "      <td>0.209697</td>\n",
       "      <td>0.191305</td>\n",
       "      <td>-0.053083</td>\n",
       "      <td>-0.675982</td>\n",
       "      <td>9.657274</td>\n",
       "      <td>0.460806</td>\n",
       "      <td>3.705238</td>\n",
       "      <td>-0.699058</td>\n",
       "      <td>-0.554691</td>\n",
       "      <td>-0.249258</td>\n",
       "      <td>0.773466</td>\n",
       "      <td>0.827667</td>\n",
       "      <td>0.240655</td>\n",
       "      <td>-0.805992</td>\n",
       "      <td>0.386209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.573661</td>\n",
       "      <td>-0.933568</td>\n",
       "      <td>0.478517</td>\n",
       "      <td>-0.226007</td>\n",
       "      <td>-0.563545</td>\n",
       "      <td>0.145234</td>\n",
       "      <td>0.127037</td>\n",
       "      <td>0.068242</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>-0.572915</td>\n",
       "      <td>0.404805</td>\n",
       "      <td>-0.088541</td>\n",
       "      <td>-0.781098</td>\n",
       "      <td>194.129301</td>\n",
       "      <td>6.695017</td>\n",
       "      <td>2.061198</td>\n",
       "      <td>-0.558483</td>\n",
       "      <td>1.432895</td>\n",
       "      <td>0.436790</td>\n",
       "      <td>0.576592</td>\n",
       "      <td>-0.529424</td>\n",
       "      <td>36.907175</td>\n",
       "      <td>0.405817</td>\n",
       "      <td>-0.763352</td>\n",
       "      <td>0.678369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083821</td>\n",
       "      <td>0.772203</td>\n",
       "      <td>-0.486021</td>\n",
       "      <td>1.323415</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>-0.893019</td>\n",
       "      <td>0.385744</td>\n",
       "      <td>3.496815</td>\n",
       "      <td>0.984022</td>\n",
       "      <td>0.469394</td>\n",
       "      <td>0.942983</td>\n",
       "      <td>-0.276453</td>\n",
       "      <td>-0.127854</td>\n",
       "      <td>0.686010</td>\n",
       "      <td>-0.905814</td>\n",
       "      <td>0.867913</td>\n",
       "      <td>-0.210211</td>\n",
       "      <td>-0.639533</td>\n",
       "      <td>-0.591309</td>\n",
       "      <td>0.437459</td>\n",
       "      <td>0.055561</td>\n",
       "      <td>-0.279790</td>\n",
       "      <td>-0.209213</td>\n",
       "      <td>0.159690</td>\n",
       "      <td>-0.620217</td>\n",
       "      <td>-0.381076</td>\n",
       "      <td>0.273500</td>\n",
       "      <td>-0.015379</td>\n",
       "      <td>0.199157</td>\n",
       "      <td>0.024769</td>\n",
       "      <td>0.351266</td>\n",
       "      <td>3.666041</td>\n",
       "      <td>-0.080577</td>\n",
       "      <td>0.980872</td>\n",
       "      <td>-0.757020</td>\n",
       "      <td>-0.621108</td>\n",
       "      <td>-0.883062</td>\n",
       "      <td>-0.952557</td>\n",
       "      <td>-0.840776</td>\n",
       "      <td>0.197097</td>\n",
       "      <td>0.802715</td>\n",
       "      <td>0.273318</td>\n",
       "      <td>1.130349</td>\n",
       "      <td>-0.982010</td>\n",
       "      <td>-0.465466</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.222674</td>\n",
       "      <td>0.616482</td>\n",
       "      <td>0.590436</td>\n",
       "      <td>-0.162293</td>\n",
       "      <td>-0.251791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106865</td>\n",
       "      <td>-0.499867</td>\n",
       "      <td>-0.497867</td>\n",
       "      <td>0.128467</td>\n",
       "      <td>0.211529</td>\n",
       "      <td>0.457237</td>\n",
       "      <td>-0.995484</td>\n",
       "      <td>-0.703193</td>\n",
       "      <td>0.379080</td>\n",
       "      <td>0.466788</td>\n",
       "      <td>0.758920</td>\n",
       "      <td>-0.761595</td>\n",
       "      <td>0.437084</td>\n",
       "      <td>-0.031858</td>\n",
       "      <td>-0.080431</td>\n",
       "      <td>2.781710</td>\n",
       "      <td>-0.029748</td>\n",
       "      <td>0.758338</td>\n",
       "      <td>1.312190</td>\n",
       "      <td>0.623752</td>\n",
       "      <td>0.921371</td>\n",
       "      <td>-0.838069</td>\n",
       "      <td>-0.570460</td>\n",
       "      <td>-0.475158</td>\n",
       "      <td>0.116048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   D_63_CL  D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_126_1.0      D_39  \\\n",
       "0      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.088670   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.009356   \n",
       "2      0.0      1.0      0.0      0.0      0.0      0.0        0.0 -0.015073   \n",
       "3      0.0      1.0      0.0      0.0      0.0      0.0        0.0 -0.014873   \n",
       "4      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.033273   \n",
       "5      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.033959   \n",
       "6      1.0      0.0      0.0      0.0      0.0      0.0        1.0  0.222336   \n",
       "7      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.328384   \n",
       "8      0.0      1.0      0.0      0.0      0.0      0.0        1.0  0.423830   \n",
       "9      0.0      1.0      0.0      0.0      0.0      0.0        1.0  0.083821   \n",
       "\n",
       "        B_1       R_1       B_4        B_5       R_2      D_47       B_7  \\\n",
       "0  0.422883 -0.123533  0.330714   0.057551 -0.327319  0.162116  0.153997   \n",
       "1 -0.135002 -0.945277 -0.141814   0.086966  0.579557 -0.145716 -0.204815   \n",
       "2 -0.170979 -0.258682 -0.389827   0.024327 -0.492363 -0.821940 -0.258762   \n",
       "3 -0.223407 -0.883683 -0.353099  -0.223005 -0.428510 -0.643058 -0.300280   \n",
       "4 -0.195419 -0.058354 -0.192431  -0.348331  0.510546  1.013961 -0.191926   \n",
       "5 -0.065408 -0.367628 -0.383324   1.847961  0.523478  0.641964 -0.228026   \n",
       "6  1.910754  0.348825  1.852588  -0.054349 -0.390543  0.376058  1.144288   \n",
       "7 -0.001411  0.572702 -0.189329  10.347930 -0.784146  0.073841 -0.211080   \n",
       "8  1.371426 -0.978761  0.444971   1.671162 -0.992471 -0.171064  0.456671   \n",
       "9  0.772203 -0.486021  1.323415   0.001172 -0.893019  0.385744  3.496815   \n",
       "\n",
       "       D_51       B_9       R_3      B_10       S_5      B_11         S_6  \\\n",
       "0  1.006030  0.231699 -0.043217 -0.089483  3.638024  0.478876   -0.311477   \n",
       "1  1.010842 -0.037068 -0.044199  0.621777 -0.020577 -0.102654   -0.792032   \n",
       "2 -0.002134  0.721955  0.900807  0.743205  0.074672 -0.109776   -0.709898   \n",
       "3 -0.014527 -0.059112  0.905350  0.542930 -0.136505 -0.153291   -0.232473   \n",
       "4 -0.011494 -0.053452 -0.067831  0.766531 -0.042975 -0.155627  151.980436   \n",
       "5 -0.004001  0.006202 -0.083173  0.757617  0.160296 -0.108064    0.010762   \n",
       "6 -0.010623  0.723240 -0.003207 -0.256594 -0.199341  2.114731    0.134970   \n",
       "7 -0.009833  0.253116 -0.080337  0.670136  1.239760 -0.013591    0.454343   \n",
       "8  2.001720  1.251933 -0.054729 -0.133260  0.402893  1.915337   -0.490060   \n",
       "9  0.984022  0.469394  0.942983 -0.276453 -0.127854  0.686010   -0.905814   \n",
       "\n",
       "        R_4      B_12       S_8       R_5      D_58      B_14      D_60  \\\n",
       "0  0.284984  0.745897  0.582049 -0.354592  0.574823  0.757507  0.044970   \n",
       "1 -0.522592  0.426698  0.318758  0.807574 -0.105164 -0.227537 -0.264075   \n",
       "2 -0.357747  0.280176  0.582819 -0.936657 -0.288263 -0.261517  1.241431   \n",
       "3  0.221122  0.693485 -0.655890 -0.015347 -0.298928 -0.233798  1.241429   \n",
       "4 -0.183302 -0.078702 -0.653955  0.164959 -0.299617 -0.221912 -0.354567   \n",
       "5  0.301183  0.494892  0.297002  0.558112 -0.287839 -0.113335  0.971279   \n",
       "6 -0.425366  0.014964  0.568502 -0.477325  1.737608  0.779787 -0.120332   \n",
       "7  0.781253  5.886662  0.357607 -0.684848 -0.073630  1.499211  0.913269   \n",
       "8 -0.963956  2.540084  0.797687  0.218684  0.184618  6.875262  0.325715   \n",
       "9  0.867913 -0.210211 -0.639533 -0.591309  0.437459  0.055561 -0.279790   \n",
       "\n",
       "       S_11      D_65      B_18       S_12       R_6      S_13      B_21  \\\n",
       "0 -0.383791 -0.190572 -0.545462  -0.304223 -0.996249 -0.008294  0.794719   \n",
       "1  0.211278 -0.973053  0.120966  -0.313650 -0.500436 -0.010874  0.446834   \n",
       "2 -0.770256  0.655815  0.512504   7.950641  0.273920 -0.009436  0.144507   \n",
       "3 -0.210928  0.053156  0.508230  -0.505015 -0.258240  0.000592  0.579612   \n",
       "4 -0.207450  0.477755  0.517069   0.154848  0.641112 -0.003882  0.206477   \n",
       "5 -0.409977 -0.614616  0.514596  -2.578471  0.669237  0.977716  0.843779   \n",
       "6  0.613925 -0.269985 -0.611844   0.138682 -0.952198  0.662183 -0.619526   \n",
       "7  2.791333 -0.836904  0.129061  18.108978  0.407863  2.357697 -0.483538   \n",
       "8  1.603298  0.801118 -0.669607   1.184640 -0.628633  1.603906 -0.903933   \n",
       "9 -0.209213  0.159690 -0.620217  -0.381076  0.273500 -0.015379  0.199157   \n",
       "\n",
       "       D_71      S_15      B_23         P_4      D_75      B_24       R_7  \\\n",
       "0  0.451037 -1.012926  0.201219    0.335225  0.747442  0.054414  0.033041   \n",
       "1 -0.110781 -0.682462 -0.174941    0.292785 -0.028178 -0.298784  0.532287   \n",
       "2 -0.240139 -1.013311 -0.230821  172.259390 -0.269416  0.737110  0.186946   \n",
       "3  0.215973  0.332545 -0.254013   -0.052569 -0.269139  0.186481 -0.042703   \n",
       "4  0.032392  0.343609 -0.180194    0.047355 -0.273675  0.118052 -0.405498   \n",
       "5  0.059112 -0.344836 -0.225360   -0.512758 -0.275786 -0.684749  0.140870   \n",
       "6 -0.186159 -0.659381  1.273408   -0.523700  3.241703 -0.279179  0.349923   \n",
       "7  1.524913 -0.339626 -0.193146   -0.358642 -0.005316  0.425611  0.099369   \n",
       "8  1.547623 -0.657538  0.593146   -0.185924  0.502306 -0.395392  0.436674   \n",
       "9  0.024769  0.351266  3.666041   -0.080577  0.980872 -0.757020 -0.621108   \n",
       "\n",
       "        R_8      S_16      R_10       R_11      S_17      R_12      B_28  \\\n",
       "0  0.423007  0.839197 -0.003552   0.094757 -0.836871 -0.650364  0.583116   \n",
       "1  0.250505 -0.777465 -0.932566  -0.728273 -0.923484  0.297105 -0.283309   \n",
       "2  0.637384  0.100231  0.450799  -0.139133 -0.001227  0.708681 -0.453971   \n",
       "3 -0.148317 -0.460127 -0.438068   0.271815  0.650425  0.748226 -0.444675   \n",
       "4 -0.834055 -0.778098 -0.601903  -0.156164  0.559099 -0.557724 -0.380166   \n",
       "5 -0.128991 -0.603364  0.804499  -0.582640 -0.916404 -0.713558 -0.396513   \n",
       "6 -0.143452 -0.598497 -0.629213  93.581049 -0.526925 -0.301315  1.400412   \n",
       "7 -0.554045 -0.668458 -0.871837   0.131746  0.858274 -0.586089  0.116368   \n",
       "8  0.209697  0.191305 -0.053083  -0.675982  9.657274  0.460806  3.705238   \n",
       "9 -0.883062 -0.952557 -0.840776   0.197097  0.802715  0.273318  1.130349   \n",
       "\n",
       "       R_13      R_14      R_15      R_16      S_18      D_86      R_17  \\\n",
       "0  0.714527  0.862570  0.167428 -0.351155  0.831049  0.531626 -0.992781   \n",
       "1  0.703677 -0.031958 -0.043347  0.665378 -0.446564  0.521436 -0.856685   \n",
       "2 -0.567493  0.216251 -0.413277  0.214913 -0.209690 -0.780781  0.874721   \n",
       "3  0.905898 -0.185451 -0.327616  0.839341 -0.021021 -0.296522 -0.577510   \n",
       "4  0.913617 -0.835234 -0.964208 -0.473012  0.119153  0.310637 -0.101731   \n",
       "5  0.683074 -0.928714  0.088619 -0.727746 -0.176926 -0.869537 -0.311417   \n",
       "6  0.050985  0.491498 -0.037262 -0.610211  0.859834  0.329066  0.837080   \n",
       "7 -0.603662  0.912236 -0.996071 -0.626542  0.896683 -0.638769 -0.850323   \n",
       "8 -0.699058 -0.554691 -0.249258  0.773466  0.827667  0.240655 -0.805992   \n",
       "9 -0.982010 -0.465466  0.447500  0.222674  0.616482  0.590436 -0.162293   \n",
       "\n",
       "       R_18  B_31      S_19      R_19      B_32      S_20      R_20      R_21  \\\n",
       "0  0.267686   0.0  0.775236 -0.754435 -0.530806  0.669845 -0.618786  0.095855   \n",
       "1 -0.957945   0.0  0.555555 -0.926871  0.693469 -0.180441 -0.442285 -0.728532   \n",
       "2  0.292753   0.0  0.694647 -0.133293  0.397529  0.572277 -0.157337 -0.663548   \n",
       "3 -0.612577   0.0 -0.735841  0.753719 -0.444878 -0.560667  0.020916  0.718757   \n",
       "4 -0.939846   0.0  0.224778  0.932417  0.287468 -0.183209  0.163799  0.504434   \n",
       "5  0.046633   0.0  0.188313 -0.564191  0.814412 -0.283820 -0.777557 -0.669366   \n",
       "6 -0.559712   0.0 -0.541884  0.536968 -0.688138 -0.538365  0.644121  0.370828   \n",
       "7  0.911160   0.0 -0.101937  0.196178  0.600394 -0.949445 -0.023875 -0.114598   \n",
       "8  0.386209   0.0 -0.573661 -0.933568  0.478517 -0.226007 -0.563545  0.145234   \n",
       "9 -0.251791   0.0  0.106865 -0.499867 -0.497867  0.128467  0.211529  0.457237   \n",
       "\n",
       "       R_22      R_23      D_92      D_93      D_94      R_24      R_25  \\\n",
       "0 -0.477925  0.780788  0.846082 -0.808936 -0.317926  0.163805  0.401359   \n",
       "1 -0.242978  0.958416  0.248877 -0.193481  0.880665 -0.667898 -0.987678   \n",
       "2  0.146571 -0.249689 -0.316950 -0.919391 -0.222258 -0.086815 -0.484734   \n",
       "3  0.878509 -0.281785 -0.081803  0.388113  0.050858 -0.903229  0.792877   \n",
       "4 -0.236152  0.044267  0.016284 -0.322540  0.800911  0.530087  0.632804   \n",
       "5  0.374531 -0.913155 -0.746813  0.157101  0.426296  0.230793 -0.300751   \n",
       "6 -0.264401 -0.792298  0.301140 -0.544563  0.151110  0.836944  0.455373   \n",
       "7  0.204908  0.733496  0.704320 -0.359874 -0.080273 -0.853068 -0.405682   \n",
       "8  0.127037  0.068242  0.076399 -0.572915  0.404805 -0.088541 -0.781098   \n",
       "9 -0.995484 -0.703193  0.379080  0.466788  0.758920 -0.761595  0.437084   \n",
       "\n",
       "         D_96      S_26     D_102      B_36      B_37      B_40       D_127  \\\n",
       "0    0.801887  1.079796 -0.003867  0.590360  0.430429  0.161425    0.052367   \n",
       "1   -0.761791 -0.878604 -0.006589 -0.734539 -0.143569 -0.095629    0.108921   \n",
       "2   -0.557958 -0.229440  0.934155  0.815258 -0.147299 -0.238291   -0.746571   \n",
       "3    0.532444 -0.389322 -0.014836  0.799593 -0.178254 -0.232669    0.236212   \n",
       "4    0.702489  0.408062  1.509746  0.668401 -0.228728 -0.117194    0.497304   \n",
       "5    0.902265 -0.909136 -0.027127  0.317457 -0.068319 -0.209274    0.133024   \n",
       "6   -0.814104 -0.850202 -0.027438  0.268026  1.950424  1.187604   -0.545737   \n",
       "7    0.185805  0.177160  0.000485 -0.349365 -0.026091 -0.214251  178.695210   \n",
       "8  194.129301  6.695017  2.061198 -0.558483  1.432895  0.436790    0.576592   \n",
       "9   -0.031858 -0.080431  2.781710 -0.029748  0.758338  1.312190    0.623752   \n",
       "\n",
       "       B_41      D_133      R_28     D_140     D_144  \n",
       "0  0.808855   0.131938  0.532728 -0.332968 -0.244970  \n",
       "1 -0.223163   0.164071  0.292014  0.319202 -0.997646  \n",
       "2  0.558312  -0.142226 -0.248045  0.693572 -0.104327  \n",
       "3 -0.076542   0.792279  0.554352 -0.256709  0.632331  \n",
       "4 -0.863557   0.367536 -0.159272  0.854168 -0.488993  \n",
       "5 -0.065377   0.387876 -0.552725  0.341766 -0.691941  \n",
       "6  0.207217  -0.897264 -0.462191 -0.181095  0.170142  \n",
       "7  0.917482   0.805153  0.537940 -0.758068  0.223687  \n",
       "8 -0.529424  36.907175  0.405817 -0.763352  0.678369  \n",
       "9  0.921371  -0.838069 -0.570460 -0.475158  0.116048  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_126_1.0</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030079</td>\n",
       "      <td>-0.194353</td>\n",
       "      <td>0.578712</td>\n",
       "      <td>-0.384822</td>\n",
       "      <td>-0.142929</td>\n",
       "      <td>0.581005</td>\n",
       "      <td>-0.393345</td>\n",
       "      <td>-0.271646</td>\n",
       "      <td>-0.007788</td>\n",
       "      <td>-0.052815</td>\n",
       "      <td>-0.011894</td>\n",
       "      <td>0.524912</td>\n",
       "      <td>-0.127970</td>\n",
       "      <td>-0.117280</td>\n",
       "      <td>152.672934</td>\n",
       "      <td>0.720555</td>\n",
       "      <td>-0.140806</td>\n",
       "      <td>-0.643897</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>-0.291579</td>\n",
       "      <td>-0.221002</td>\n",
       "      <td>1.244001</td>\n",
       "      <td>-0.213967</td>\n",
       "      <td>0.060939</td>\n",
       "      <td>0.516491</td>\n",
       "      <td>-0.189201</td>\n",
       "      <td>0.677130</td>\n",
       "      <td>-0.007030</td>\n",
       "      <td>-0.647836</td>\n",
       "      <td>-0.233256</td>\n",
       "      <td>0.339005</td>\n",
       "      <td>-0.228037</td>\n",
       "      <td>0.371743</td>\n",
       "      <td>-0.279139</td>\n",
       "      <td>-0.521531</td>\n",
       "      <td>-0.864698</td>\n",
       "      <td>0.109204</td>\n",
       "      <td>0.377151</td>\n",
       "      <td>-0.756786</td>\n",
       "      <td>0.128584</td>\n",
       "      <td>-0.611160</td>\n",
       "      <td>0.503640</td>\n",
       "      <td>-0.441005</td>\n",
       "      <td>0.876096</td>\n",
       "      <td>-0.589107</td>\n",
       "      <td>-0.102574</td>\n",
       "      <td>-0.582524</td>\n",
       "      <td>0.419583</td>\n",
       "      <td>-0.564247</td>\n",
       "      <td>-0.174935</td>\n",
       "      <td>0.232135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300156</td>\n",
       "      <td>-0.630990</td>\n",
       "      <td>-0.735156</td>\n",
       "      <td>-0.716060</td>\n",
       "      <td>0.304229</td>\n",
       "      <td>0.709052</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>-0.960587</td>\n",
       "      <td>-0.396852</td>\n",
       "      <td>0.603038</td>\n",
       "      <td>0.875520</td>\n",
       "      <td>-0.330116</td>\n",
       "      <td>0.062894</td>\n",
       "      <td>-0.693150</td>\n",
       "      <td>0.515303</td>\n",
       "      <td>-0.011467</td>\n",
       "      <td>-0.442691</td>\n",
       "      <td>-0.175864</td>\n",
       "      <td>-0.252220</td>\n",
       "      <td>0.681342</td>\n",
       "      <td>-0.215606</td>\n",
       "      <td>0.083272</td>\n",
       "      <td>-0.051607</td>\n",
       "      <td>0.899916</td>\n",
       "      <td>36.316310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.566662</td>\n",
       "      <td>-0.008937</td>\n",
       "      <td>-0.625142</td>\n",
       "      <td>-0.239551</td>\n",
       "      <td>-0.102401</td>\n",
       "      <td>-0.824745</td>\n",
       "      <td>-0.829083</td>\n",
       "      <td>-0.182771</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>-0.029411</td>\n",
       "      <td>-0.037635</td>\n",
       "      <td>0.762243</td>\n",
       "      <td>-0.058611</td>\n",
       "      <td>-0.065835</td>\n",
       "      <td>-0.187174</td>\n",
       "      <td>-0.443022</td>\n",
       "      <td>0.185327</td>\n",
       "      <td>0.184351</td>\n",
       "      <td>0.610542</td>\n",
       "      <td>-0.281618</td>\n",
       "      <td>-0.104739</td>\n",
       "      <td>-0.208782</td>\n",
       "      <td>3.193557</td>\n",
       "      <td>-0.616374</td>\n",
       "      <td>0.513737</td>\n",
       "      <td>8.083164</td>\n",
       "      <td>-0.061052</td>\n",
       "      <td>0.931915</td>\n",
       "      <td>0.363911</td>\n",
       "      <td>-0.200203</td>\n",
       "      <td>-0.347505</td>\n",
       "      <td>-0.160666</td>\n",
       "      <td>-0.491952</td>\n",
       "      <td>-0.270175</td>\n",
       "      <td>0.137662</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>-0.946326</td>\n",
       "      <td>0.066443</td>\n",
       "      <td>0.610326</td>\n",
       "      <td>0.528433</td>\n",
       "      <td>-0.506065</td>\n",
       "      <td>0.158755</td>\n",
       "      <td>-0.103816</td>\n",
       "      <td>-0.929343</td>\n",
       "      <td>-0.764254</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>-0.992074</td>\n",
       "      <td>0.949096</td>\n",
       "      <td>-0.024935</td>\n",
       "      <td>-0.978841</td>\n",
       "      <td>-0.329449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302395</td>\n",
       "      <td>-0.163770</td>\n",
       "      <td>-0.294761</td>\n",
       "      <td>-0.684658</td>\n",
       "      <td>0.568481</td>\n",
       "      <td>-0.074052</td>\n",
       "      <td>-0.171454</td>\n",
       "      <td>-0.770602</td>\n",
       "      <td>0.217587</td>\n",
       "      <td>0.114829</td>\n",
       "      <td>0.953832</td>\n",
       "      <td>-0.274646</td>\n",
       "      <td>-0.815210</td>\n",
       "      <td>0.753606</td>\n",
       "      <td>0.272526</td>\n",
       "      <td>-0.026121</td>\n",
       "      <td>0.956390</td>\n",
       "      <td>-0.022518</td>\n",
       "      <td>-0.118569</td>\n",
       "      <td>179.589215</td>\n",
       "      <td>-0.582900</td>\n",
       "      <td>0.254664</td>\n",
       "      <td>-0.715495</td>\n",
       "      <td>-0.410238</td>\n",
       "      <td>0.199063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.033107</td>\n",
       "      <td>-0.174373</td>\n",
       "      <td>-0.978577</td>\n",
       "      <td>-0.357863</td>\n",
       "      <td>-0.203055</td>\n",
       "      <td>0.140283</td>\n",
       "      <td>0.227325</td>\n",
       "      <td>-0.298821</td>\n",
       "      <td>-0.014707</td>\n",
       "      <td>-0.058253</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.533525</td>\n",
       "      <td>-0.100474</td>\n",
       "      <td>-0.161027</td>\n",
       "      <td>152.356448</td>\n",
       "      <td>-0.610055</td>\n",
       "      <td>-0.189456</td>\n",
       "      <td>-0.648441</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>-0.275178</td>\n",
       "      <td>-0.207605</td>\n",
       "      <td>1.244771</td>\n",
       "      <td>-0.210789</td>\n",
       "      <td>0.046459</td>\n",
       "      <td>0.514890</td>\n",
       "      <td>-0.040511</td>\n",
       "      <td>0.526153</td>\n",
       "      <td>-0.017195</td>\n",
       "      <td>-0.077509</td>\n",
       "      <td>0.109168</td>\n",
       "      <td>0.342928</td>\n",
       "      <td>-0.225009</td>\n",
       "      <td>0.343578</td>\n",
       "      <td>-0.259023</td>\n",
       "      <td>0.351462</td>\n",
       "      <td>-0.530828</td>\n",
       "      <td>-0.134636</td>\n",
       "      <td>-0.921508</td>\n",
       "      <td>-0.938155</td>\n",
       "      <td>-0.744672</td>\n",
       "      <td>-0.641608</td>\n",
       "      <td>-0.835390</td>\n",
       "      <td>-0.421001</td>\n",
       "      <td>-0.901208</td>\n",
       "      <td>0.452562</td>\n",
       "      <td>0.881577</td>\n",
       "      <td>0.214264</td>\n",
       "      <td>-0.174861</td>\n",
       "      <td>-0.106231</td>\n",
       "      <td>-0.097231</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037235</td>\n",
       "      <td>-0.530533</td>\n",
       "      <td>0.486548</td>\n",
       "      <td>-0.589126</td>\n",
       "      <td>0.203690</td>\n",
       "      <td>0.107670</td>\n",
       "      <td>0.637974</td>\n",
       "      <td>-0.807461</td>\n",
       "      <td>-0.643628</td>\n",
       "      <td>-0.014345</td>\n",
       "      <td>-0.722370</td>\n",
       "      <td>0.114526</td>\n",
       "      <td>0.256631</td>\n",
       "      <td>0.364241</td>\n",
       "      <td>-0.120702</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>0.794329</td>\n",
       "      <td>-0.182900</td>\n",
       "      <td>-0.242466</td>\n",
       "      <td>-0.857550</td>\n",
       "      <td>0.673143</td>\n",
       "      <td>0.218296</td>\n",
       "      <td>-0.468812</td>\n",
       "      <td>-0.195074</td>\n",
       "      <td>0.507778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.984176</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>-0.850152</td>\n",
       "      <td>-0.215573</td>\n",
       "      <td>0.182334</td>\n",
       "      <td>-0.438968</td>\n",
       "      <td>0.203038</td>\n",
       "      <td>-0.197336</td>\n",
       "      <td>1.987695</td>\n",
       "      <td>-0.057482</td>\n",
       "      <td>0.888322</td>\n",
       "      <td>0.665093</td>\n",
       "      <td>1.293623</td>\n",
       "      <td>0.093459</td>\n",
       "      <td>0.345464</td>\n",
       "      <td>0.850891</td>\n",
       "      <td>4.357720</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>0.353175</td>\n",
       "      <td>-0.293428</td>\n",
       "      <td>1.381102</td>\n",
       "      <td>1.139103</td>\n",
       "      <td>2.195266</td>\n",
       "      <td>0.380903</td>\n",
       "      <td>0.510628</td>\n",
       "      <td>1.166226</td>\n",
       "      <td>-0.162388</td>\n",
       "      <td>2.358034</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>10.159919</td>\n",
       "      <td>-0.669296</td>\n",
       "      <td>-0.179047</td>\n",
       "      <td>-0.204001</td>\n",
       "      <td>-0.261437</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>0.500036</td>\n",
       "      <td>0.837986</td>\n",
       "      <td>-0.458745</td>\n",
       "      <td>0.078365</td>\n",
       "      <td>0.544259</td>\n",
       "      <td>-0.579326</td>\n",
       "      <td>-0.097402</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>-0.390269</td>\n",
       "      <td>-0.534526</td>\n",
       "      <td>0.164324</td>\n",
       "      <td>0.643167</td>\n",
       "      <td>0.021145</td>\n",
       "      <td>-0.024452</td>\n",
       "      <td>-0.742711</td>\n",
       "      <td>-0.436073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.448375</td>\n",
       "      <td>-0.967543</td>\n",
       "      <td>0.703076</td>\n",
       "      <td>0.277079</td>\n",
       "      <td>0.811748</td>\n",
       "      <td>0.158112</td>\n",
       "      <td>0.934542</td>\n",
       "      <td>0.926036</td>\n",
       "      <td>0.628684</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>0.876584</td>\n",
       "      <td>-0.556110</td>\n",
       "      <td>-0.757304</td>\n",
       "      <td>0.291302</td>\n",
       "      <td>8.920435</td>\n",
       "      <td>0.134475</td>\n",
       "      <td>-0.606101</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>-0.182312</td>\n",
       "      <td>179.498156</td>\n",
       "      <td>-0.715862</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>0.669250</td>\n",
       "      <td>-0.645083</td>\n",
       "      <td>-0.310766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>-0.208411</td>\n",
       "      <td>0.169286</td>\n",
       "      <td>-0.311881</td>\n",
       "      <td>-0.157200</td>\n",
       "      <td>-0.736100</td>\n",
       "      <td>0.424354</td>\n",
       "      <td>-0.202172</td>\n",
       "      <td>0.007645</td>\n",
       "      <td>-0.049693</td>\n",
       "      <td>-0.065498</td>\n",
       "      <td>0.741042</td>\n",
       "      <td>-0.168080</td>\n",
       "      <td>-0.124675</td>\n",
       "      <td>0.162340</td>\n",
       "      <td>0.490329</td>\n",
       "      <td>-0.070819</td>\n",
       "      <td>-0.644992</td>\n",
       "      <td>-0.485652</td>\n",
       "      <td>-0.279110</td>\n",
       "      <td>-0.208335</td>\n",
       "      <td>-0.348158</td>\n",
       "      <td>-0.197489</td>\n",
       "      <td>0.352429</td>\n",
       "      <td>0.513218</td>\n",
       "      <td>0.118718</td>\n",
       "      <td>-0.685404</td>\n",
       "      <td>-0.014224</td>\n",
       "      <td>0.626296</td>\n",
       "      <td>-0.253399</td>\n",
       "      <td>0.332759</td>\n",
       "      <td>-0.209010</td>\n",
       "      <td>-0.547537</td>\n",
       "      <td>-0.275195</td>\n",
       "      <td>0.503822</td>\n",
       "      <td>-0.559253</td>\n",
       "      <td>-0.895226</td>\n",
       "      <td>-0.696610</td>\n",
       "      <td>-0.435517</td>\n",
       "      <td>-0.943093</td>\n",
       "      <td>-0.064824</td>\n",
       "      <td>-0.709923</td>\n",
       "      <td>-0.351739</td>\n",
       "      <td>-0.812298</td>\n",
       "      <td>-0.990240</td>\n",
       "      <td>-0.923232</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>0.144755</td>\n",
       "      <td>-0.007410</td>\n",
       "      <td>-0.810802</td>\n",
       "      <td>0.426805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935423</td>\n",
       "      <td>0.849905</td>\n",
       "      <td>0.465850</td>\n",
       "      <td>0.135578</td>\n",
       "      <td>-0.133945</td>\n",
       "      <td>0.833261</td>\n",
       "      <td>-0.069866</td>\n",
       "      <td>-0.175530</td>\n",
       "      <td>-0.267707</td>\n",
       "      <td>-0.818986</td>\n",
       "      <td>-0.171589</td>\n",
       "      <td>-0.312395</td>\n",
       "      <td>0.922094</td>\n",
       "      <td>-0.025609</td>\n",
       "      <td>-1.005682</td>\n",
       "      <td>-0.021132</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>-0.197078</td>\n",
       "      <td>-0.171804</td>\n",
       "      <td>0.097737</td>\n",
       "      <td>0.779770</td>\n",
       "      <td>0.773277</td>\n",
       "      <td>-0.545606</td>\n",
       "      <td>0.186408</td>\n",
       "      <td>0.465836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.659131</td>\n",
       "      <td>0.448053</td>\n",
       "      <td>0.067979</td>\n",
       "      <td>0.859824</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.361719</td>\n",
       "      <td>0.616309</td>\n",
       "      <td>1.160108</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.281724</td>\n",
       "      <td>-0.018602</td>\n",
       "      <td>-0.270469</td>\n",
       "      <td>1.185511</td>\n",
       "      <td>0.486292</td>\n",
       "      <td>-0.094813</td>\n",
       "      <td>-0.369142</td>\n",
       "      <td>0.918834</td>\n",
       "      <td>0.799589</td>\n",
       "      <td>0.561896</td>\n",
       "      <td>1.258619</td>\n",
       "      <td>0.865443</td>\n",
       "      <td>-0.158910</td>\n",
       "      <td>2.217692</td>\n",
       "      <td>3.913039</td>\n",
       "      <td>-0.665647</td>\n",
       "      <td>-0.004832</td>\n",
       "      <td>-0.786381</td>\n",
       "      <td>1.606951</td>\n",
       "      <td>-0.127500</td>\n",
       "      <td>2.361169</td>\n",
       "      <td>-0.676759</td>\n",
       "      <td>1.269687</td>\n",
       "      <td>-0.630520</td>\n",
       "      <td>2.487550</td>\n",
       "      <td>0.017016</td>\n",
       "      <td>-0.212522</td>\n",
       "      <td>-0.112579</td>\n",
       "      <td>-0.036839</td>\n",
       "      <td>-0.736215</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>-0.278097</td>\n",
       "      <td>-0.138879</td>\n",
       "      <td>1.855432</td>\n",
       "      <td>0.617518</td>\n",
       "      <td>-0.505121</td>\n",
       "      <td>0.039299</td>\n",
       "      <td>-0.902163</td>\n",
       "      <td>0.807571</td>\n",
       "      <td>0.484423</td>\n",
       "      <td>0.895847</td>\n",
       "      <td>0.303898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.779081</td>\n",
       "      <td>-0.329965</td>\n",
       "      <td>-0.634499</td>\n",
       "      <td>-0.750194</td>\n",
       "      <td>-0.876187</td>\n",
       "      <td>0.542935</td>\n",
       "      <td>-0.557729</td>\n",
       "      <td>-0.705906</td>\n",
       "      <td>-0.977363</td>\n",
       "      <td>-0.526665</td>\n",
       "      <td>-0.597136</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.538592</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>9.204380</td>\n",
       "      <td>2.767770</td>\n",
       "      <td>0.061763</td>\n",
       "      <td>0.441586</td>\n",
       "      <td>1.432246</td>\n",
       "      <td>-0.307704</td>\n",
       "      <td>0.823928</td>\n",
       "      <td>-0.945595</td>\n",
       "      <td>-0.434873</td>\n",
       "      <td>0.711327</td>\n",
       "      <td>-0.798540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667602</td>\n",
       "      <td>5.285590</td>\n",
       "      <td>0.565360</td>\n",
       "      <td>2.831356</td>\n",
       "      <td>1.522588</td>\n",
       "      <td>0.405705</td>\n",
       "      <td>0.246889</td>\n",
       "      <td>1.031161</td>\n",
       "      <td>0.986411</td>\n",
       "      <td>1.452378</td>\n",
       "      <td>1.859874</td>\n",
       "      <td>-0.221832</td>\n",
       "      <td>8.969167</td>\n",
       "      <td>6.895579</td>\n",
       "      <td>0.204981</td>\n",
       "      <td>-0.520122</td>\n",
       "      <td>0.272688</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>-0.563745</td>\n",
       "      <td>1.153643</td>\n",
       "      <td>4.819905</td>\n",
       "      <td>0.475913</td>\n",
       "      <td>-0.597645</td>\n",
       "      <td>0.592965</td>\n",
       "      <td>-0.611217</td>\n",
       "      <td>35.932871</td>\n",
       "      <td>-0.242534</td>\n",
       "      <td>0.993586</td>\n",
       "      <td>-0.899421</td>\n",
       "      <td>-0.431931</td>\n",
       "      <td>-0.010166</td>\n",
       "      <td>1.152519</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>1.730240</td>\n",
       "      <td>-0.072746</td>\n",
       "      <td>-0.413805</td>\n",
       "      <td>0.375482</td>\n",
       "      <td>-0.292448</td>\n",
       "      <td>-0.386726</td>\n",
       "      <td>0.297266</td>\n",
       "      <td>0.553135</td>\n",
       "      <td>0.879651</td>\n",
       "      <td>1.986122</td>\n",
       "      <td>0.284422</td>\n",
       "      <td>-0.899992</td>\n",
       "      <td>0.075677</td>\n",
       "      <td>0.758974</td>\n",
       "      <td>-0.018987</td>\n",
       "      <td>0.026109</td>\n",
       "      <td>-0.418833</td>\n",
       "      <td>-0.746122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133007</td>\n",
       "      <td>-0.754931</td>\n",
       "      <td>-0.693169</td>\n",
       "      <td>-0.827945</td>\n",
       "      <td>0.493280</td>\n",
       "      <td>0.938008</td>\n",
       "      <td>-0.202728</td>\n",
       "      <td>0.242026</td>\n",
       "      <td>0.212631</td>\n",
       "      <td>0.861536</td>\n",
       "      <td>-0.348335</td>\n",
       "      <td>-0.959809</td>\n",
       "      <td>-0.081780</td>\n",
       "      <td>-0.270257</td>\n",
       "      <td>-0.017283</td>\n",
       "      <td>0.001524</td>\n",
       "      <td>0.185647</td>\n",
       "      <td>5.419262</td>\n",
       "      <td>0.597646</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>-0.397688</td>\n",
       "      <td>53.554505</td>\n",
       "      <td>0.303012</td>\n",
       "      <td>0.291930</td>\n",
       "      <td>-0.625848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.016557</td>\n",
       "      <td>-0.191332</td>\n",
       "      <td>-0.737462</td>\n",
       "      <td>-0.102883</td>\n",
       "      <td>-0.156807</td>\n",
       "      <td>-0.117743</td>\n",
       "      <td>0.736112</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>0.989974</td>\n",
       "      <td>-0.060050</td>\n",
       "      <td>-0.000638</td>\n",
       "      <td>-0.246507</td>\n",
       "      <td>-0.145975</td>\n",
       "      <td>-0.102455</td>\n",
       "      <td>151.518764</td>\n",
       "      <td>-0.744956</td>\n",
       "      <td>-0.161139</td>\n",
       "      <td>-0.646905</td>\n",
       "      <td>0.297287</td>\n",
       "      <td>0.853669</td>\n",
       "      <td>-0.225104</td>\n",
       "      <td>-0.348675</td>\n",
       "      <td>-0.180160</td>\n",
       "      <td>-0.525979</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.215481</td>\n",
       "      <td>-0.557530</td>\n",
       "      <td>-0.021375</td>\n",
       "      <td>-0.122074</td>\n",
       "      <td>0.184807</td>\n",
       "      <td>0.328590</td>\n",
       "      <td>0.611173</td>\n",
       "      <td>0.496033</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>0.869049</td>\n",
       "      <td>-0.337090</td>\n",
       "      <td>-0.518525</td>\n",
       "      <td>-0.268546</td>\n",
       "      <td>-0.981103</td>\n",
       "      <td>0.034075</td>\n",
       "      <td>0.631776</td>\n",
       "      <td>0.955106</td>\n",
       "      <td>0.197413</td>\n",
       "      <td>-0.208551</td>\n",
       "      <td>0.157094</td>\n",
       "      <td>0.693808</td>\n",
       "      <td>0.253921</td>\n",
       "      <td>0.562217</td>\n",
       "      <td>-0.446284</td>\n",
       "      <td>0.514654</td>\n",
       "      <td>-0.695042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254033</td>\n",
       "      <td>-0.702067</td>\n",
       "      <td>-0.495289</td>\n",
       "      <td>0.883981</td>\n",
       "      <td>-0.199348</td>\n",
       "      <td>0.604370</td>\n",
       "      <td>-0.463123</td>\n",
       "      <td>0.714029</td>\n",
       "      <td>-0.283412</td>\n",
       "      <td>0.511822</td>\n",
       "      <td>0.115179</td>\n",
       "      <td>-0.490476</td>\n",
       "      <td>0.713411</td>\n",
       "      <td>0.924921</td>\n",
       "      <td>-0.775120</td>\n",
       "      <td>-0.012685</td>\n",
       "      <td>0.738089</td>\n",
       "      <td>-0.207437</td>\n",
       "      <td>-0.150364</td>\n",
       "      <td>-0.211089</td>\n",
       "      <td>-0.964375</td>\n",
       "      <td>0.182457</td>\n",
       "      <td>0.935750</td>\n",
       "      <td>0.747358</td>\n",
       "      <td>0.239573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.898562</td>\n",
       "      <td>0.064531</td>\n",
       "      <td>-0.540586</td>\n",
       "      <td>-0.197865</td>\n",
       "      <td>2.605556</td>\n",
       "      <td>0.174905</td>\n",
       "      <td>0.026418</td>\n",
       "      <td>-0.168445</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>0.165908</td>\n",
       "      <td>0.924353</td>\n",
       "      <td>0.749759</td>\n",
       "      <td>2.778317</td>\n",
       "      <td>0.098288</td>\n",
       "      <td>-0.881596</td>\n",
       "      <td>0.335042</td>\n",
       "      <td>1.623025</td>\n",
       "      <td>0.363794</td>\n",
       "      <td>-0.935747</td>\n",
       "      <td>-0.289912</td>\n",
       "      <td>0.539758</td>\n",
       "      <td>1.244891</td>\n",
       "      <td>-0.800673</td>\n",
       "      <td>0.541419</td>\n",
       "      <td>0.510576</td>\n",
       "      <td>-0.343820</td>\n",
       "      <td>-0.342248</td>\n",
       "      <td>0.987543</td>\n",
       "      <td>-0.146541</td>\n",
       "      <td>-0.233827</td>\n",
       "      <td>-0.345522</td>\n",
       "      <td>-0.157970</td>\n",
       "      <td>0.365298</td>\n",
       "      <td>-0.264884</td>\n",
       "      <td>0.113635</td>\n",
       "      <td>-0.484168</td>\n",
       "      <td>0.891503</td>\n",
       "      <td>-0.528155</td>\n",
       "      <td>0.821282</td>\n",
       "      <td>-0.626519</td>\n",
       "      <td>0.405926</td>\n",
       "      <td>0.743717</td>\n",
       "      <td>-0.236594</td>\n",
       "      <td>-0.967426</td>\n",
       "      <td>-0.700800</td>\n",
       "      <td>0.146933</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>-0.949277</td>\n",
       "      <td>-0.666110</td>\n",
       "      <td>0.235210</td>\n",
       "      <td>0.447423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.361601</td>\n",
       "      <td>-0.150428</td>\n",
       "      <td>0.540769</td>\n",
       "      <td>0.401871</td>\n",
       "      <td>-0.832844</td>\n",
       "      <td>-0.862597</td>\n",
       "      <td>-0.106549</td>\n",
       "      <td>0.645137</td>\n",
       "      <td>-0.778245</td>\n",
       "      <td>0.290737</td>\n",
       "      <td>-0.086707</td>\n",
       "      <td>-0.614921</td>\n",
       "      <td>0.959553</td>\n",
       "      <td>-0.481837</td>\n",
       "      <td>0.434845</td>\n",
       "      <td>-0.004620</td>\n",
       "      <td>-0.323023</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-0.228654</td>\n",
       "      <td>-0.722585</td>\n",
       "      <td>-0.719202</td>\n",
       "      <td>-0.169802</td>\n",
       "      <td>-0.747083</td>\n",
       "      <td>-0.426592</td>\n",
       "      <td>155.855957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003841</td>\n",
       "      <td>0.089720</td>\n",
       "      <td>0.415459</td>\n",
       "      <td>0.132267</td>\n",
       "      <td>-0.236566</td>\n",
       "      <td>-0.093649</td>\n",
       "      <td>0.513509</td>\n",
       "      <td>0.923101</td>\n",
       "      <td>-0.016988</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.919821</td>\n",
       "      <td>-0.295705</td>\n",
       "      <td>-0.104684</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>151.938278</td>\n",
       "      <td>-0.967807</td>\n",
       "      <td>-0.175356</td>\n",
       "      <td>0.570274</td>\n",
       "      <td>0.798853</td>\n",
       "      <td>0.346007</td>\n",
       "      <td>-0.166419</td>\n",
       "      <td>-0.329426</td>\n",
       "      <td>0.628206</td>\n",
       "      <td>0.318365</td>\n",
       "      <td>-0.080726</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>-0.407203</td>\n",
       "      <td>0.661895</td>\n",
       "      <td>-0.080348</td>\n",
       "      <td>-0.171800</td>\n",
       "      <td>-0.664791</td>\n",
       "      <td>1.011396</td>\n",
       "      <td>0.529122</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>-0.092283</td>\n",
       "      <td>0.843276</td>\n",
       "      <td>-0.500389</td>\n",
       "      <td>0.496417</td>\n",
       "      <td>-0.957163</td>\n",
       "      <td>-0.833386</td>\n",
       "      <td>-0.723729</td>\n",
       "      <td>0.889336</td>\n",
       "      <td>0.976312</td>\n",
       "      <td>-0.960502</td>\n",
       "      <td>-0.105648</td>\n",
       "      <td>0.353810</td>\n",
       "      <td>-0.967627</td>\n",
       "      <td>-0.769593</td>\n",
       "      <td>-0.453097</td>\n",
       "      <td>0.909475</td>\n",
       "      <td>-0.042573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001821</td>\n",
       "      <td>-0.058118</td>\n",
       "      <td>-0.396198</td>\n",
       "      <td>0.040644</td>\n",
       "      <td>-0.494280</td>\n",
       "      <td>0.817254</td>\n",
       "      <td>-0.200227</td>\n",
       "      <td>-0.172498</td>\n",
       "      <td>0.417819</td>\n",
       "      <td>-0.903633</td>\n",
       "      <td>-0.391284</td>\n",
       "      <td>0.636375</td>\n",
       "      <td>-0.840368</td>\n",
       "      <td>0.385180</td>\n",
       "      <td>0.259008</td>\n",
       "      <td>-0.016090</td>\n",
       "      <td>0.343993</td>\n",
       "      <td>0.045426</td>\n",
       "      <td>0.230074</td>\n",
       "      <td>-0.652167</td>\n",
       "      <td>-0.648913</td>\n",
       "      <td>0.345835</td>\n",
       "      <td>-0.629454</td>\n",
       "      <td>0.936892</td>\n",
       "      <td>0.309401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   D_63_CL  D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_126_1.0      D_39  \\\n",
       "0      0.0      1.0      0.0      0.0      0.0      0.0        0.0 -0.030079   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.566662   \n",
       "2      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.033107   \n",
       "3      0.0      0.0      1.0      0.0      0.0      0.0        0.0  1.984176   \n",
       "4      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.009987   \n",
       "5      1.0      0.0      0.0      0.0      0.0      0.0        1.0  2.659131   \n",
       "6      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.667602   \n",
       "7      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.016557   \n",
       "8      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.898562   \n",
       "9      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.003841   \n",
       "\n",
       "        B_1       R_1       B_4       B_5       R_2      D_47       B_7  \\\n",
       "0 -0.194353  0.578712 -0.384822 -0.142929  0.581005 -0.393345 -0.271646   \n",
       "1 -0.008937 -0.625142 -0.239551 -0.102401 -0.824745 -0.829083 -0.182771   \n",
       "2 -0.174373 -0.978577 -0.357863 -0.203055  0.140283  0.227325 -0.298821   \n",
       "3  0.037931 -0.850152 -0.215573  0.182334 -0.438968  0.203038 -0.197336   \n",
       "4 -0.208411  0.169286 -0.311881 -0.157200 -0.736100  0.424354 -0.202172   \n",
       "5  0.448053  0.067979  0.859824  0.000886  0.361719  0.616309  1.160108   \n",
       "6  5.285590  0.565360  2.831356  1.522588  0.405705  0.246889  1.031161   \n",
       "7 -0.191332 -0.737462 -0.102883 -0.156807 -0.117743  0.736112  0.644666   \n",
       "8  0.064531 -0.540586 -0.197865  2.605556  0.174905  0.026418 -0.168445   \n",
       "9  0.089720  0.415459  0.132267 -0.236566 -0.093649  0.513509  0.923101   \n",
       "\n",
       "       D_51       B_9       R_3      B_10       S_5      B_11         S_6  \\\n",
       "0 -0.007788 -0.052815 -0.011894  0.524912 -0.127970 -0.117280  152.672934   \n",
       "1 -0.003393 -0.029411 -0.037635  0.762243 -0.058611 -0.065835   -0.187174   \n",
       "2 -0.014707 -0.058253 -0.003134  0.533525 -0.100474 -0.161027  152.356448   \n",
       "3  1.987695 -0.057482  0.888322  0.665093  1.293623  0.093459    0.345464   \n",
       "4  0.007645 -0.049693 -0.065498  0.741042 -0.168080 -0.124675    0.162340   \n",
       "5  0.006057  0.281724 -0.018602 -0.270469  1.185511  0.486292   -0.094813   \n",
       "6  0.986411  1.452378  1.859874 -0.221832  8.969167  6.895579    0.204981   \n",
       "7  0.989974 -0.060050 -0.000638 -0.246507 -0.145975 -0.102455  151.518764   \n",
       "8 -0.009791  0.165908  0.924353  0.749759  2.778317  0.098288   -0.881596   \n",
       "9 -0.016988  0.029362  0.919821 -0.295705 -0.104684  0.026329  151.938278   \n",
       "\n",
       "        R_4      B_12       S_8       R_5      D_58      B_14      D_60  \\\n",
       "0  0.720555 -0.140806 -0.643897  0.750581 -0.291579 -0.221002  1.244001   \n",
       "1 -0.443022  0.185327  0.184351  0.610542 -0.281618 -0.104739 -0.208782   \n",
       "2 -0.610055 -0.189456 -0.648441  0.013534 -0.275178 -0.207605  1.244771   \n",
       "3  0.850891  4.357720  0.906308  0.353175 -0.293428  1.381102  1.139103   \n",
       "4  0.490329 -0.070819 -0.644992 -0.485652 -0.279110 -0.208335 -0.348158   \n",
       "5 -0.369142  0.918834  0.799589  0.561896  1.258619  0.865443 -0.158910   \n",
       "6 -0.520122  0.272688 -0.001977 -0.563745  1.153643  4.819905  0.475913   \n",
       "7 -0.744956 -0.161139 -0.646905  0.297287  0.853669 -0.225104 -0.348675   \n",
       "8  0.335042  1.623025  0.363794 -0.935747 -0.289912  0.539758  1.244891   \n",
       "9 -0.967807 -0.175356  0.570274  0.798853  0.346007 -0.166419 -0.329426   \n",
       "\n",
       "       S_11      D_65      B_18       S_12       R_6      S_13      B_21  \\\n",
       "0 -0.213967  0.060939  0.516491  -0.189201  0.677130 -0.007030 -0.647836   \n",
       "1  3.193557 -0.616374  0.513737   8.083164 -0.061052  0.931915  0.363911   \n",
       "2 -0.210789  0.046459  0.514890  -0.040511  0.526153 -0.017195 -0.077509   \n",
       "3  2.195266  0.380903  0.510628   1.166226 -0.162388  2.358034  0.018404   \n",
       "4 -0.197489  0.352429  0.513218   0.118718 -0.685404 -0.014224  0.626296   \n",
       "5  2.217692  3.913039 -0.665647  -0.004832 -0.786381  1.606951 -0.127500   \n",
       "6 -0.597645  0.592965 -0.611217  35.932871 -0.242534  0.993586 -0.899421   \n",
       "7 -0.180160 -0.525979  0.001058   0.215481 -0.557530 -0.021375 -0.122074   \n",
       "8 -0.800673  0.541419  0.510576  -0.343820 -0.342248  0.987543 -0.146541   \n",
       "9  0.628206  0.318365 -0.080726   0.015104 -0.407203  0.661895 -0.080348   \n",
       "\n",
       "        D_71      S_15      B_23       P_4      D_75      B_24       R_7  \\\n",
       "0  -0.233256  0.339005 -0.228037  0.371743 -0.279139 -0.521531 -0.864698   \n",
       "1  -0.200203 -0.347505 -0.160666 -0.491952 -0.270175  0.137662  0.203826   \n",
       "2   0.109168  0.342928 -0.225009  0.343578 -0.259023  0.351462 -0.530828   \n",
       "3  10.159919 -0.669296 -0.179047 -0.204001 -0.261437  0.545092  0.500036   \n",
       "4  -0.253399  0.332759 -0.209010 -0.547537 -0.275195  0.503822 -0.559253   \n",
       "5   2.361169 -0.676759  1.269687 -0.630520  2.487550  0.017016 -0.212522   \n",
       "6  -0.431931 -0.010166  1.152519  0.080905  1.730240 -0.072746 -0.413805   \n",
       "7   0.184807  0.328590  0.611173  0.496033  0.481366  0.869049 -0.337090   \n",
       "8  -0.233827 -0.345522 -0.157970  0.365298 -0.264884  0.113635 -0.484168   \n",
       "9  -0.171800 -0.664791  1.011396  0.529122 -0.010894 -0.092283  0.843276   \n",
       "\n",
       "        R_8      S_16      R_10      R_11      S_17      R_12      B_28  \\\n",
       "0  0.109204  0.377151 -0.756786  0.128584 -0.611160  0.503640 -0.441005   \n",
       "1 -0.946326  0.066443  0.610326  0.528433 -0.506065  0.158755 -0.103816   \n",
       "2 -0.134636 -0.921508 -0.938155 -0.744672 -0.641608 -0.835390 -0.421001   \n",
       "3  0.837986 -0.458745  0.078365  0.544259 -0.579326 -0.097402  0.008614   \n",
       "4 -0.895226 -0.696610 -0.435517 -0.943093 -0.064824 -0.709923 -0.351739   \n",
       "5 -0.112579 -0.036839 -0.736215  0.240692 -0.278097 -0.138879  1.855432   \n",
       "6  0.375482 -0.292448 -0.386726  0.297266  0.553135  0.879651  1.986122   \n",
       "7 -0.518525 -0.268546 -0.981103  0.034075  0.631776  0.955106  0.197413   \n",
       "8  0.891503 -0.528155  0.821282 -0.626519  0.405926  0.743717 -0.236594   \n",
       "9 -0.500389  0.496417 -0.957163 -0.833386 -0.723729  0.889336  0.976312   \n",
       "\n",
       "       R_13      R_14      R_15      R_16      S_18      D_86      R_17  \\\n",
       "0  0.876096 -0.589107 -0.102574 -0.582524  0.419583 -0.564247 -0.174935   \n",
       "1 -0.929343 -0.764254  0.463576 -0.992074  0.949096 -0.024935 -0.978841   \n",
       "2 -0.901208  0.452562  0.881577  0.214264 -0.174861 -0.106231 -0.097231   \n",
       "3 -0.390269 -0.534526  0.164324  0.643167  0.021145 -0.024452 -0.742711   \n",
       "4 -0.812298 -0.990240 -0.923232  0.405293  0.144755 -0.007410 -0.810802   \n",
       "5  0.617518 -0.505121  0.039299 -0.902163  0.807571  0.484423  0.895847   \n",
       "6  0.284422 -0.899992  0.075677  0.758974 -0.018987  0.026109 -0.418833   \n",
       "7 -0.208551  0.157094  0.693808  0.253921  0.562217 -0.446284  0.514654   \n",
       "8 -0.967426 -0.700800  0.146933  0.213592 -0.949277 -0.666110  0.235210   \n",
       "9 -0.960502 -0.105648  0.353810 -0.967627 -0.769593 -0.453097  0.909475   \n",
       "\n",
       "       R_18  B_31      S_19      R_19      B_32      S_20      R_20      R_21  \\\n",
       "0  0.232135   0.0  0.300156 -0.630990 -0.735156 -0.716060  0.304229  0.709052   \n",
       "1 -0.329449   0.0  0.302395 -0.163770 -0.294761 -0.684658  0.568481 -0.074052   \n",
       "2  0.938095   0.0 -0.037235 -0.530533  0.486548 -0.589126  0.203690  0.107670   \n",
       "3 -0.436073   0.0 -0.448375 -0.967543  0.703076  0.277079  0.811748  0.158112   \n",
       "4  0.426805   0.0  0.935423  0.849905  0.465850  0.135578 -0.133945  0.833261   \n",
       "5  0.303898   0.0 -0.779081 -0.329965 -0.634499 -0.750194 -0.876187  0.542935   \n",
       "6 -0.746122   0.0  0.133007 -0.754931 -0.693169 -0.827945  0.493280  0.938008   \n",
       "7 -0.695042   0.0  0.254033 -0.702067 -0.495289  0.883981 -0.199348  0.604370   \n",
       "8  0.447423   0.0 -0.361601 -0.150428  0.540769  0.401871 -0.832844 -0.862597   \n",
       "9 -0.042573   0.0 -0.001821 -0.058118 -0.396198  0.040644 -0.494280  0.817254   \n",
       "\n",
       "       R_22      R_23      D_92      D_93      D_94      R_24      R_25  \\\n",
       "0  0.037476 -0.960587 -0.396852  0.603038  0.875520 -0.330116  0.062894   \n",
       "1 -0.171454 -0.770602  0.217587  0.114829  0.953832 -0.274646 -0.815210   \n",
       "2  0.637974 -0.807461 -0.643628 -0.014345 -0.722370  0.114526  0.256631   \n",
       "3  0.934542  0.926036  0.628684  0.040198  0.876584 -0.556110 -0.757304   \n",
       "4 -0.069866 -0.175530 -0.267707 -0.818986 -0.171589 -0.312395  0.922094   \n",
       "5 -0.557729 -0.705906 -0.977363 -0.526665 -0.597136  0.050000  0.538592   \n",
       "6 -0.202728  0.242026  0.212631  0.861536 -0.348335 -0.959809 -0.081780   \n",
       "7 -0.463123  0.714029 -0.283412  0.511822  0.115179 -0.490476  0.713411   \n",
       "8 -0.106549  0.645137 -0.778245  0.290737 -0.086707 -0.614921  0.959553   \n",
       "9 -0.200227 -0.172498  0.417819 -0.903633 -0.391284  0.636375 -0.840368   \n",
       "\n",
       "       D_96      S_26     D_102      B_36      B_37      B_40       D_127  \\\n",
       "0 -0.693150  0.515303 -0.011467 -0.442691 -0.175864 -0.252220    0.681342   \n",
       "1  0.753606  0.272526 -0.026121  0.956390 -0.022518 -0.118569  179.589215   \n",
       "2  0.364241 -0.120702 -0.016335  0.794329 -0.182900 -0.242466   -0.857550   \n",
       "3  0.291302  8.920435  0.134475 -0.606101  0.012084 -0.182312  179.498156   \n",
       "4 -0.025609 -1.005682 -0.021132  0.414900 -0.197078 -0.171804    0.097737   \n",
       "5  0.203203  9.204380  2.767770  0.061763  0.441586  1.432246   -0.307704   \n",
       "6 -0.270257 -0.017283  0.001524  0.185647  5.419262  0.597646    0.635309   \n",
       "7  0.924921 -0.775120 -0.012685  0.738089 -0.207437 -0.150364   -0.211089   \n",
       "8 -0.481837  0.434845 -0.004620 -0.323023  0.076301 -0.228654   -0.722585   \n",
       "9  0.385180  0.259008 -0.016090  0.343993  0.045426  0.230074   -0.652167   \n",
       "\n",
       "       B_41      D_133      R_28     D_140       D_144  \n",
       "0 -0.215606   0.083272 -0.051607  0.899916   36.316310  \n",
       "1 -0.582900   0.254664 -0.715495 -0.410238    0.199063  \n",
       "2  0.673143   0.218296 -0.468812 -0.195074    0.507778  \n",
       "3 -0.715862   0.006146  0.669250 -0.645083   -0.310766  \n",
       "4  0.779770   0.773277 -0.545606  0.186408    0.465836  \n",
       "5  0.823928  -0.945595 -0.434873  0.711327   -0.798540  \n",
       "6 -0.397688  53.554505  0.303012  0.291930   -0.625848  \n",
       "7 -0.964375   0.182457  0.935750  0.747358    0.239573  \n",
       "8 -0.719202  -0.169802 -0.747083 -0.426592  155.855957  \n",
       "9 -0.648913   0.345835 -0.629454  0.936892    0.309401  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_63_CL</th>\n",
       "      <th>D_63_CO</th>\n",
       "      <th>D_63_CR</th>\n",
       "      <th>D_63_XL</th>\n",
       "      <th>D_63_XM</th>\n",
       "      <th>D_63_XZ</th>\n",
       "      <th>D_126_1.0</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>B_4</th>\n",
       "      <th>B_5</th>\n",
       "      <th>R_2</th>\n",
       "      <th>D_47</th>\n",
       "      <th>B_7</th>\n",
       "      <th>D_51</th>\n",
       "      <th>B_9</th>\n",
       "      <th>R_3</th>\n",
       "      <th>B_10</th>\n",
       "      <th>S_5</th>\n",
       "      <th>B_11</th>\n",
       "      <th>S_6</th>\n",
       "      <th>R_4</th>\n",
       "      <th>B_12</th>\n",
       "      <th>S_8</th>\n",
       "      <th>R_5</th>\n",
       "      <th>D_58</th>\n",
       "      <th>B_14</th>\n",
       "      <th>D_60</th>\n",
       "      <th>S_11</th>\n",
       "      <th>D_65</th>\n",
       "      <th>B_18</th>\n",
       "      <th>S_12</th>\n",
       "      <th>R_6</th>\n",
       "      <th>S_13</th>\n",
       "      <th>B_21</th>\n",
       "      <th>D_71</th>\n",
       "      <th>S_15</th>\n",
       "      <th>B_23</th>\n",
       "      <th>P_4</th>\n",
       "      <th>D_75</th>\n",
       "      <th>B_24</th>\n",
       "      <th>R_7</th>\n",
       "      <th>R_8</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_10</th>\n",
       "      <th>R_11</th>\n",
       "      <th>S_17</th>\n",
       "      <th>R_12</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_13</th>\n",
       "      <th>R_14</th>\n",
       "      <th>R_15</th>\n",
       "      <th>R_16</th>\n",
       "      <th>S_18</th>\n",
       "      <th>D_86</th>\n",
       "      <th>R_17</th>\n",
       "      <th>R_18</th>\n",
       "      <th>B_31</th>\n",
       "      <th>S_19</th>\n",
       "      <th>R_19</th>\n",
       "      <th>B_32</th>\n",
       "      <th>S_20</th>\n",
       "      <th>R_20</th>\n",
       "      <th>R_21</th>\n",
       "      <th>R_22</th>\n",
       "      <th>R_23</th>\n",
       "      <th>D_92</th>\n",
       "      <th>D_93</th>\n",
       "      <th>D_94</th>\n",
       "      <th>R_24</th>\n",
       "      <th>R_25</th>\n",
       "      <th>D_96</th>\n",
       "      <th>S_26</th>\n",
       "      <th>D_102</th>\n",
       "      <th>B_36</th>\n",
       "      <th>B_37</th>\n",
       "      <th>B_40</th>\n",
       "      <th>D_127</th>\n",
       "      <th>B_41</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996287</td>\n",
       "      <td>0.044366</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>-0.186904</td>\n",
       "      <td>4.658030</td>\n",
       "      <td>0.834875</td>\n",
       "      <td>1.028766</td>\n",
       "      <td>-0.168169</td>\n",
       "      <td>1.984755</td>\n",
       "      <td>-0.056415</td>\n",
       "      <td>-0.034827</td>\n",
       "      <td>0.741902</td>\n",
       "      <td>2.504043</td>\n",
       "      <td>0.035512</td>\n",
       "      <td>-0.302672</td>\n",
       "      <td>-0.162103</td>\n",
       "      <td>3.612395</td>\n",
       "      <td>0.897335</td>\n",
       "      <td>0.178103</td>\n",
       "      <td>-0.282950</td>\n",
       "      <td>1.169871</td>\n",
       "      <td>1.155816</td>\n",
       "      <td>1.181610</td>\n",
       "      <td>-0.469102</td>\n",
       "      <td>0.517604</td>\n",
       "      <td>0.042446</td>\n",
       "      <td>-0.917876</td>\n",
       "      <td>1.988939</td>\n",
       "      <td>0.085436</td>\n",
       "      <td>16.451593</td>\n",
       "      <td>-0.656091</td>\n",
       "      <td>-0.174653</td>\n",
       "      <td>-0.449109</td>\n",
       "      <td>-0.284669</td>\n",
       "      <td>-0.861673</td>\n",
       "      <td>-0.025184</td>\n",
       "      <td>-0.064856</td>\n",
       "      <td>0.492459</td>\n",
       "      <td>-0.766172</td>\n",
       "      <td>-0.116871</td>\n",
       "      <td>-0.102215</td>\n",
       "      <td>-0.314956</td>\n",
       "      <td>-0.064433</td>\n",
       "      <td>-0.199990</td>\n",
       "      <td>-0.684715</td>\n",
       "      <td>-0.510261</td>\n",
       "      <td>-0.212632</td>\n",
       "      <td>-0.377754</td>\n",
       "      <td>-0.804947</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>0.552765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.759360</td>\n",
       "      <td>-0.247751</td>\n",
       "      <td>0.862425</td>\n",
       "      <td>-0.482263</td>\n",
       "      <td>-0.601561</td>\n",
       "      <td>0.117057</td>\n",
       "      <td>-0.108683</td>\n",
       "      <td>-0.933899</td>\n",
       "      <td>185.110329</td>\n",
       "      <td>-0.663106</td>\n",
       "      <td>0.276206</td>\n",
       "      <td>-0.346441</td>\n",
       "      <td>0.362380</td>\n",
       "      <td>0.916180</td>\n",
       "      <td>7.697775</td>\n",
       "      <td>-0.009747</td>\n",
       "      <td>0.321661</td>\n",
       "      <td>0.064551</td>\n",
       "      <td>-0.209691</td>\n",
       "      <td>179.231150</td>\n",
       "      <td>-0.798256</td>\n",
       "      <td>-0.244368</td>\n",
       "      <td>0.062582</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>0.812878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.424901</td>\n",
       "      <td>-0.057480</td>\n",
       "      <td>-0.309244</td>\n",
       "      <td>-0.112085</td>\n",
       "      <td>1.832033</td>\n",
       "      <td>0.460239</td>\n",
       "      <td>1.255745</td>\n",
       "      <td>-0.171866</td>\n",
       "      <td>1.986845</td>\n",
       "      <td>0.029512</td>\n",
       "      <td>-0.027625</td>\n",
       "      <td>0.139115</td>\n",
       "      <td>1.253139</td>\n",
       "      <td>-0.061496</td>\n",
       "      <td>0.277963</td>\n",
       "      <td>-0.566108</td>\n",
       "      <td>2.149004</td>\n",
       "      <td>1.097705</td>\n",
       "      <td>-0.952127</td>\n",
       "      <td>0.192394</td>\n",
       "      <td>0.150649</td>\n",
       "      <td>-0.049668</td>\n",
       "      <td>-0.818600</td>\n",
       "      <td>0.713652</td>\n",
       "      <td>0.065541</td>\n",
       "      <td>13.586764</td>\n",
       "      <td>-0.419730</td>\n",
       "      <td>0.994242</td>\n",
       "      <td>0.112015</td>\n",
       "      <td>-0.418729</td>\n",
       "      <td>-0.988376</td>\n",
       "      <td>-0.142139</td>\n",
       "      <td>163.714800</td>\n",
       "      <td>-0.012479</td>\n",
       "      <td>-0.083920</td>\n",
       "      <td>-0.134584</td>\n",
       "      <td>-0.065424</td>\n",
       "      <td>-0.872420</td>\n",
       "      <td>-0.503379</td>\n",
       "      <td>-0.335352</td>\n",
       "      <td>0.516931</td>\n",
       "      <td>-0.847583</td>\n",
       "      <td>0.095987</td>\n",
       "      <td>0.433340</td>\n",
       "      <td>0.844210</td>\n",
       "      <td>-0.376106</td>\n",
       "      <td>-0.457564</td>\n",
       "      <td>-0.636278</td>\n",
       "      <td>-0.534196</td>\n",
       "      <td>-0.150334</td>\n",
       "      <td>0.159996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261688</td>\n",
       "      <td>-0.432966</td>\n",
       "      <td>-0.473895</td>\n",
       "      <td>0.885901</td>\n",
       "      <td>0.065269</td>\n",
       "      <td>-0.265344</td>\n",
       "      <td>0.392485</td>\n",
       "      <td>-0.005997</td>\n",
       "      <td>-0.847344</td>\n",
       "      <td>-0.355057</td>\n",
       "      <td>0.758756</td>\n",
       "      <td>-0.703034</td>\n",
       "      <td>0.567717</td>\n",
       "      <td>-0.800869</td>\n",
       "      <td>16.129256</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>-0.069284</td>\n",
       "      <td>-0.143428</td>\n",
       "      <td>-0.503888</td>\n",
       "      <td>0.415064</td>\n",
       "      <td>-0.172199</td>\n",
       "      <td>-0.464009</td>\n",
       "      <td>-0.765897</td>\n",
       "      <td>0.286217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.192458</td>\n",
       "      <td>-0.815902</td>\n",
       "      <td>-0.208114</td>\n",
       "      <td>-0.228899</td>\n",
       "      <td>0.304369</td>\n",
       "      <td>0.553088</td>\n",
       "      <td>-0.187201</td>\n",
       "      <td>-0.019175</td>\n",
       "      <td>-0.059288</td>\n",
       "      <td>-0.036357</td>\n",
       "      <td>0.737597</td>\n",
       "      <td>-0.181771</td>\n",
       "      <td>-0.160577</td>\n",
       "      <td>151.614678</td>\n",
       "      <td>-0.775592</td>\n",
       "      <td>-0.061991</td>\n",
       "      <td>-0.648866</td>\n",
       "      <td>-0.300081</td>\n",
       "      <td>-0.274546</td>\n",
       "      <td>-0.215267</td>\n",
       "      <td>-0.348737</td>\n",
       "      <td>-0.183773</td>\n",
       "      <td>0.195372</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.078681</td>\n",
       "      <td>-0.868145</td>\n",
       "      <td>-0.015827</td>\n",
       "      <td>0.698191</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>0.344416</td>\n",
       "      <td>-0.196133</td>\n",
       "      <td>0.206875</td>\n",
       "      <td>-0.259511</td>\n",
       "      <td>-0.812935</td>\n",
       "      <td>-0.403809</td>\n",
       "      <td>-0.293777</td>\n",
       "      <td>0.712885</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.087007</td>\n",
       "      <td>0.072649</td>\n",
       "      <td>-0.414567</td>\n",
       "      <td>-0.141943</td>\n",
       "      <td>-0.234067</td>\n",
       "      <td>-0.237830</td>\n",
       "      <td>0.425401</td>\n",
       "      <td>0.762231</td>\n",
       "      <td>0.167746</td>\n",
       "      <td>0.712379</td>\n",
       "      <td>0.534048</td>\n",
       "      <td>-0.400201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420047</td>\n",
       "      <td>0.842868</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>-0.611975</td>\n",
       "      <td>-0.996524</td>\n",
       "      <td>-0.998043</td>\n",
       "      <td>-0.538360</td>\n",
       "      <td>-0.749037</td>\n",
       "      <td>-0.624288</td>\n",
       "      <td>0.417245</td>\n",
       "      <td>0.092623</td>\n",
       "      <td>-0.700463</td>\n",
       "      <td>0.033805</td>\n",
       "      <td>-0.047896</td>\n",
       "      <td>0.141676</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>-0.120814</td>\n",
       "      <td>-0.206114</td>\n",
       "      <td>-0.171145</td>\n",
       "      <td>0.551678</td>\n",
       "      <td>-0.813501</td>\n",
       "      <td>-0.708440</td>\n",
       "      <td>0.824055</td>\n",
       "      <td>-0.030353</td>\n",
       "      <td>-0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>0.480596</td>\n",
       "      <td>0.220609</td>\n",
       "      <td>0.235523</td>\n",
       "      <td>-0.119380</td>\n",
       "      <td>0.782134</td>\n",
       "      <td>-0.398871</td>\n",
       "      <td>0.180826</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>1.383214</td>\n",
       "      <td>-0.011860</td>\n",
       "      <td>-0.163127</td>\n",
       "      <td>0.194091</td>\n",
       "      <td>0.472865</td>\n",
       "      <td>152.238594</td>\n",
       "      <td>-0.242742</td>\n",
       "      <td>-0.071025</td>\n",
       "      <td>-0.293853</td>\n",
       "      <td>-0.275111</td>\n",
       "      <td>1.272444</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>-0.243468</td>\n",
       "      <td>-1.018712</td>\n",
       "      <td>-0.515040</td>\n",
       "      <td>-0.004645</td>\n",
       "      <td>-0.373114</td>\n",
       "      <td>-0.031730</td>\n",
       "      <td>0.976516</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>-0.012825</td>\n",
       "      <td>2.359810</td>\n",
       "      <td>0.209497</td>\n",
       "      <td>0.582542</td>\n",
       "      <td>2.255548</td>\n",
       "      <td>-0.902608</td>\n",
       "      <td>-0.675243</td>\n",
       "      <td>0.397748</td>\n",
       "      <td>-0.259936</td>\n",
       "      <td>-0.219300</td>\n",
       "      <td>0.230296</td>\n",
       "      <td>-0.438565</td>\n",
       "      <td>-0.754276</td>\n",
       "      <td>0.394081</td>\n",
       "      <td>-0.521084</td>\n",
       "      <td>0.413113</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>-0.856618</td>\n",
       "      <td>-0.495383</td>\n",
       "      <td>0.198037</td>\n",
       "      <td>-0.811499</td>\n",
       "      <td>-0.857042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.618032</td>\n",
       "      <td>0.255354</td>\n",
       "      <td>-0.913557</td>\n",
       "      <td>0.081917</td>\n",
       "      <td>0.683271</td>\n",
       "      <td>-0.598286</td>\n",
       "      <td>0.607920</td>\n",
       "      <td>0.194571</td>\n",
       "      <td>-0.943997</td>\n",
       "      <td>0.774461</td>\n",
       "      <td>0.645457</td>\n",
       "      <td>0.684008</td>\n",
       "      <td>0.118329</td>\n",
       "      <td>-0.320696</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>-0.538927</td>\n",
       "      <td>0.562077</td>\n",
       "      <td>0.179704</td>\n",
       "      <td>-0.810349</td>\n",
       "      <td>0.453933</td>\n",
       "      <td>-0.557300</td>\n",
       "      <td>-0.940495</td>\n",
       "      <td>-0.630348</td>\n",
       "      <td>-0.690617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.454174</td>\n",
       "      <td>-0.009752</td>\n",
       "      <td>0.542798</td>\n",
       "      <td>0.337619</td>\n",
       "      <td>1.080671</td>\n",
       "      <td>-0.465420</td>\n",
       "      <td>1.425864</td>\n",
       "      <td>0.157638</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>-0.059246</td>\n",
       "      <td>-0.012104</td>\n",
       "      <td>-0.008111</td>\n",
       "      <td>2.667567</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.506624</td>\n",
       "      <td>0.247375</td>\n",
       "      <td>1.772522</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>-0.201456</td>\n",
       "      <td>0.125034</td>\n",
       "      <td>0.301681</td>\n",
       "      <td>-0.105077</td>\n",
       "      <td>-0.188614</td>\n",
       "      <td>0.163518</td>\n",
       "      <td>-0.005146</td>\n",
       "      <td>7.480183</td>\n",
       "      <td>0.439340</td>\n",
       "      <td>0.980600</td>\n",
       "      <td>-0.321833</td>\n",
       "      <td>8.240606</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.178392</td>\n",
       "      <td>-0.857783</td>\n",
       "      <td>0.230844</td>\n",
       "      <td>-0.611120</td>\n",
       "      <td>0.499622</td>\n",
       "      <td>0.510118</td>\n",
       "      <td>-0.740287</td>\n",
       "      <td>0.756835</td>\n",
       "      <td>-0.075922</td>\n",
       "      <td>-0.211905</td>\n",
       "      <td>0.949999</td>\n",
       "      <td>0.532028</td>\n",
       "      <td>0.419504</td>\n",
       "      <td>0.057190</td>\n",
       "      <td>0.531299</td>\n",
       "      <td>-0.124721</td>\n",
       "      <td>0.437617</td>\n",
       "      <td>-0.267050</td>\n",
       "      <td>-0.131357</td>\n",
       "      <td>-0.504973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702447</td>\n",
       "      <td>0.455753</td>\n",
       "      <td>0.235937</td>\n",
       "      <td>0.300714</td>\n",
       "      <td>0.865828</td>\n",
       "      <td>-0.655947</td>\n",
       "      <td>0.415048</td>\n",
       "      <td>-0.972326</td>\n",
       "      <td>0.514081</td>\n",
       "      <td>-0.901579</td>\n",
       "      <td>0.904772</td>\n",
       "      <td>0.103044</td>\n",
       "      <td>-0.848928</td>\n",
       "      <td>-0.421799</td>\n",
       "      <td>3.983588</td>\n",
       "      <td>-0.005015</td>\n",
       "      <td>-0.464634</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>1.626139</td>\n",
       "      <td>-0.513714</td>\n",
       "      <td>0.170901</td>\n",
       "      <td>-0.498938</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.603922</td>\n",
       "      <td>-0.004369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102783</td>\n",
       "      <td>1.788111</td>\n",
       "      <td>41.932788</td>\n",
       "      <td>3.176767</td>\n",
       "      <td>4.797061</td>\n",
       "      <td>0.125443</td>\n",
       "      <td>0.355532</td>\n",
       "      <td>1.297939</td>\n",
       "      <td>1.998126</td>\n",
       "      <td>1.476048</td>\n",
       "      <td>1.866804</td>\n",
       "      <td>-0.302274</td>\n",
       "      <td>7.054234</td>\n",
       "      <td>2.481852</td>\n",
       "      <td>-0.596803</td>\n",
       "      <td>-0.166410</td>\n",
       "      <td>2.324893</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>0.432603</td>\n",
       "      <td>0.963231</td>\n",
       "      <td>7.993588</td>\n",
       "      <td>0.303585</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>-0.277433</td>\n",
       "      <td>-0.735194</td>\n",
       "      <td>28.699962</td>\n",
       "      <td>0.503154</td>\n",
       "      <td>0.990975</td>\n",
       "      <td>-0.461641</td>\n",
       "      <td>-0.234507</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>1.582337</td>\n",
       "      <td>0.463565</td>\n",
       "      <td>1.231769</td>\n",
       "      <td>-0.647970</td>\n",
       "      <td>-0.984526</td>\n",
       "      <td>-0.680164</td>\n",
       "      <td>-0.415780</td>\n",
       "      <td>-0.007986</td>\n",
       "      <td>0.507563</td>\n",
       "      <td>0.243538</td>\n",
       "      <td>-0.862674</td>\n",
       "      <td>4.752257</td>\n",
       "      <td>-0.364441</td>\n",
       "      <td>-0.043502</td>\n",
       "      <td>0.518970</td>\n",
       "      <td>0.297982</td>\n",
       "      <td>0.134232</td>\n",
       "      <td>-0.090623</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>-0.171879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.765073</td>\n",
       "      <td>196.909390</td>\n",
       "      <td>-0.811619</td>\n",
       "      <td>0.619618</td>\n",
       "      <td>-0.871096</td>\n",
       "      <td>-0.528703</td>\n",
       "      <td>-0.533627</td>\n",
       "      <td>0.728674</td>\n",
       "      <td>-0.444351</td>\n",
       "      <td>-0.376107</td>\n",
       "      <td>0.822036</td>\n",
       "      <td>0.657160</td>\n",
       "      <td>0.657401</td>\n",
       "      <td>0.193351</td>\n",
       "      <td>0.513024</td>\n",
       "      <td>0.102160</td>\n",
       "      <td>-0.010612</td>\n",
       "      <td>1.863122</td>\n",
       "      <td>1.919145</td>\n",
       "      <td>-0.091340</td>\n",
       "      <td>0.625160</td>\n",
       "      <td>105.494513</td>\n",
       "      <td>0.909654</td>\n",
       "      <td>0.432224</td>\n",
       "      <td>0.815222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.015498</td>\n",
       "      <td>-0.204442</td>\n",
       "      <td>0.208937</td>\n",
       "      <td>-0.277039</td>\n",
       "      <td>-0.212471</td>\n",
       "      <td>-0.091549</td>\n",
       "      <td>0.293356</td>\n",
       "      <td>-0.193583</td>\n",
       "      <td>-0.013363</td>\n",
       "      <td>-0.060523</td>\n",
       "      <td>-0.055132</td>\n",
       "      <td>0.752844</td>\n",
       "      <td>-0.155758</td>\n",
       "      <td>-0.147721</td>\n",
       "      <td>152.728431</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>-0.182534</td>\n",
       "      <td>-0.654547</td>\n",
       "      <td>-0.385891</td>\n",
       "      <td>-0.293018</td>\n",
       "      <td>-0.246545</td>\n",
       "      <td>-0.355444</td>\n",
       "      <td>-0.182572</td>\n",
       "      <td>0.630667</td>\n",
       "      <td>0.508351</td>\n",
       "      <td>-0.117438</td>\n",
       "      <td>0.647314</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>-0.167580</td>\n",
       "      <td>0.078750</td>\n",
       "      <td>0.333606</td>\n",
       "      <td>-0.195449</td>\n",
       "      <td>0.360111</td>\n",
       "      <td>-0.276879</td>\n",
       "      <td>-0.184449</td>\n",
       "      <td>-0.274039</td>\n",
       "      <td>-0.336232</td>\n",
       "      <td>-0.674084</td>\n",
       "      <td>0.203942</td>\n",
       "      <td>-0.589312</td>\n",
       "      <td>-0.083162</td>\n",
       "      <td>0.944363</td>\n",
       "      <td>-0.323670</td>\n",
       "      <td>0.738254</td>\n",
       "      <td>-0.354968</td>\n",
       "      <td>-0.455762</td>\n",
       "      <td>-0.101913</td>\n",
       "      <td>0.711684</td>\n",
       "      <td>0.874076</td>\n",
       "      <td>-0.804976</td>\n",
       "      <td>-0.931097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.773818</td>\n",
       "      <td>0.550227</td>\n",
       "      <td>0.543620</td>\n",
       "      <td>-0.232965</td>\n",
       "      <td>-0.549089</td>\n",
       "      <td>-0.756496</td>\n",
       "      <td>-0.545826</td>\n",
       "      <td>-0.906501</td>\n",
       "      <td>0.548257</td>\n",
       "      <td>-0.280471</td>\n",
       "      <td>-0.139456</td>\n",
       "      <td>0.936206</td>\n",
       "      <td>-0.126965</td>\n",
       "      <td>-0.160732</td>\n",
       "      <td>-0.355366</td>\n",
       "      <td>-0.016377</td>\n",
       "      <td>-0.493889</td>\n",
       "      <td>-0.161673</td>\n",
       "      <td>-0.146237</td>\n",
       "      <td>-0.347619</td>\n",
       "      <td>0.448352</td>\n",
       "      <td>-0.154504</td>\n",
       "      <td>-0.901717</td>\n",
       "      <td>-0.722758</td>\n",
       "      <td>0.666239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.906835</td>\n",
       "      <td>0.075130</td>\n",
       "      <td>-0.201672</td>\n",
       "      <td>0.119533</td>\n",
       "      <td>17.154675</td>\n",
       "      <td>0.319634</td>\n",
       "      <td>-0.070756</td>\n",
       "      <td>-0.060440</td>\n",
       "      <td>0.984920</td>\n",
       "      <td>-0.055513</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>0.372289</td>\n",
       "      <td>3.333877</td>\n",
       "      <td>0.071811</td>\n",
       "      <td>-0.808890</td>\n",
       "      <td>-0.036662</td>\n",
       "      <td>3.782359</td>\n",
       "      <td>-0.305818</td>\n",
       "      <td>-0.402133</td>\n",
       "      <td>0.278847</td>\n",
       "      <td>1.373787</td>\n",
       "      <td>0.384747</td>\n",
       "      <td>1.377680</td>\n",
       "      <td>0.365446</td>\n",
       "      <td>-0.004462</td>\n",
       "      <td>6.085311</td>\n",
       "      <td>-0.873839</td>\n",
       "      <td>1.991267</td>\n",
       "      <td>0.589845</td>\n",
       "      <td>17.627465</td>\n",
       "      <td>0.339553</td>\n",
       "      <td>-0.052074</td>\n",
       "      <td>-0.482541</td>\n",
       "      <td>-0.024955</td>\n",
       "      <td>0.091510</td>\n",
       "      <td>0.551536</td>\n",
       "      <td>-0.909977</td>\n",
       "      <td>-0.626296</td>\n",
       "      <td>0.872338</td>\n",
       "      <td>-0.160638</td>\n",
       "      <td>0.868030</td>\n",
       "      <td>-0.587285</td>\n",
       "      <td>0.463981</td>\n",
       "      <td>0.271653</td>\n",
       "      <td>-0.394314</td>\n",
       "      <td>-0.915415</td>\n",
       "      <td>0.323303</td>\n",
       "      <td>0.455209</td>\n",
       "      <td>-0.831061</td>\n",
       "      <td>-0.355587</td>\n",
       "      <td>-0.437348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106624</td>\n",
       "      <td>0.046953</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>-0.775752</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.440295</td>\n",
       "      <td>-0.985739</td>\n",
       "      <td>-0.817625</td>\n",
       "      <td>184.087169</td>\n",
       "      <td>-0.685116</td>\n",
       "      <td>0.596425</td>\n",
       "      <td>0.587057</td>\n",
       "      <td>0.558693</td>\n",
       "      <td>0.346084</td>\n",
       "      <td>28.226339</td>\n",
       "      <td>0.340048</td>\n",
       "      <td>0.017044</td>\n",
       "      <td>0.065338</td>\n",
       "      <td>0.547835</td>\n",
       "      <td>-0.436280</td>\n",
       "      <td>-0.413149</td>\n",
       "      <td>-0.098672</td>\n",
       "      <td>-0.136547</td>\n",
       "      <td>-0.499212</td>\n",
       "      <td>-0.501198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.012517</td>\n",
       "      <td>3.299001</td>\n",
       "      <td>-0.639011</td>\n",
       "      <td>1.706389</td>\n",
       "      <td>1.986045</td>\n",
       "      <td>0.299762</td>\n",
       "      <td>-0.272525</td>\n",
       "      <td>1.788369</td>\n",
       "      <td>-0.017721</td>\n",
       "      <td>0.731293</td>\n",
       "      <td>-0.081999</td>\n",
       "      <td>-0.309167</td>\n",
       "      <td>3.222006</td>\n",
       "      <td>3.796911</td>\n",
       "      <td>0.077272</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>-0.115962</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>-0.018412</td>\n",
       "      <td>-0.013377</td>\n",
       "      <td>1.333675</td>\n",
       "      <td>0.447927</td>\n",
       "      <td>-0.574359</td>\n",
       "      <td>-0.144098</td>\n",
       "      <td>-0.548608</td>\n",
       "      <td>0.199729</td>\n",
       "      <td>0.617746</td>\n",
       "      <td>-0.013012</td>\n",
       "      <td>-0.369092</td>\n",
       "      <td>-0.324843</td>\n",
       "      <td>-0.337784</td>\n",
       "      <td>1.797904</td>\n",
       "      <td>-0.542189</td>\n",
       "      <td>0.247878</td>\n",
       "      <td>-0.484490</td>\n",
       "      <td>-0.170783</td>\n",
       "      <td>0.431233</td>\n",
       "      <td>-0.982591</td>\n",
       "      <td>-0.858350</td>\n",
       "      <td>-0.566265</td>\n",
       "      <td>-0.350588</td>\n",
       "      <td>0.152406</td>\n",
       "      <td>0.410202</td>\n",
       "      <td>-0.707911</td>\n",
       "      <td>0.054654</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.187564</td>\n",
       "      <td>0.655305</td>\n",
       "      <td>-0.690996</td>\n",
       "      <td>0.793032</td>\n",
       "      <td>0.859696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.942567</td>\n",
       "      <td>0.646986</td>\n",
       "      <td>0.140980</td>\n",
       "      <td>-0.454837</td>\n",
       "      <td>-0.862895</td>\n",
       "      <td>-0.691078</td>\n",
       "      <td>-0.237546</td>\n",
       "      <td>0.127526</td>\n",
       "      <td>0.779789</td>\n",
       "      <td>-0.611857</td>\n",
       "      <td>0.098089</td>\n",
       "      <td>0.711350</td>\n",
       "      <td>0.635825</td>\n",
       "      <td>-0.845828</td>\n",
       "      <td>0.123187</td>\n",
       "      <td>0.324134</td>\n",
       "      <td>-0.458618</td>\n",
       "      <td>3.425436</td>\n",
       "      <td>9.478719</td>\n",
       "      <td>0.295298</td>\n",
       "      <td>0.906533</td>\n",
       "      <td>-0.342997</td>\n",
       "      <td>-0.783628</td>\n",
       "      <td>0.307807</td>\n",
       "      <td>0.268315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.458655</td>\n",
       "      <td>4.092299</td>\n",
       "      <td>83.332066</td>\n",
       "      <td>-0.241115</td>\n",
       "      <td>-0.238378</td>\n",
       "      <td>-0.200400</td>\n",
       "      <td>1.611819</td>\n",
       "      <td>1.851060</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>-0.067584</td>\n",
       "      <td>1.905397</td>\n",
       "      <td>-0.355954</td>\n",
       "      <td>3.172913</td>\n",
       "      <td>4.257299</td>\n",
       "      <td>151.474301</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>-0.275673</td>\n",
       "      <td>0.305614</td>\n",
       "      <td>0.525677</td>\n",
       "      <td>-0.278458</td>\n",
       "      <td>0.423319</td>\n",
       "      <td>1.251206</td>\n",
       "      <td>2.393177</td>\n",
       "      <td>0.766473</td>\n",
       "      <td>-0.316807</td>\n",
       "      <td>115.271557</td>\n",
       "      <td>0.260143</td>\n",
       "      <td>1.303173</td>\n",
       "      <td>-0.132778</td>\n",
       "      <td>-0.243185</td>\n",
       "      <td>-0.320862</td>\n",
       "      <td>1.474199</td>\n",
       "      <td>165.681457</td>\n",
       "      <td>-0.281890</td>\n",
       "      <td>-0.618098</td>\n",
       "      <td>-0.281958</td>\n",
       "      <td>-0.747269</td>\n",
       "      <td>-0.768353</td>\n",
       "      <td>186.671058</td>\n",
       "      <td>0.120028</td>\n",
       "      <td>0.326926</td>\n",
       "      <td>-0.171937</td>\n",
       "      <td>-0.267359</td>\n",
       "      <td>0.260646</td>\n",
       "      <td>0.323245</td>\n",
       "      <td>0.174349</td>\n",
       "      <td>93.142942</td>\n",
       "      <td>-0.226509</td>\n",
       "      <td>-0.376258</td>\n",
       "      <td>0.350263</td>\n",
       "      <td>-0.871769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411795</td>\n",
       "      <td>-0.569150</td>\n",
       "      <td>0.464777</td>\n",
       "      <td>-0.320411</td>\n",
       "      <td>0.410716</td>\n",
       "      <td>-0.156419</td>\n",
       "      <td>-0.815382</td>\n",
       "      <td>0.743960</td>\n",
       "      <td>0.784721</td>\n",
       "      <td>-0.899253</td>\n",
       "      <td>-0.102906</td>\n",
       "      <td>0.881609</td>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.461516</td>\n",
       "      <td>0.061326</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.187048</td>\n",
       "      <td>4.280495</td>\n",
       "      <td>-0.238612</td>\n",
       "      <td>0.509863</td>\n",
       "      <td>0.434160</td>\n",
       "      <td>-0.462045</td>\n",
       "      <td>-0.320133</td>\n",
       "      <td>-0.855815</td>\n",
       "      <td>0.518931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   D_63_CL  D_63_CO  D_63_CR  D_63_XL  D_63_XM  D_63_XZ  D_126_1.0      D_39  \\\n",
       "0      0.0      0.0      1.0      0.0      0.0      0.0        0.0  0.996287   \n",
       "1      0.0      1.0      0.0      0.0      0.0      0.0        1.0  1.424901   \n",
       "2      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.004943   \n",
       "3      0.0      1.0      0.0      0.0      0.0      0.0        1.0  0.084183   \n",
       "4      0.0      0.0      1.0      0.0      0.0      0.0        1.0  1.454174   \n",
       "5      1.0      0.0      0.0      0.0      0.0      0.0        1.0  0.102783   \n",
       "6      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.015498   \n",
       "7      0.0      0.0      1.0      0.0      0.0      0.0        1.0  1.906835   \n",
       "8      0.0      1.0      0.0      0.0      0.0      0.0        1.0 -0.012517   \n",
       "9      0.0      0.0      1.0      0.0      0.0      0.0        0.0  3.458655   \n",
       "\n",
       "        B_1        R_1       B_4        B_5       R_2      D_47       B_7  \\\n",
       "0  0.044366   0.019767 -0.186904   4.658030  0.834875  1.028766 -0.168169   \n",
       "1 -0.057480  -0.309244 -0.112085   1.832033  0.460239  1.255745 -0.171866   \n",
       "2 -0.192458  -0.815902 -0.208114  -0.228899  0.304369  0.553088 -0.187201   \n",
       "3  0.480596   0.220609  0.235523  -0.119380  0.782134 -0.398871  0.180826   \n",
       "4 -0.009752   0.542798  0.337619   1.080671 -0.465420  1.425864  0.157638   \n",
       "5  1.788111  41.932788  3.176767   4.797061  0.125443  0.355532  1.297939   \n",
       "6 -0.204442   0.208937 -0.277039  -0.212471 -0.091549  0.293356 -0.193583   \n",
       "7  0.075130  -0.201672  0.119533  17.154675  0.319634 -0.070756 -0.060440   \n",
       "8  3.299001  -0.639011  1.706389   1.986045  0.299762 -0.272525  1.788369   \n",
       "9  4.092299  83.332066 -0.241115  -0.238378 -0.200400  1.611819  1.851060   \n",
       "\n",
       "       D_51       B_9       R_3      B_10       S_5      B_11         S_6  \\\n",
       "0  1.984755 -0.056415 -0.034827  0.741902  2.504043  0.035512   -0.302672   \n",
       "1  1.986845  0.029512 -0.027625  0.139115  1.253139 -0.061496    0.277963   \n",
       "2 -0.019175 -0.059288 -0.036357  0.737597 -0.181771 -0.160577  151.614678   \n",
       "3  0.006784  1.383214 -0.011860 -0.163127  0.194091  0.472865  152.238594   \n",
       "4 -0.003987 -0.059246 -0.012104 -0.008111  2.667567  0.002113    0.506624   \n",
       "5  1.998126  1.476048  1.866804 -0.302274  7.054234  2.481852   -0.596803   \n",
       "6 -0.013363 -0.060523 -0.055132  0.752844 -0.155758 -0.147721  152.728431   \n",
       "7  0.984920 -0.055513  0.003769  0.372289  3.333877  0.071811   -0.808890   \n",
       "8 -0.017721  0.731293 -0.081999 -0.309167  3.222006  3.796911    0.077272   \n",
       "9  0.001252 -0.067584  1.905397 -0.355954  3.172913  4.257299  151.474301   \n",
       "\n",
       "        R_4      B_12       S_8       R_5      D_58      B_14      D_60  \\\n",
       "0 -0.162103  3.612395  0.897335  0.178103 -0.282950  1.169871  1.155816   \n",
       "1 -0.566108  2.149004  1.097705 -0.952127  0.192394  0.150649 -0.049668   \n",
       "2 -0.775592 -0.061991 -0.648866 -0.300081 -0.274546 -0.215267 -0.348737   \n",
       "3 -0.242742 -0.071025 -0.293853 -0.275111  1.272444  0.009259 -0.243468   \n",
       "4  0.247375  1.772522  0.006220 -0.201456  0.125034  0.301681 -0.105077   \n",
       "5 -0.166410  2.324893 -0.000694  0.432603  0.963231  7.993588  0.303585   \n",
       "6  0.017972 -0.182534 -0.654547 -0.385891 -0.293018 -0.246545 -0.355444   \n",
       "7 -0.036662  3.782359 -0.305818 -0.402133  0.278847  1.373787  0.384747   \n",
       "8  0.038534 -0.115962  0.011634 -0.018412 -0.013377  1.333675  0.447927   \n",
       "9  0.759398 -0.275673  0.305614  0.525677 -0.278458  0.423319  1.251206   \n",
       "\n",
       "       S_11      D_65      B_18        S_12       R_6      S_13      B_21  \\\n",
       "0  1.181610 -0.469102  0.517604    0.042446 -0.917876  1.988939  0.085436   \n",
       "1 -0.818600  0.713652  0.065541   13.586764 -0.419730  0.994242  0.112015   \n",
       "2 -0.183773  0.195372  0.511628    0.078681 -0.868145 -0.015827  0.698191   \n",
       "3 -1.018712 -0.515040 -0.004645   -0.373114 -0.031730  0.976516  0.050601   \n",
       "4 -0.188614  0.163518 -0.005146    7.480183  0.439340  0.980600 -0.321833   \n",
       "5  0.002213 -0.277433 -0.735194   28.699962  0.503154  0.990975 -0.461641   \n",
       "6 -0.182572  0.630667  0.508351   -0.117438  0.647314 -0.007935 -0.167580   \n",
       "7  1.377680  0.365446 -0.004462    6.085311 -0.873839  1.991267  0.589845   \n",
       "8 -0.574359 -0.144098 -0.548608    0.199729  0.617746 -0.013012 -0.369092   \n",
       "9  2.393177  0.766473 -0.316807  115.271557  0.260143  1.303173 -0.132778   \n",
       "\n",
       "        D_71      S_15      B_23         P_4      D_75      B_24       R_7  \\\n",
       "0  16.451593 -0.656091 -0.174653   -0.449109 -0.284669 -0.861673 -0.025184   \n",
       "1  -0.418729 -0.988376 -0.142139  163.714800 -0.012479 -0.083920 -0.134584   \n",
       "2  -0.006470  0.344416 -0.196133    0.206875 -0.259511 -0.812935 -0.403809   \n",
       "3  -0.012825  2.359810  0.209497    0.582542  2.255548 -0.902608 -0.675243   \n",
       "4   8.240606  0.004420  0.178392   -0.857783  0.230844 -0.611120  0.499622   \n",
       "5  -0.234507  0.002689  1.582337    0.463565  1.231769 -0.647970 -0.984526   \n",
       "6   0.078750  0.333606 -0.195449    0.360111 -0.276879 -0.184449 -0.274039   \n",
       "7  17.627465  0.339553 -0.052074   -0.482541 -0.024955  0.091510  0.551536   \n",
       "8  -0.324843 -0.337784  1.797904   -0.542189  0.247878 -0.484490 -0.170783   \n",
       "9  -0.243185 -0.320862  1.474199  165.681457 -0.281890 -0.618098 -0.281958   \n",
       "\n",
       "        R_8      S_16        R_10      R_11      S_17      R_12      B_28  \\\n",
       "0 -0.064856  0.492459   -0.766172 -0.116871 -0.102215 -0.314956 -0.064433   \n",
       "1 -0.065424 -0.872420   -0.503379 -0.335352  0.516931 -0.847583  0.095987   \n",
       "2 -0.293777  0.712885   -0.012892  0.087007  0.072649 -0.414567 -0.141943   \n",
       "3  0.397748 -0.259936   -0.219300  0.230296 -0.438565 -0.754276  0.394081   \n",
       "4  0.510118 -0.740287    0.756835 -0.075922 -0.211905  0.949999  0.532028   \n",
       "5 -0.680164 -0.415780   -0.007986  0.507563  0.243538 -0.862674  4.752257   \n",
       "6 -0.336232 -0.674084    0.203942 -0.589312 -0.083162  0.944363 -0.323670   \n",
       "7 -0.909977 -0.626296    0.872338 -0.160638  0.868030 -0.587285  0.463981   \n",
       "8  0.431233 -0.982591   -0.858350 -0.566265 -0.350588  0.152406  0.410202   \n",
       "9 -0.747269 -0.768353  186.671058  0.120028  0.326926 -0.171937 -0.267359   \n",
       "\n",
       "       R_13      R_14      R_15       R_16      S_18      D_86      R_17  \\\n",
       "0 -0.199990 -0.684715 -0.510261  -0.212632 -0.377754 -0.804947  0.051694   \n",
       "1  0.433340  0.844210 -0.376106  -0.457564 -0.636278 -0.534196 -0.150334   \n",
       "2 -0.234067 -0.237830  0.425401   0.762231  0.167746  0.712379  0.534048   \n",
       "3 -0.521084  0.413113  0.020533  -0.856618 -0.495383  0.198037 -0.811499   \n",
       "4  0.419504  0.057190  0.531299  -0.124721  0.437617 -0.267050 -0.131357   \n",
       "5 -0.364441 -0.043502  0.518970   0.297982  0.134232 -0.090623 -0.059550   \n",
       "6  0.738254 -0.354968 -0.455762  -0.101913  0.711684  0.874076 -0.804976   \n",
       "7  0.271653 -0.394314 -0.915415   0.323303  0.455209 -0.831061 -0.355587   \n",
       "8 -0.707911  0.054654 -0.003798  -0.187564  0.655305 -0.690996  0.793032   \n",
       "9  0.260646  0.323245  0.174349  93.142942 -0.226509 -0.376258  0.350263   \n",
       "\n",
       "       R_18  B_31      S_19        R_19      B_32      S_20      R_20  \\\n",
       "0  0.552765   0.0 -0.759360   -0.247751  0.862425 -0.482263 -0.601561   \n",
       "1  0.159996   0.0  0.261688   -0.432966 -0.473895  0.885901  0.065269   \n",
       "2 -0.400201   0.0  0.420047    0.842868  0.782351 -0.611975 -0.996524   \n",
       "3 -0.857042   0.0  0.395736    0.618032  0.255354 -0.913557  0.081917   \n",
       "4 -0.504973   0.0  0.702447    0.455753  0.235937  0.300714  0.865828   \n",
       "5 -0.171879   0.0 -0.765073  196.909390 -0.811619  0.619618 -0.871096   \n",
       "6 -0.931097   0.0 -0.773818    0.550227  0.543620 -0.232965 -0.549089   \n",
       "7 -0.437348   0.0  0.106624    0.046953  0.141789 -0.775752  0.001797   \n",
       "8  0.859696   0.0 -0.942567    0.646986  0.140980 -0.454837 -0.862895   \n",
       "9 -0.871769   0.0  0.411795   -0.569150  0.464777 -0.320411  0.410716   \n",
       "\n",
       "       R_21      R_22      R_23        D_92      D_93      D_94      R_24  \\\n",
       "0  0.117057 -0.108683 -0.933899  185.110329 -0.663106  0.276206 -0.346441   \n",
       "1 -0.265344  0.392485 -0.005997   -0.847344 -0.355057  0.758756 -0.703034   \n",
       "2 -0.998043 -0.538360 -0.749037   -0.624288  0.417245  0.092623 -0.700463   \n",
       "3  0.683271 -0.598286  0.607920    0.194571 -0.943997  0.774461  0.645457   \n",
       "4 -0.655947  0.415048 -0.972326    0.514081 -0.901579  0.904772  0.103044   \n",
       "5 -0.528703 -0.533627  0.728674   -0.444351 -0.376107  0.822036  0.657160   \n",
       "6 -0.756496 -0.545826 -0.906501    0.548257 -0.280471 -0.139456  0.936206   \n",
       "7  0.440295 -0.985739 -0.817625  184.087169 -0.685116  0.596425  0.587057   \n",
       "8 -0.691078 -0.237546  0.127526    0.779789 -0.611857  0.098089  0.711350   \n",
       "9 -0.156419 -0.815382  0.743960    0.784721 -0.899253 -0.102906  0.881609   \n",
       "\n",
       "       R_25      D_96       S_26     D_102      B_36      B_37      B_40  \\\n",
       "0  0.362380  0.916180   7.697775 -0.009747  0.321661  0.064551 -0.209691   \n",
       "1  0.567717 -0.800869  16.129256 -0.007874  0.235601 -0.069284 -0.143428   \n",
       "2  0.033805 -0.047896   0.141676  0.310599 -0.120814 -0.206114 -0.171145   \n",
       "3  0.684008  0.118329  -0.320696 -0.001052 -0.538927  0.562077  0.179704   \n",
       "4 -0.848928 -0.421799   3.983588 -0.005015 -0.464634  0.009952  1.626139   \n",
       "5  0.657401  0.193351   0.513024  0.102160 -0.010612  1.863122  1.919145   \n",
       "6 -0.126965 -0.160732  -0.355366 -0.016377 -0.493889 -0.161673 -0.146237   \n",
       "7  0.558693  0.346084  28.226339  0.340048  0.017044  0.065338  0.547835   \n",
       "8  0.635825 -0.845828   0.123187  0.324134 -0.458618  3.425436  9.478719   \n",
       "9  0.698818  0.461516   0.061326 -0.000195 -0.187048  4.280495 -0.238612   \n",
       "\n",
       "        D_127      B_41       D_133      R_28     D_140     D_144  \n",
       "0  179.231150 -0.798256   -0.244368  0.062582  0.842288  0.812878  \n",
       "1   -0.503888  0.415064   -0.172199 -0.464009 -0.765897  0.286217  \n",
       "2    0.551678 -0.813501   -0.708440  0.824055 -0.030353 -0.002410  \n",
       "3   -0.810349  0.453933   -0.557300 -0.940495 -0.630348 -0.690617  \n",
       "4   -0.513714  0.170901   -0.498938 -0.391959 -0.603922 -0.004369  \n",
       "5   -0.091340  0.625160  105.494513  0.909654  0.432224  0.815222  \n",
       "6   -0.347619  0.448352   -0.154504 -0.901717 -0.722758  0.666239  \n",
       "7   -0.436280 -0.413149   -0.098672 -0.136547 -0.499212 -0.501198  \n",
       "8    0.295298  0.906533   -0.342997 -0.783628  0.307807  0.268315  \n",
       "9    0.509863  0.434160   -0.462045 -0.320133 -0.855815  0.518931  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_search_space = {\n",
    "    # --- Tree Booster Parameters ---\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)), # Depth of a tree - Integer\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.001, 0.3),  # Step size shrinkage - Float\n",
    "\n",
    "    # --- Learning Task Parameters ---\n",
    "    'gamma': hp.uniform('gamma', 0.0, 1.0), # Minimum loss reduction required to make a further partition - Float\n",
    "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 10, 1)), # Minimum sum of instance weight (hessian) needed in a child - Integer\n",
    "\n",
    "    # --- Sampling Parameters ---\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0), # Fraction of samples used per tree - Float\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0), # Fraction of features used per tree - Float\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode', 0.5, 1.0),\n",
    "\n",
    "    # --- Regularization ---\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0), # L1 regularization term on weights - Float\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.1, 10.0), # L2 regularization term on weights - Float\n",
    "\n",
    "    # --- Number of Estimators (Trees) ---\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 1000, 50)), # Number of boosting rounds - Integer\n",
    "    \n",
    "    # --- Optional: Add seed for reproducibility if needed ---\n",
    "    'seed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "from hyperopt import STATUS_FAIL\n",
    "\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Hyperopt optimization (minimizing 1 - Macro F1)\"\"\"\n",
    "\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "\n",
    "    early_stopping_rounds = 50\n",
    "\n",
    "    print(\"\\nTraining with params:\")\n",
    "    print(params)\n",
    "\n",
    "    try:\n",
    "        model = xgb.XGBClassifier(\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            eval_set=[(X_val_scaled, y_val)],\n",
    "            verbose=False # Keep verbose False during hyperparameter search\n",
    "        )\n",
    "\n",
    "        # Predict class labels on the validation set\n",
    "        preds = model.predict(X_val_scaled)\n",
    "\n",
    "        # Calculate the Macro Average F1 Score\n",
    "        # Note: average='macro' calculates F1 for each label, then finds their unweighted mean.\n",
    "        # It does not take label imbalance into account.\n",
    "        score = f1_score(y_val, preds, average='macro')\n",
    "        loss = 1.0 - score # Loss = 1 - F1 Score (since we want to maximize F1)\n",
    "\n",
    "        actual_n_estimators = model.best_iteration + 1\n",
    "        print(f\"Score (Macro F1): {score:.4f} | Loss (1-F1): {loss:.4f} | Trees: {actual_n_estimators}\")\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'status': STATUS_OK,\n",
    "            'eval_time': time.time(),\n",
    "            'attachments': {'actual_n_estimators': actual_n_estimators, 'macro_f1': score}\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception during training: {str(e)}\")\n",
    "        return {\n",
    "            'loss': float('inf'), # Assign a large loss for failed trials\n",
    "            'status': STATUS_FAIL,\n",
    "            'exception': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Hyperopt optimization (minimizing 1 - Macro F1)...\n",
      "                                                       \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7685875917454542, 'colsample_bynode': 0.5526606529048173, 'colsample_bytree': 0.9656211530822304, 'gamma': 0.22112393376190054, 'learning_rate': 0.19001005106489924, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 850, 'reg_alpha': 0.190496195178539, 'reg_lambda': 1.9744009387337769, 'seed': 0, 'subsample': 0.8411318103731124}\n",
      "Score (Macro F1): 0.8526 | Loss (1-F1): 0.1474 | Trees: 95\n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9396923893750253, 'colsample_bynode': 0.6953772297746847, 'colsample_bytree': 0.7240504079328978, 'gamma': 0.15232687318869131, 'learning_rate': 0.2708335701059083, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 600, 'reg_alpha': 0.18777487575294727, 'reg_lambda': 2.8298700391980365, 'seed': 0, 'subsample': 0.9135579211284748}\n",
      "Score (Macro F1): 0.8526 | Loss (1-F1): 0.1474 | Trees: 231                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.929859106176625, 'colsample_bynode': 0.997880924085792, 'colsample_bytree': 0.6722995975529426, 'gamma': 0.3782392869709291, 'learning_rate': 0.20544252813218192, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 450, 'reg_alpha': 0.4101277476340921, 'reg_lambda': 7.057741094758419, 'seed': 0, 'subsample': 0.7210771337355122}\n",
      "Score (Macro F1): 0.8536 | Loss (1-F1): 0.1464 | Trees: 128                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5790593304846792, 'colsample_bynode': 0.8591675142994344, 'colsample_bytree': 0.5778018880456188, 'gamma': 0.4651754117507132, 'learning_rate': 0.2003960145020942, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 500, 'reg_alpha': 0.8964179680799482, 'reg_lambda': 3.2175194196521923, 'seed': 0, 'subsample': 0.954663135591284}\n",
      "Score (Macro F1): 0.8522 | Loss (1-F1): 0.1478 | Trees: 88                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9715393012150689, 'colsample_bynode': 0.5006185315601643, 'colsample_bytree': 0.975358678930164, 'gamma': 0.8787625364224586, 'learning_rate': 0.03112544083506059, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 750, 'reg_alpha': 0.3744678637601164, 'reg_lambda': 9.272712658958918, 'seed': 0, 'subsample': 0.7732001452367051}\n",
      "Score (Macro F1): 0.8534 | Loss (1-F1): 0.1466 | Trees: 750                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.935482645232434, 'colsample_bynode': 0.9828366748849778, 'colsample_bytree': 0.5434030320859482, 'gamma': 0.5039061315846585, 'learning_rate': 0.03422943984825437, 'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 750, 'reg_alpha': 0.8120201961136909, 'reg_lambda': 6.265466289817151, 'seed': 0, 'subsample': 0.9991756881657872}\n",
      "Score (Macro F1): 0.8535 | Loss (1-F1): 0.1465 | Trees: 747                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8470095341804815, 'colsample_bynode': 0.8175182157333372, 'colsample_bytree': 0.6829615987374331, 'gamma': 0.5036965315927044, 'learning_rate': 0.1830951741281102, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 1000, 'reg_alpha': 0.07464196842676663, 'reg_lambda': 9.904051442925828, 'seed': 0, 'subsample': 0.8647249521343083}\n",
      "Score (Macro F1): 0.8524 | Loss (1-F1): 0.1476 | Trees: 54                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8026898537017289, 'colsample_bynode': 0.7592474901014272, 'colsample_bytree': 0.8887559461739756, 'gamma': 0.2825724252165869, 'learning_rate': 0.22195458027940076, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 700, 'reg_alpha': 0.9381806490254235, 'reg_lambda': 0.43488145750561535, 'seed': 0, 'subsample': 0.5797666220819824}\n",
      "Score (Macro F1): 0.8522 | Loss (1-F1): 0.1478 | Trees: 64                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9104285923931779, 'colsample_bynode': 0.520141325630147, 'colsample_bytree': 0.8366055538657591, 'gamma': 0.4307567617301, 'learning_rate': 0.0024238541474410785, 'max_depth': 6, 'min_child_weight': 10, 'n_estimators': 750, 'reg_alpha': 0.8609343460681542, 'reg_lambda': 1.08220268063966, 'seed': 0, 'subsample': 0.7509342903513976}\n",
      "Score (Macro F1): 0.8367 | Loss (1-F1): 0.1633 | Trees: 750                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6459331031472352, 'colsample_bynode': 0.9864024634496789, 'colsample_bytree': 0.6997260383007193, 'gamma': 0.030567208601904206, 'learning_rate': 0.05044698232985412, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 300, 'reg_alpha': 0.8953238343456044, 'reg_lambda': 5.013865816051863, 'seed': 0, 'subsample': 0.6670197618256024}\n",
      "Score (Macro F1): 0.8535 | Loss (1-F1): 0.1465 | Trees: 298                       \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8402704683923372, 'colsample_bynode': 0.9994814904231913, 'colsample_bytree': 0.6962875698702644, 'gamma': 0.1729778110007505, 'learning_rate': 0.16393610898678065, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 600, 'reg_alpha': 0.46560116934614804, 'reg_lambda': 4.910498960529424, 'seed': 0, 'subsample': 0.7039251622885354}\n",
      "Score (Macro F1): 0.8521 | Loss (1-F1): 0.1479 | Trees: 54                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8750070952826915, 'colsample_bynode': 0.5198223092802222, 'colsample_bytree': 0.7732100184350981, 'gamma': 0.008948332584280072, 'learning_rate': 0.040193480379092934, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 250, 'reg_alpha': 0.6758242580770901, 'reg_lambda': 5.6006884933074845, 'seed': 0, 'subsample': 0.7880451421275081}\n",
      "Score (Macro F1): 0.8541 | Loss (1-F1): 0.1459 | Trees: 250                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8133819757840011, 'colsample_bynode': 0.506474014183979, 'colsample_bytree': 0.8557726015433877, 'gamma': 0.7737556634562845, 'learning_rate': 0.04493085575292497, 'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 300, 'reg_alpha': 0.6814082460413754, 'reg_lambda': 9.305308859425951, 'seed': 0, 'subsample': 0.8146235357906524}\n",
      "Score (Macro F1): 0.8549 | Loss (1-F1): 0.1451 | Trees: 300                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9758409276602971, 'colsample_bynode': 0.8259599293048843, 'colsample_bytree': 0.8255582545378133, 'gamma': 0.3664452413419772, 'learning_rate': 0.024940756529201018, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 600, 'reg_alpha': 0.44676361602012926, 'reg_lambda': 8.059036250478846, 'seed': 0, 'subsample': 0.923732271962304}\n",
      "Score (Macro F1): 0.8533 | Loss (1-F1): 0.1467 | Trees: 600                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8347745285895818, 'colsample_bynode': 0.8057658995872903, 'colsample_bytree': 0.5766208911384505, 'gamma': 0.18849424070404974, 'learning_rate': 0.02024844152389819, 'max_depth': 8, 'min_child_weight': 9, 'n_estimators': 400, 'reg_alpha': 0.022630288679654664, 'reg_lambda': 9.513088311714979, 'seed': 0, 'subsample': 0.8082925817075997}\n",
      "Score (Macro F1): 0.8532 | Loss (1-F1): 0.1468 | Trees: 400                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5001495714675965, 'colsample_bynode': 0.5598983434370092, 'colsample_bytree': 0.646482572549465, 'gamma': 0.11609137438367378, 'learning_rate': 0.04345137910078391, 'max_depth': 9, 'min_child_weight': 10, 'n_estimators': 350, 'reg_alpha': 0.489965709721621, 'reg_lambda': 6.218332716378768, 'seed': 0, 'subsample': 0.7978206376923767}\n",
      "Score (Macro F1): 0.8551 | Loss (1-F1): 0.1449 | Trees: 346                       \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7721990979842219, 'colsample_bynode': 0.976303520501302, 'colsample_bytree': 0.836380363124381, 'gamma': 0.03227266245444249, 'learning_rate': 0.06889588493999975, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 800, 'reg_alpha': 0.27501628355384233, 'reg_lambda': 3.978978393502225, 'seed': 0, 'subsample': 0.5189953253034847}\n",
      "Score (Macro F1): 0.8534 | Loss (1-F1): 0.1466 | Trees: 787                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6960345412168965, 'colsample_bynode': 0.7632294683911254, 'colsample_bytree': 0.6675037884054981, 'gamma': 0.7879224968140971, 'learning_rate': 0.11293062880913893, 'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 750, 'reg_alpha': 0.15781105702702714, 'reg_lambda': 3.200998215081656, 'seed': 0, 'subsample': 0.6155180574704033}\n",
      "Score (Macro F1): 0.8516 | Loss (1-F1): 0.1484 | Trees: 124                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7495381604830553, 'colsample_bynode': 0.5629278221913325, 'colsample_bytree': 0.9472337362320987, 'gamma': 0.19387425975349237, 'learning_rate': 0.2972690626092521, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 250, 'reg_alpha': 0.4697103055339882, 'reg_lambda': 8.421214444898949, 'seed': 0, 'subsample': 0.9275027261357094}\n",
      "Score (Macro F1): 0.8529 | Loss (1-F1): 0.1471 | Trees: 125                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5132273301238661, 'colsample_bynode': 0.5195040658389181, 'colsample_bytree': 0.9358305987239033, 'gamma': 0.6752355562294173, 'learning_rate': 0.11238235526187776, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 650, 'reg_alpha': 0.8079221496042333, 'reg_lambda': 5.027425887454992, 'seed': 0, 'subsample': 0.7424521891186919}\n",
      "Score (Macro F1): 0.8517 | Loss (1-F1): 0.1483 | Trees: 386                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5257187221496895, 'colsample_bynode': 0.6365325062270564, 'colsample_bytree': 0.6182912428414136, 'gamma': 0.6395250964298782, 'learning_rate': 0.09039491288249721, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 100, 'reg_alpha': 0.6175980430816922, 'reg_lambda': 7.463945184922382, 'seed': 0, 'subsample': 0.8609410003561819}\n",
      "Score (Macro F1): 0.8540 | Loss (1-F1): 0.1460 | Trees: 99                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6709493454966178, 'colsample_bynode': 0.6222183095750071, 'colsample_bytree': 0.7810580087925239, 'gamma': 0.8478445980255017, 'learning_rate': 0.13760308113833217, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 150, 'reg_alpha': 0.5774810012379045, 'reg_lambda': 6.424102705898246, 'seed': 0, 'subsample': 0.6629812320502838}\n",
      "Score (Macro F1): 0.8509 | Loss (1-F1): 0.1491 | Trees: 89                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7198530526291851, 'colsample_bynode': 0.6146548127294984, 'colsample_bytree': 0.896482162775015, 'gamma': 0.9882682595015088, 'learning_rate': 0.07388886290434789, 'max_depth': 9, 'min_child_weight': 8, 'n_estimators': 400, 'reg_alpha': 0.7315910140036143, 'reg_lambda': 8.6674175688865, 'seed': 0, 'subsample': 0.8258510135787351}\n",
      "Score (Macro F1): 0.8543 | Loss (1-F1): 0.1457 | Trees: 212                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6094867025137487, 'colsample_bynode': 0.6906837269472813, 'colsample_bytree': 0.6276986117202529, 'gamma': 0.6185256114284514, 'learning_rate': 0.10049404452060995, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 350, 'reg_alpha': 0.5606779259066069, 'reg_lambda': 7.44300259142844, 'seed': 0, 'subsample': 0.8849063123918263}\n",
      "Score (Macro F1): 0.8532 | Loss (1-F1): 0.1468 | Trees: 139                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5932924756676798, 'colsample_bynode': 0.5825251334012868, 'colsample_bytree': 0.7557128024771201, 'gamma': 0.7444253746224313, 'learning_rate': 0.0019797037390981848, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 200, 'reg_alpha': 0.7203518550383492, 'reg_lambda': 9.957984693486358, 'seed': 0, 'subsample': 0.682486262120618}\n",
      "Score (Macro F1): 0.4840 | Loss (1-F1): 0.5160 | Trees: 200                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5455939128926742, 'colsample_bynode': 0.9188108650730167, 'colsample_bytree': 0.8851015242134666, 'gamma': 0.9681374860094916, 'learning_rate': 0.13332295067587696, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 500, 'reg_alpha': 0.9844096601181263, 'reg_lambda': 4.067075463815222, 'seed': 0, 'subsample': 0.9686501486001803}\n",
      "Score (Macro F1): 0.8538 | Loss (1-F1): 0.1462 | Trees: 197                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7254892527410876, 'colsample_bynode': 0.6574719705983226, 'colsample_bytree': 0.63174588081457, 'gamma': 0.5925875642460907, 'learning_rate': 0.0645946464768183, 'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 150, 'reg_alpha': 0.33511142822995166, 'reg_lambda': 6.134137216010037, 'seed': 0, 'subsample': 0.7925273579155026}\n",
      "Score (Macro F1): 0.8548 | Loss (1-F1): 0.1452 | Trees: 150                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8885151737400054, 'colsample_bynode': 0.7127485307714172, 'colsample_bytree': 0.5089479686332387, 'gamma': 0.9093447699331311, 'learning_rate': 0.08710941637155112, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 350, 'reg_alpha': 0.5191790213257541, 'reg_lambda': 8.826159010742083, 'seed': 0, 'subsample': 0.6148951797159339}\n",
      "Score (Macro F1): 0.8526 | Loss (1-F1): 0.1474 | Trees: 199                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7854166800949577, 'colsample_bynode': 0.5784364819184311, 'colsample_bytree': 0.9994593852520264, 'gamma': 0.2767821989518312, 'learning_rate': 0.01122121718426198, 'max_depth': 7, 'min_child_weight': 8, 'n_estimators': 950, 'reg_alpha': 0.2800093762683631, 'reg_lambda': 1.521575157579985, 'seed': 0, 'subsample': 0.8286625403650928}\n",
      "Score (Macro F1): 0.8551 | Loss (1-F1): 0.1449 | Trees: 950                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6381856219450752, 'colsample_bynode': 0.5849909859269585, 'colsample_bytree': 0.7936904295614023, 'gamma': 0.09444978493060714, 'learning_rate': 0.009987691902758507, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 1000, 'reg_alpha': 0.30598000629886224, 'reg_lambda': 2.010561316277679, 'seed': 0, 'subsample': 0.8446622069993465}\n",
      "Score (Macro F1): 0.8543 | Loss (1-F1): 0.1457 | Trees: 1000                       \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7692873411232646, 'colsample_bynode': 0.5572463179668337, 'colsample_bytree': 0.9962097624089624, 'gamma': 0.29379413942203203, 'learning_rate': 0.2624613244888709, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 950, 'reg_alpha': 0.23467291428314208, 'reg_lambda': 1.8504317719937466, 'seed': 0, 'subsample': 0.8913512783209931}\n",
      "Score (Macro F1): 0.8517 | Loss (1-F1): 0.1483 | Trees: 155                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6940230659327478, 'colsample_bynode': 0.6761829269838061, 'colsample_bytree': 0.7266961819078659, 'gamma': 0.10192283389608348, 'learning_rate': 0.23786853018162546, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 850, 'reg_alpha': 0.1135669726703869, 'reg_lambda': 0.33841372280097914, 'seed': 0, 'subsample': 0.7612601303226721}\n",
      "Score (Macro F1): 0.8528 | Loss (1-F1): 0.1472 | Trees: 64                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5595159670747466, 'colsample_bynode': 0.7183161306624256, 'colsample_bytree': 0.5032819822094433, 'gamma': 0.26009274578991215, 'learning_rate': 0.0015222027298414098, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 900, 'reg_alpha': 0.23017041249038878, 'reg_lambda': 2.247280503057397, 'seed': 0, 'subsample': 0.7268770779028993}\n",
      "Score (Macro F1): 0.8212 | Loss (1-F1): 0.1788 | Trees: 900                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7942431511890033, 'colsample_bynode': 0.6049043688892364, 'colsample_bytree': 0.5933839233717294, 'gamma': 0.3521732591548922, 'learning_rate': 0.16732709538085253, 'max_depth': 4, 'min_child_weight': 10, 'n_estimators': 500, 'reg_alpha': 0.4157585078247941, 'reg_lambda': 4.242554859865146, 'seed': 0, 'subsample': 0.9789001395251071}\n",
      "Score (Macro F1): 0.8539 | Loss (1-F1): 0.1461 | Trees: 365                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.742902888241636, 'colsample_bynode': 0.5529960279776337, 'colsample_bytree': 0.5350145379273896, 'gamma': 0.10345106070742173, 'learning_rate': 0.06375174291519055, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 550, 'reg_alpha': 0.3510112165344186, 'reg_lambda': 1.0003013996587313, 'seed': 0, 'subsample': 0.9417416086436191}\n",
      "Score (Macro F1): 0.8532 | Loss (1-F1): 0.1468 | Trees: 201                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6264358289997443, 'colsample_bynode': 0.6421012537053975, 'colsample_bytree': 0.655543669594899, 'gamma': 0.2370836935630672, 'learning_rate': 0.12734451234989141, 'max_depth': 7, 'min_child_weight': 8, 'n_estimators': 450, 'reg_alpha': 0.009565220190252521, 'reg_lambda': 6.7767450293868885, 'seed': 0, 'subsample': 0.9045461396552253}\n",
      "Score (Macro F1): 0.8548 | Loss (1-F1): 0.1452 | Trees: 172                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8674530385737778, 'colsample_bynode': 0.7361855803661486, 'colsample_bytree': 0.7278275612909128, 'gamma': 0.5536477171632244, 'learning_rate': 0.017616131132553114, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 650, 'reg_alpha': 0.40240180012481847, 'reg_lambda': 5.516915100030989, 'seed': 0, 'subsample': 0.8474508608613261}\n",
      "Score (Macro F1): 0.8549 | Loss (1-F1): 0.1451 | Trees: 645                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9946738037788194, 'colsample_bynode': 0.6626542283990308, 'colsample_bytree': 0.5567712577452679, 'gamma': 0.42695081647947164, 'learning_rate': 0.05170577654534498, 'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 450, 'reg_alpha': 0.15495493893688467, 'reg_lambda': 2.706654789178273, 'seed': 0, 'subsample': 0.5213791461106349}\n",
      "Score (Macro F1): 0.8530 | Loss (1-F1): 0.1470 | Trees: 450                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9120296657509013, 'colsample_bynode': 0.8665537154579632, 'colsample_bytree': 0.8088493903038644, 'gamma': 0.13124448607245887, 'learning_rate': 0.19349238330116555, 'max_depth': 10, 'min_child_weight': 5, 'n_estimators': 550, 'reg_alpha': 0.514912265142682, 'reg_lambda': 1.2010531894749394, 'seed': 0, 'subsample': 0.9961400196261957}\n",
      "Score (Macro F1): 0.8521 | Loss (1-F1): 0.1479 | Trees: 41                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.786336480421326, 'colsample_bynode': 0.5825049392178164, 'colsample_bytree': 0.9992588673272802, 'gamma': 0.3236204026326558, 'learning_rate': 0.08304995364789174, 'max_depth': 6, 'min_child_weight': 10, 'n_estimators': 850, 'reg_alpha': 0.2623098563594222, 'reg_lambda': 3.2833144561083563, 'seed': 0, 'subsample': 0.7057665779201163}\n",
      "Score (Macro F1): 0.8542 | Loss (1-F1): 0.1458 | Trees: 346                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6705376235218593, 'colsample_bynode': 0.5389439278192956, 'colsample_bytree': 0.7406465359500621, 'gamma': 0.42171759014226007, 'learning_rate': 0.1552417680176971, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 950, 'reg_alpha': 0.060081426911339414, 'reg_lambda': 4.520647078404752, 'seed': 0, 'subsample': 0.780515428538536}\n",
      "Score (Macro F1): 0.8510 | Loss (1-F1): 0.1490 | Trees: 132                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6638767356727865, 'colsample_bynode': 0.7809317868190905, 'colsample_bytree': 0.7105780200115315, 'gamma': 0.04473463160712092, 'learning_rate': 0.03464672804052939, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 300, 'reg_alpha': 0.6346533902549883, 'reg_lambda': 3.6491400858547447, 'seed': 0, 'subsample': 0.6329125798087312}\n",
      "Score (Macro F1): 0.8532 | Loss (1-F1): 0.1468 | Trees: 300                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8198659800548134, 'colsample_bynode': 0.5343566157481634, 'colsample_bytree': 0.5939884642465995, 'gamma': 0.4691647032577301, 'learning_rate': 0.05215294151088241, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 650, 'reg_alpha': 0.19612461287226754, 'reg_lambda': 7.683742993943335, 'seed': 0, 'subsample': 0.5733542519955679}\n",
      "Score (Macro F1): 0.8547 | Loss (1-F1): 0.1453 | Trees: 287                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9529085180319371, 'colsample_bynode': 0.5047693540579992, 'colsample_bytree': 0.915281624790936, 'gamma': 0.23079909912222774, 'learning_rate': 0.2210236108211266, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 400, 'reg_alpha': 0.3870369406420397, 'reg_lambda': 6.866874753683694, 'seed': 0, 'subsample': 0.8768736396728001}\n",
      "Score (Macro F1): 0.8544 | Loss (1-F1): 0.1456 | Trees: 145                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5012606644043038, 'colsample_bynode': 0.8688526666462951, 'colsample_bytree': 0.8717543584543078, 'gamma': 0.5244503605510106, 'learning_rate': 0.1784358924269949, 'max_depth': 3, 'min_child_weight': 7, 'n_estimators': 700, 'reg_alpha': 0.7979810691820148, 'reg_lambda': 5.672312117283002, 'seed': 0, 'subsample': 0.8227024537895323}\n",
      "Score (Macro F1): 0.8521 | Loss (1-F1): 0.1479 | Trees: 424                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8530523167298042, 'colsample_bynode': 0.6012592905801105, 'colsample_bytree': 0.6459652118405608, 'gamma': 0.14654600868028836, 'learning_rate': 0.10134208094558793, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 250, 'reg_alpha': 0.3216897062183094, 'reg_lambda': 2.6738439895294857, 'seed': 0, 'subsample': 0.7397487754455809}\n",
      "Score (Macro F1): 0.8526 | Loss (1-F1): 0.1474 | Trees: 150                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.708182047009354, 'colsample_bynode': 0.8946182595865065, 'colsample_bytree': 0.9683688884932461, 'gamma': 0.06762583921318036, 'learning_rate': 0.01371132090830715, 'max_depth': 4, 'min_child_weight': 9, 'n_estimators': 200, 'reg_alpha': 0.5731604677623626, 'reg_lambda': 4.57052946873751, 'seed': 0, 'subsample': 0.7086272401951126}\n",
      "Score (Macro F1): 0.8372 | Loss (1-F1): 0.1628 | Trees: 200                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8980603430473335, 'colsample_bynode': 0.7050326641218971, 'colsample_bytree': 0.686046656801315, 'gamma': 0.3046354636748685, 'learning_rate': 0.025681330933953077, 'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 800, 'reg_alpha': 0.0788454564652939, 'reg_lambda': 6.037285623014504, 'seed': 0, 'subsample': 0.7998323555907514}\n",
      "Score (Macro F1): 0.8544 | Loss (1-F1): 0.1456 | Trees: 797                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5753344383283331, 'colsample_bynode': 0.5004248207922306, 'colsample_bytree': 0.5213103344479373, 'gamma': 0.004132968213859278, 'learning_rate': 0.11713369073834912, 'max_depth': 9, 'min_child_weight': 4, 'n_estimators': 350, 'reg_alpha': 0.4548461699544031, 'reg_lambda': 0.7050938094301422, 'seed': 0, 'subsample': 0.7666454967134}\n",
      "Score (Macro F1): 0.8524 | Loss (1-F1): 0.1476 | Trees: 89                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8161900692431117, 'colsample_bynode': 0.9570805097353641, 'colsample_bytree': 0.7562149542611332, 'gamma': 0.38732706407291895, 'learning_rate': 0.04077004713364146, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 100, 'reg_alpha': 0.2895902893316252, 'reg_lambda': 3.633238872615121, 'seed': 0, 'subsample': 0.9420631807137906}\n",
      "Score (Macro F1): 0.8497 | Loss (1-F1): 0.1503 | Trees: 100                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9355057609398683, 'colsample_bynode': 0.7486912732855, 'colsample_bytree': 0.5610920237472128, 'gamma': 0.1937593858718129, 'learning_rate': 0.20975965175792263, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 600, 'reg_alpha': 0.5026346611203864, 'reg_lambda': 1.4037326083327804, 'seed': 0, 'subsample': 0.6758928208904937}\n",
      "Score (Macro F1): 0.8494 | Loss (1-F1): 0.1506 | Trees: 44                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7457776389827928, 'colsample_bynode': 0.8019417129047095, 'colsample_bytree': 0.5952861109612448, 'gamma': 0.2584164987219789, 'learning_rate': 0.2932708063105688, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 500, 'reg_alpha': 0.7648190615181492, 'reg_lambda': 7.966954788800532, 'seed': 0, 'subsample': 0.8592858808231554}\n",
      "Score (Macro F1): 0.8525 | Loss (1-F1): 0.1475 | Trees: 115                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6161982543344565, 'colsample_bynode': 0.6340825551951937, 'colsample_bytree': 0.6718660083514227, 'gamma': 0.3359719842386415, 'learning_rate': 0.057133172884280436, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 200, 'reg_alpha': 0.8650951100485638, 'reg_lambda': 5.396739621487806, 'seed': 0, 'subsample': 0.9042049450416931}\n",
      "Score (Macro F1): 0.8549 | Loss (1-F1): 0.1451 | Trees: 199                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8595688167995463, 'colsample_bynode': 0.6793713438660112, 'colsample_bytree': 0.6113297530079815, 'gamma': 0.4712085066515896, 'learning_rate': 0.1423089698538495, 'max_depth': 8, 'min_child_weight': 6, 'n_estimators': 700, 'reg_alpha': 0.6515579037137895, 'reg_lambda': 0.11942451451485314, 'seed': 0, 'subsample': 0.6479405408091368}\n",
      "Score (Macro F1): 0.8511 | Loss (1-F1): 0.1489 | Trees: 72                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6532845920529433, 'colsample_bynode': 0.572507196366511, 'colsample_bytree': 0.858988106578384, 'gamma': 0.1611763867498286, 'learning_rate': 0.07778775156622665, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 450, 'reg_alpha': 0.36363015904720664, 'reg_lambda': 7.227169857684243, 'seed': 0, 'subsample': 0.8316031347672542}\n",
      "Score (Macro F1): 0.8540 | Loss (1-F1): 0.1460 | Trees: 237                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.779086835997661, 'colsample_bynode': 0.5352481685680784, 'colsample_bytree': 0.7045971264127034, 'gamma': 0.38838674352472286, 'learning_rate': 0.2511630987885813, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 150, 'reg_alpha': 0.4359038094851945, 'reg_lambda': 6.513377097763381, 'seed': 0, 'subsample': 0.6899873178657894}\n",
      "Score (Macro F1): 0.8510 | Loss (1-F1): 0.1490 | Trees: 30                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8317638878282047, 'colsample_bynode': 0.7314252012234849, 'colsample_bytree': 0.931473983562689, 'gamma': 0.20413630102062047, 'learning_rate': 0.09863356034352685, 'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 800, 'reg_alpha': 0.604719516266172, 'reg_lambda': 4.525483617890238, 'seed': 0, 'subsample': 0.5828320942007814}\n",
      "Score (Macro F1): 0.8533 | Loss (1-F1): 0.1467 | Trees: 255                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.534160287614595, 'colsample_bynode': 0.5996943161257341, 'colsample_bytree': 0.8101517208512321, 'gamma': 0.7030938018653929, 'learning_rate': 0.0059118016964655185, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 300, 'reg_alpha': 0.5425775292872685, 'reg_lambda': 9.610490908997578, 'seed': 0, 'subsample': 0.7319388612217826}\n",
      "Score (Macro F1): 0.8392 | Loss (1-F1): 0.1608 | Trees: 300                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6949704276695777, 'colsample_bynode': 0.8387307936950843, 'colsample_bytree': 0.7694507605204846, 'gamma': 0.05977393045910052, 'learning_rate': 0.030945357779532737, 'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 950, 'reg_alpha': 0.14972803917337307, 'reg_lambda': 2.3822374922015914, 'seed': 0, 'subsample': 0.755914247599206}\n",
      "Score (Macro F1): 0.8543 | Loss (1-F1): 0.1457 | Trees: 950                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.7300562010183229, 'colsample_bynode': 0.6595491984641498, 'colsample_bytree': 0.9880022167406791, 'gamma': 0.5621601801763905, 'learning_rate': 0.1203657867260527, 'max_depth': 7, 'min_child_weight': 10, 'n_estimators': 400, 'reg_alpha': 0.4805724953186239, 'reg_lambda': 1.6505666356391107, 'seed': 0, 'subsample': 0.8143633136920507}\n",
      "Score (Macro F1): 0.8527 | Loss (1-F1): 0.1473 | Trees: 129                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.762207526436393, 'colsample_bynode': 0.5216002895798799, 'colsample_bytree': 0.6520933508488957, 'gamma': 0.27126974782664465, 'learning_rate': 0.04282387401964824, 'max_depth': 8, 'min_child_weight': 1, 'n_estimators': 900, 'reg_alpha': 0.7025553819886251, 'reg_lambda': 5.165601245120365, 'seed': 0, 'subsample': 0.50167620727585}\n",
      "Score (Macro F1): 0.8538 | Loss (1-F1): 0.1462 | Trees: 470                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5870574618535407, 'colsample_bynode': 0.7694742727990153, 'colsample_bytree': 0.909466746791711, 'gamma': 0.013404528649189992, 'learning_rate': 0.28238619749196064, 'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 600, 'reg_alpha': 0.20594368344056063, 'reg_lambda': 3.0218206163756807, 'seed': 0, 'subsample': 0.7802608216895651}\n",
      "Score (Macro F1): 0.8526 | Loss (1-F1): 0.1474 | Trees: 166                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9598223004597592, 'colsample_bynode': 0.6150019602464892, 'colsample_bytree': 0.7894774065325301, 'gamma': 0.14880301318225525, 'learning_rate': 0.14917908725905132, 'max_depth': 10, 'min_child_weight': 6, 'n_estimators': 250, 'reg_alpha': 0.25359426777205174, 'reg_lambda': 5.837907321395784, 'seed': 0, 'subsample': 0.9177426687429139}\n",
      "Score (Macro F1): 0.8533 | Loss (1-F1): 0.1467 | Trees: 73                         \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8035307021132554, 'colsample_bynode': 0.6866864849341308, 'colsample_bytree': 0.8406158785438855, 'gamma': 0.507583597542129, 'learning_rate': 0.06262791343054741, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 350, 'reg_alpha': 0.10887936546437127, 'reg_lambda': 8.948573258726155, 'seed': 0, 'subsample': 0.8698772490108384}\n",
      "Score (Macro F1): 0.8539 | Loss (1-F1): 0.1461 | Trees: 350                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.682152879544669, 'colsample_bynode': 0.6277401558867834, 'colsample_bytree': 0.5725184386871729, 'gamma': 0.11369891956193656, 'learning_rate': 0.09175743673682324, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 550, 'reg_alpha': 0.9538640154853638, 'reg_lambda': 4.826711487797747, 'seed': 0, 'subsample': 0.9745398670591149}\n",
      "Score (Macro F1): 0.8538 | Loss (1-F1): 0.1462 | Trees: 392                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9989185287645087, 'colsample_bynode': 0.7307845993191155, 'colsample_bytree': 0.7175455062096712, 'gamma': 0.5400757311949466, 'learning_rate': 0.023562749173287552, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 750, 'reg_alpha': 0.4017158192199658, 'reg_lambda': 6.3681605871199505, 'seed': 0, 'subsample': 0.8572651785017066}\n",
      "Score (Macro F1): 0.8550 | Loss (1-F1): 0.1450 | Trees: 714                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.994378957376648, 'colsample_bynode': 0.6497964641907743, 'colsample_bytree': 0.7447560794774408, 'gamma': 0.6564876330908153, 'learning_rate': 0.020832423024021156, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 750, 'reg_alpha': 0.3735586900988484, 'reg_lambda': 6.534625991724931, 'seed': 0, 'subsample': 0.7957694593685906}\n",
      "Score (Macro F1): 0.8552 | Loss (1-F1): 0.1448 | Trees: 750                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9757873025865935, 'colsample_bynode': 0.6477901515296701, 'colsample_bytree': 0.693347541992005, 'gamma': 0.8354583690987627, 'learning_rate': 0.0016175998551621953, 'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 900, 'reg_alpha': 0.3153756123054276, 'reg_lambda': 8.237921405704276, 'seed': 0, 'subsample': 0.8014649603957315}\n",
      "Score (Macro F1): 0.8327 | Loss (1-F1): 0.1673 | Trees: 900                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.923521264678494, 'colsample_bynode': 0.5729379021055988, 'colsample_bytree': 0.7364194897206416, 'gamma': 0.6771933581037327, 'learning_rate': 0.036912150137719986, 'max_depth': 10, 'min_child_weight': 6, 'n_estimators': 1000, 'reg_alpha': 0.35601811552172746, 'reg_lambda': 7.790742405711795, 'seed': 0, 'subsample': 0.841119353332108}\n",
      "Score (Macro F1): 0.8540 | Loss (1-F1): 0.1460 | Trees: 353                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5616226561069992, 'colsample_bynode': 0.7005250769160434, 'colsample_bytree': 0.8148175539620967, 'gamma': 0.7691652926891003, 'learning_rate': 0.012894556647488484, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 700, 'reg_alpha': 0.48143204682883495, 'reg_lambda': 7.014203037633646, 'seed': 0, 'subsample': 0.8968167563195839}\n",
      "Score (Macro F1): 0.8546 | Loss (1-F1): 0.1454 | Trees: 700                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8874698506920116, 'colsample_bynode': 0.5482497982329373, 'colsample_bytree': 0.630854305154252, 'gamma': 0.590878429471247, 'learning_rate': 0.07357102237698188, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 750, 'reg_alpha': 0.5962122713461154, 'reg_lambda': 6.681964079211988, 'seed': 0, 'subsample': 0.7162512954828412}\n",
      "Score (Macro F1): 0.8529 | Loss (1-F1): 0.1471 | Trees: 206                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6352868856572934, 'colsample_bynode': 0.5216049304898229, 'colsample_bytree': 0.7668427193910176, 'gamma': 0.6272795539784326, 'learning_rate': 0.0282771454913864, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 850, 'reg_alpha': 0.5365227940616827, 'reg_lambda': 7.3126599043982266, 'seed': 0, 'subsample': 0.7693622999616433}\n",
      "Score (Macro F1): 0.8541 | Loss (1-F1): 0.1459 | Trees: 559                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.6051791562393694, 'colsample_bynode': 0.591296608995104, 'colsample_bytree': 0.6683538475006221, 'gamma': 0.7012523132387071, 'learning_rate': 0.04687571045545852, 'max_depth': 9, 'min_child_weight': 10, 'n_estimators': 650, 'reg_alpha': 0.42659630594825393, 'reg_lambda': 8.512810677486849, 'seed': 0, 'subsample': 0.7493748499004946}\n",
      "Score (Macro F1): 0.8535 | Loss (1-F1): 0.1465 | Trees: 425                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.5203570829393931, 'colsample_bynode': 0.5625896945937808, 'colsample_bytree': 0.950795913955666, 'gamma': 0.8883129547340436, 'learning_rate': 0.056983624263879165, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 950, 'reg_alpha': 0.28596204412687876, 'reg_lambda': 5.288900219651942, 'seed': 0, 'subsample': 0.7900890812323166}\n",
      "Score (Macro F1): 0.8535 | Loss (1-F1): 0.1465 | Trees: 400                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9884364297183803, 'colsample_bynode': 0.6500387164836763, 'colsample_bytree': 0.6791548127769368, 'gamma': 0.8124004803378151, 'learning_rate': 0.01743625411138701, 'max_depth': 8, 'min_child_weight': 9, 'n_estimators': 800, 'reg_alpha': 0.3835586629946968, 'reg_lambda': 5.891490497819792, 'seed': 0, 'subsample': 0.8816898342779336}\n",
      "Score (Macro F1): 0.8554 | Loss (1-F1): 0.1446 | Trees: 794                       \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.983343725179637, 'colsample_bynode': 0.6701560765490363, 'colsample_bytree': 0.607628069870499, 'gamma': 0.9633303037078003, 'learning_rate': 0.08169775354531846, 'max_depth': 8, 'min_child_weight': 9, 'n_estimators': 800, 'reg_alpha': 0.6663584636546664, 'reg_lambda': 5.937971076821088, 'seed': 0, 'subsample': 0.93478560463493}\n",
      "Score (Macro F1): 0.8549 | Loss (1-F1): 0.1451 | Trees: 224                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9191737094381004, 'colsample_bynode': 0.6454587477462315, 'colsample_bytree': 0.6442239032599624, 'gamma': 0.8071730480772283, 'learning_rate': 0.10488782131736597, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 900, 'reg_alpha': 0.23018621907046144, 'reg_lambda': 9.076971267282204, 'seed': 0, 'subsample': 0.8853118735806713}\n",
      "Score (Macro F1): 0.8542 | Loss (1-F1): 0.1458 | Trees: 165                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9540772996649787, 'colsample_bynode': 0.7208318785200507, 'colsample_bytree': 0.6836521478401993, 'gamma': 0.7446727624051961, 'learning_rate': 0.0924585756911552, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 500, 'reg_alpha': 0.3415373046993067, 'reg_lambda': 7.5379547803224884, 'seed': 0, 'subsample': 0.9965049496728606}\n",
      "Score (Macro F1): 0.8521 | Loss (1-F1): 0.1479 | Trees: 181                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9007742037358686, 'colsample_bynode': 0.7869045948709822, 'colsample_bytree': 0.7960310510235896, 'gamma': 0.9386086236457385, 'learning_rate': 0.01760309617897438, 'max_depth': 10, 'min_child_weight': 10, 'n_estimators': 600, 'reg_alpha': 0.38561762932977844, 'reg_lambda': 4.830911678159625, 'seed': 0, 'subsample': 0.8125851393810649}\n",
      "Score (Macro F1): 0.8556 | Loss (1-F1): 0.1444 | Trees: 592                        \n",
      "                                                                                   \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9437996352215606, 'colsample_bynode': 0.7990630340092052, 'colsample_bytree': 0.7474343844005706, 'gamma': 0.9253203053976883, 'learning_rate': 0.021081764788095227, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 850, 'reg_alpha': 0.3770272259049696, 'reg_lambda': 4.828778732353174, 'seed': 0, 'subsample': 0.9531492450297445}\n",
      "Score (Macro F1): 0.8547 | Loss (1-F1): 0.1453 | Trees: 783                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9862187877505975, 'colsample_bynode': 0.7865489469360196, 'colsample_bytree': 0.7966650091680415, 'gamma': 0.8345046755561596, 'learning_rate': 0.0694064493545562, 'max_depth': 10, 'min_child_weight': 10, 'n_estimators': 650, 'reg_alpha': 0.18311336631418712, 'reg_lambda': 6.590537264102554, 'seed': 0, 'subsample': 0.8437600237174193}\n",
      "Score (Macro F1): 0.8545 | Loss (1-F1): 0.1455 | Trees: 191                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9667574380906288, 'colsample_bynode': 0.8278457893404769, 'colsample_bytree': 0.8358769175749969, 'gamma': 0.9930485062599745, 'learning_rate': 0.0012552007963945837, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 700, 'reg_alpha': 0.45246327481911797, 'reg_lambda': 3.4068604922490624, 'seed': 0, 'subsample': 0.6912028027862953}\n",
      "Score (Macro F1): 0.7985 | Loss (1-F1): 0.2015 | Trees: 700                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8952206206324886, 'colsample_bynode': 0.7504690970630556, 'colsample_bytree': 0.7775106325052425, 'gamma': 0.8687054569405561, 'learning_rate': 0.12805327671191152, 'max_depth': 9, 'min_child_weight': 6, 'n_estimators': 750, 'reg_alpha': 0.1277102854866876, 'reg_lambda': 4.002889602645554, 'seed': 0, 'subsample': 0.8106143723094927}\n",
      "Score (Macro F1): 0.8543 | Loss (1-F1): 0.1457 | Trees: 88                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.87689137115291, 'colsample_bynode': 0.8486968059410512, 'colsample_bytree': 0.8781383639925999, 'gamma': 0.9390328757572826, 'learning_rate': 0.017870650449490703, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 600, 'reg_alpha': 0.5552659277888647, 'reg_lambda': 5.716892826572163, 'seed': 0, 'subsample': 0.9599136801899915}\n",
      "Score (Macro F1): 0.8546 | Loss (1-F1): 0.1454 | Trees: 599                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9350968911148175, 'colsample_bynode': 0.9229359230508414, 'colsample_bytree': 0.7610078044876906, 'gamma': 0.6635875804494188, 'learning_rate': 0.17542615000171957, 'max_depth': 10, 'min_child_weight': 10, 'n_estimators': 600, 'reg_alpha': 0.06111072927118977, 'reg_lambda': 3.759385517733402, 'seed': 0, 'subsample': 0.9857095617785101}\n",
      "Score (Macro F1): 0.8517 | Loss (1-F1): 0.1483 | Trees: 60                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9040602175423427, 'colsample_bynode': 0.7711375215017815, 'colsample_bytree': 0.8485535761017867, 'gamma': 0.7931432354464799, 'learning_rate': 0.055901851026716715, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 800, 'reg_alpha': 0.3105959034542244, 'reg_lambda': 6.91798130708395, 'seed': 0, 'subsample': 0.9148479885306195}\n",
      "Score (Macro F1): 0.8546 | Loss (1-F1): 0.1454 | Trees: 226                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9916811014074449, 'colsample_bynode': 0.7479326226213534, 'colsample_bytree': 0.7136791651696786, 'gamma': 0.7478426281989802, 'learning_rate': 0.035002513337995575, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 700, 'reg_alpha': 0.38812695310862744, 'reg_lambda': 4.318598649865259, 'seed': 0, 'subsample': 0.876155782876524}\n",
      "Score (Macro F1): 0.8544 | Loss (1-F1): 0.1456 | Trees: 402                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8444055393594191, 'colsample_bynode': 0.819941522302551, 'colsample_bytree': 0.8212159663837012, 'gamma': 0.8970228179617254, 'learning_rate': 0.11045082384080922, 'max_depth': 9, 'min_child_weight': 9, 'n_estimators': 550, 'reg_alpha': 0.2502878083453679, 'reg_lambda': 4.97546483916172, 'seed': 0, 'subsample': 0.8332829623698994}\n",
      "Score (Macro F1): 0.8532 | Loss (1-F1): 0.1468 | Trees: 179                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9991351635264567, 'colsample_bynode': 0.8935116628293117, 'colsample_bytree': 0.7315111752293086, 'gamma': 0.7060864100654941, 'learning_rate': 0.04905803377961541, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 650, 'reg_alpha': 0.5205761477500294, 'reg_lambda': 6.2258781218958115, 'seed': 0, 'subsample': 0.9259907141475829}\n",
      "Score (Macro F1): 0.8549 | Loss (1-F1): 0.1451 | Trees: 455                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9454412746175366, 'colsample_bynode': 0.7099417072032869, 'colsample_bytree': 0.7452266856123667, 'gamma': 0.5964814564821709, 'learning_rate': 0.004984227915556505, 'max_depth': 10, 'min_child_weight': 8, 'n_estimators': 750, 'reg_alpha': 0.2106562383219227, 'reg_lambda': 5.460954281068485, 'seed': 0, 'subsample': 0.7801184522361919}\n",
      "Score (Macro F1): 0.8512 | Loss (1-F1): 0.1488 | Trees: 750                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9685286955336873, 'colsample_bynode': 0.6930367869839856, 'colsample_bytree': 0.7956973491275967, 'gamma': 0.8551558584002149, 'learning_rate': 0.06454545331771572, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 850, 'reg_alpha': 0.18176376938241456, 'reg_lambda': 4.269550029555745, 'seed': 0, 'subsample': 0.7416254113726376}\n",
      "Score (Macro F1): 0.8539 | Loss (1-F1): 0.1461 | Trees: 236                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8792187636586811, 'colsample_bynode': 0.8092099607204579, 'colsample_bytree': 0.6974413595130228, 'gamma': 0.9653574540536684, 'learning_rate': 0.1599284251468496, 'max_depth': 10, 'min_child_weight': 6, 'n_estimators': 1000, 'reg_alpha': 0.4125604974053081, 'reg_lambda': 7.152560678715954, 'seed': 0, 'subsample': 0.8502074371179452}\n",
      "Score (Macro F1): 0.8519 | Loss (1-F1): 0.1481 | Trees: 62                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9107596990810662, 'colsample_bynode': 0.6160036469754312, 'colsample_bytree': 0.8639986355971447, 'gamma': 0.824815419609584, 'learning_rate': 0.009981229290351985, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 800, 'reg_alpha': 0.4367864548929098, 'reg_lambda': 8.061969718658084, 'seed': 0, 'subsample': 0.9012416108700939}\n",
      "Score (Macro F1): 0.8541 | Loss (1-F1): 0.1459 | Trees: 800                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8661566300558877, 'colsample_bynode': 0.7895770312016911, 'colsample_bytree': 0.8992391695057066, 'gamma': 0.7271320456939797, 'learning_rate': 0.1886352576763212, 'max_depth': 8, 'min_child_weight': 8, 'n_estimators': 450, 'reg_alpha': 0.6213923447685132, 'reg_lambda': 4.718562333971829, 'seed': 0, 'subsample': 0.6648000392422548}\n",
      "Score (Macro F1): 0.8521 | Loss (1-F1): 0.1479 | Trees: 57                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8253182768192229, 'colsample_bynode': 0.6684754057167119, 'colsample_bytree': 0.6649374922743428, 'gamma': 0.6495650879777244, 'learning_rate': 0.22895249355339836, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 600, 'reg_alpha': 0.7383505409752827, 'reg_lambda': 5.224045303253889, 'seed': 0, 'subsample': 0.8877979672272649}\n",
      "Score (Macro F1): 0.8516 | Loss (1-F1): 0.1484 | Trees: 76                        \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9780365102139214, 'colsample_bynode': 0.883679515729593, 'colsample_bytree': 0.8024372351466229, 'gamma': 0.9142667481967586, 'learning_rate': 0.03138826089974755, 'max_depth': 9, 'min_child_weight': 5, 'n_estimators': 750, 'reg_alpha': 0.5010915617778758, 'reg_lambda': 2.960818268556242, 'seed': 0, 'subsample': 0.8708033806979298}\n",
      "Score (Macro F1): 0.8550 | Loss (1-F1): 0.1450 | Trees: 547                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9230678704418255, 'colsample_bynode': 0.6815252004785742, 'colsample_bytree': 0.7818758698307753, 'gamma': 0.7704883255295931, 'learning_rate': 0.07218748124124816, 'max_depth': 10, 'min_child_weight': 9, 'n_estimators': 900, 'reg_alpha': 0.33372524858650154, 'reg_lambda': 5.888959146748815, 'seed': 0, 'subsample': 0.7229090024074916}\n",
      "Score (Macro F1): 0.8533 | Loss (1-F1): 0.1467 | Trees: 211                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.9613843700345822, 'colsample_bynode': 0.9201244614811006, 'colsample_bytree': 0.5429101320376342, 'gamma': 0.8113257084351806, 'learning_rate': 0.0411633709190217, 'max_depth': 8, 'min_child_weight': 10, 'n_estimators': 700, 'reg_alpha': 0.585764816328519, 'reg_lambda': 6.345940878241835, 'seed': 0, 'subsample': 0.825291786552901}\n",
      "Score (Macro F1): 0.8537 | Loss (1-F1): 0.1463 | Trees: 625                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8508021501696679, 'colsample_bynode': 0.6309682204726996, 'colsample_bytree': 0.7249216289560418, 'gamma': 0.859832379739135, 'learning_rate': 0.08247463718825161, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 500, 'reg_alpha': 0.4721703130115548, 'reg_lambda': 9.740012704070654, 'seed': 0, 'subsample': 0.8040531823656284}\n",
      "Score (Macro F1): 0.8550 | Loss (1-F1): 0.1450 | Trees: 236                       \n",
      "                                                                                  \n",
      "Training with params:\n",
      "{'colsample_bylevel': 0.8021569226334958, 'colsample_bynode': 0.6533229927170033, 'colsample_bytree': 0.6194326279049259, 'gamma': 0.5711351843438225, 'learning_rate': 0.2038283727229621, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 800, 'reg_alpha': 0.03939880643793914, 'reg_lambda': 9.302827001972533, 'seed': 0, 'subsample': 0.638826127489421}\n",
      "Score (Macro F1): 0.8508 | Loss (1-F1): 0.1492 | Trees: 87                        \n",
      "100%|██████████| 100/100 [24:11<00:00, 14.51s/trial, best loss: 0.1444410904773532]\n",
      "\n",
      "Optimization finished in 1451.46 seconds.\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "print(\"\\nStarting Hyperopt optimization (minimizing 1 - Macro F1)...\")\n",
    "start_time = time.time()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=xgb_search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100, # Increased evaluations slightly\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(0)\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nOptimization finished in {end_time - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters found:\n",
      "{'colsample_bylevel': 0.9007742037358686, 'colsample_bynode': 0.7869045948709822, 'colsample_bytree': 0.7960310510235896, 'gamma': 0.9386086236457385, 'learning_rate': 0.01760309617897438, 'max_depth': 10, 'min_child_weight': 10, 'n_estimators': 600, 'reg_alpha': 0.38561762932977844, 'reg_lambda': 4.830911678159625, 'subsample': 0.8125851393810649}\n",
      "\n",
      "Best validation loss (1 - Macro F1): 0.1444\n",
      "Corresponding best validation Macro F1 Score: 0.8556\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest hyperparameters found:\")\n",
    "best['max_depth'] = int(best['max_depth'])\n",
    "best['min_child_weight'] = int(best['min_child_weight'])\n",
    "best['n_estimators'] = int(best['n_estimators'])\n",
    "print(best)\n",
    "\n",
    "best_trial = trials.best_trial\n",
    "best_loss = best_trial['result']['loss']\n",
    "best_f1 = 1.0 - best_loss # Calculate the best F1 score from the best loss\n",
    "print(f\"\\nBest validation loss (1 - Macro F1): {best_loss:.4f}\")\n",
    "print(f\"Corresponding best validation Macro F1 Score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.9007742037358686,\n",
       " 'colsample_bynode': 0.7869045948709822,\n",
       " 'colsample_bytree': 0.7960310510235896,\n",
       " 'gamma': 0.9386086236457385,\n",
       " 'learning_rate': 0.01760309617897438,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 10,\n",
       " 'n_estimators': 600,\n",
       " 'reg_alpha': 0.38561762932977844,\n",
       " 'reg_lambda': 4.830911678159625,\n",
       " 'subsample': 0.8125851393810649}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = {'colsample_bylevel': 0.9007742037358686,\n",
    " 'colsample_bynode': 0.7869045948709822,\n",
    " 'colsample_bytree': 0.7960310510235896,\n",
    " 'gamma': 0.9386086236457385,\n",
    " 'learning_rate': 0.01760309617897438,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 10,\n",
    " 'n_estimators': 600,\n",
    " 'reg_alpha': 0.38561762932977844,\n",
    " 'reg_lambda': 4.830911678159625,\n",
    " 'subsample': 0.8125851393810649}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(seed = 0, **best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLflow Run: xgboost_run (57e20e4c199e4dc1a80c35a10b327e62)\n",
      "Logged model parameters.\n",
      "Training the model...\n",
      "Model training complete.\n",
      "Evaluating the model on the validation set...\n",
      "Attempting to find custom threshold using find_threshold_binary_search for Recall[0] >= 0.9800\n",
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7561671\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Using threshold: Custom threshold 0.7562 aiming for Recall[0] >= 0.9800 (func achieved 0.9800)\n",
      "Calculating performance metrics...\n",
      "Validation Accuracy: 0.8629\n",
      "Validation Weighted F1-Score: 0.8496\n",
      "Validation Macro F1-Score: 0.7899\n",
      "Validation Recall Class 0: 0.9800\n",
      "Validation Recall Class 1: 0.5278\n",
      "Validation Precision Class 0: 0.8559\n",
      "Validation Precision Class 1: 0.9022\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8559    0.9800    0.9138     23806\n",
      "           1     0.9022    0.5278    0.6660      8318\n",
      "\n",
      "    accuracy                         0.8629     32124\n",
      "   macro avg     0.8790    0.7539    0.7899     32124\n",
      "weighted avg     0.8679    0.8629    0.8496     32124\n",
      "\n",
      "Logged validation metrics (rounded to 4 decimals).\n",
      "Generating Confusion Matrix plot...\n",
      "Saved Confusion Matrix plot to: confusion_matrix_val.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAHqCAYAAADyPMGQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABA4klEQVR4nO3deXhN1/7H8c9JZE4kMYUogpjVXGoMRdBSamxpxdheQ6tm6lKhqkXNVVNrKpe2ilJVU1tabs2qqoh5HkKQmCLZvz/8cq4jCSuEhL5fz5PncdZeZ+/vPpKTT9Zeex2bZVmWAAAAcF9OaV0AAADAk4LgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBPy//fv3KzQ0VL6+vrLZbFq8eHGq7v/w4cOy2WyaOXNmqu73SVa9enVVr149Vfd57Ngxubu767fffkvxcwcPHiybzabz58+nak0P6lHUY/qa//zzz7LZbPr5559T7dhPs9jYWOXKlUuTJk1K61LwiBGckK4cOHBAb731lvLlyyd3d3dlzJhRlStX1rhx43Tt2rVHeuywsDDt2rVLw4YN05w5c1SuXLlHerzHqU2bNrLZbMqYMWOSr+P+/ftls9lks9k0atSoFO//5MmTGjx4sHbs2JEK1T6cIUOGqEKFCqpcubL9l7/JFx6tPXv2qG7duvL29lamTJn0xhtv6Ny5c/d93v3+D4cNG2bvO3PmzGT7nT59OtG+r1y5oj59+ihv3rxyc3NTzpw51bRpU129etXeZ82aNWrXrp0KFiwoT09P5cuXTx06dNCpU6cc9uXi4qIePXpo2LBhun79+kO8UkjvMqR1AUCC77//Xs2aNZObm5tat26t4sWL6+bNm/r111/Vu3dv7d69W1OnTn0kx7527Zo2btyoAQMGqGvXro/kGHny5NG1a9fk4uLySPZ/PxkyZNDVq1e1dOlSNW/e3GHb3Llz5e7u/sBv+CdPnlR4eLiCgoJUqlQp4+etXLnygY6XnHPnzmnWrFmaNWuWJKlIkSKaM2eOQ5/+/fvL29tbAwYMSNVjI3nHjx9XtWrV5Ovrqw8//FDR0dEaNWqUdu3apU2bNsnV1TXZ5yb1fyhJc+bM0cqVKxUaGppo25AhQ5Q3b16HNj8/P4fHly5dUkhIiI4fP64333xTwcHBOnfunNavX68bN27I09NTktS3b19duHBBzZo1U4ECBXTw4EFNnDhRy5Yt044dO5Q9e3b7Ptu2bat+/fpp3rx5ateuXUpeIjxJLCAdOHjwoOXt7W0VLlzYOnnyZKLt+/fvt8aOHfvIjn/kyBFLkjVy5MhHdoy0FBYWZnl5eVmhoaFWo0aNEm0vUKCA1aRJkwd+DTZv3mxJsmbMmGHUPyYmJsXHMDF69GjLw8PDunLlSrJ9ihUrZoWEhCS57f3337ckWefOnUvxsePi4qxr166l+Hn38jD1JCckJCTZ87/TTz/9ZEmyfvrpp4c+ZqdOnSwPDw/ryJEj9rZVq1ZZkqwpU6Y80D6Dg4OtAgUKOLTNmDHDkmRt3rzZqCY/Pz/r4MGD9+z3yy+/WHFxcYnaJFkDBgxI1L9+/fpW1apVDc4ATyou1SFdGDFihKKjo/X5558rR44cibYHBwerW7du9se3bt3S0KFDlT9/frm5uSkoKEjvvfeebty44fC8oKAg1a9fX7/++qvKly8vd3d35cuXT7Nnz7b3GTx4sPLkySNJ6t27t2w2m4KCgiTdvsSV8O87Jcw9udOqVatUpUoV+fn5ydvbW4UKFdJ7771n357cHKe1a9eqatWq8vLykp+fnxo2bKg9e/YkebyIiAi1adNGfn5+8vX1Vdu2bR0uK9xPy5Yt9cMPPygqKsretnnzZu3fv18tW7ZM1P/ChQvq1auXnn32WXl7eytjxoyqV6+edu7cae/z888/67nnnpN0+y/uhEsjCedZvXp1FS9eXFu3blW1atXk6elpf13unm8TFhYmd3f3ROdfp04d+fv76+TJk/c8v8WLF6tChQry9vY2fk2SEhUVdd/X2WazqWvXrpo7d66KFSsmNzc3rVixQpJ04sQJtWvXTgEBAXJzc1OxYsX0xRdfJDrOhAkTVKxYMXl6esrf31/lypXTvHnzHqge05+JpBw/flyNGjWSl5eXsmXLpu7duxs9z9TChQtVv3595c6d295Wq1YtFSxYUF999VWK97dp0yZFRESoVatWyfa5cuWK4uLiktwWFRWlGTNm6M0331TevHl18+bNZM+3WrVqcnJyStSWKVOmRN+nklS7dm39+uuvunDhQgrOCE8SghPShaVLlypfvnyqVKmSUf8OHTpo0KBBKlOmjMaMGaOQkBANHz5cr776aqK+ERERatq0qWrXrq1PPvlE/v7+atOmjXbv3i1Jaty4scaMGSNJeu211zRnzhyNHTs2RfXv3r1b9evX140bNzRkyBB98sknevnll+87QXn16tWqU6eOzp49q8GDB6tHjx7asGGDKleurMOHDyfq37x5c125ckXDhw9X8+bNNXPmTIWHhxvX2bhxY9lsNn377bf2tnnz5qlw4cIqU6ZMov4HDx7U4sWLVb9+fY0ePVq9e/fWrl27FBISYg8xRYoU0ZAhQyRJb775pubMmaM5c+aoWrVq9v1ERkaqXr16KlWqlMaOHasaNWokWd+4ceOUNWtWhYWF2X/pTZkyRStXrtSECRMUGBiY7LnFxsZq8+bNSZ5HSpm+zmvXrlX37t3VokULjRs3TkFBQTpz5oyef/55rV69Wl27dtW4ceMUHBys9u3bO3xfTZs2Te+8846KFi2qsWPHKjw8XKVKldLvv//+QPWk5GfiTteuXVPNmjX1448/qmvXrhowYIDWr1+vPn36JOp79epVnT9//r5fFy9etD/nxIkTOnv2bJJzBsuXL6/t27ffs76kzJ07V5KSDU41atRQxowZ5enpqZdffln79+932P7rr7/q+vXrCg4OVtOmTeXp6SkPDw9VrlzZaJ5edHS0oqOjlSVLlkTbypYtK8uytGHDhhSfF54QaT3kBVy6dMmSZDVs2NCo/44dOyxJVocOHRzae/XqZUmy1q5da2/LkyePJclat26dve3s2bOWm5ub1bNnT3vboUOHkrxMFRYWZuXJkydRDQmXUBKMGTPmvpdUEo5x5+WsUqVKWdmyZbMiIyPtbTt37rScnJys1q1bJzpeu3btHPb5yiuvWJkzZ072mHeeh5eXl2VZltW0aVOrZs2almXdvryUPXt2Kzw8PMnX4Pr164kuUxw6dMhyc3OzhgwZYm+716W6kJAQS5I1efLkJLfdfdnoxx9/tCRZH3zwgf0SblKXF+8WERFhSbImTJhwz34ml+pMXmdJlpOTk7V7926H9vbt21s5cuSwzp8/79D+6quvWr6+vtbVq1cty7Kshg0bWsWKFbtnrab1pORn4u7XfOzYsZYk66uvvrK3xcTEWMHBwYku1SXUc7+vO39mEr43Zs+enej8evfubUmyrl+/fs/X4U63bt2yAgICrPLlyyfatmDBAqtNmzbWrFmzrEWLFln//ve/LU9PTytLlizW0aNH7f1Gjx5tSbIyZ85slS9f3po7d641adIkKyAgwPL3909yusCdhg4dakmy1qxZk2jbyZMnLUnWxx9/bHxOeLIw4oQ0d/nyZUmSj4+PUf/ly5dLknr06OHQ3rNnT0m3J5nfqWjRoqpatar9cdasWVWoUCEdPHjwgWu+W8LE0yVLlig+Pt7oOadOndKOHTvUpk0bZcqUyd5eokQJ1a5d236ed/rXv/7l8Lhq1aqKjIy0v4YmWrZsqZ9//lmnT5/W2rVrdfr06SQv00mSm5ub/TJFXFycIiMj7Zcht23bZnxMNzc3tW3b1qhvaGio3nrrLQ0ZMkSNGzeWu7u7pkyZct/nRUZGSpL8/f2N60qO6escEhKiokWL2h9blqWFCxeqQYMGsizLYRSmTp06unTpkv118/Pz0/Hjx7V58+aHrielPxN3Wr58uXLkyKGmTZva2zw9PfXmm28m6tu6dWutWrXqvl8JI0KS7Hdxurm5Jdqfu7u7Qx8Ta9as0ZkzZ5IcbWrevLlmzJih1q1bq1GjRho6dKh+/PFHRUZGOtx9Fx0dLen25dY1a9aoZcuW6tSpkxYvXqyLFy/q008/Tfb469atU3h4uJo3b64XXngh0faE77/0sqQFUh931SHNZcyYUdLtOQkmjhw5IicnJwUHBzu0Z8+eXX5+fjpy5IhD+53zKhL4+/s7XE54WC1atND06dPVoUMH9evXTzVr1lTjxo3VtGnTRPMj7jwPSSpUqFCibUWKFNGPP/6omJgYeXl52dvvPpeEN+mLFy/aX8f7efHFF+Xj46MFCxZox44deu655xQcHJzkpcH4+HiNGzdOkyZN0qFDhxzmjGTOnNnoeJKUM2fOe945dbdRo0ZpyZIl2rFjh+bNm6ds2bIZP9eyLOO+yTF9ne++c+vcuXOKiorS1KlTk70D9OzZs5Ju3621evVqlS9fXsHBwQoNDVXLli1VuXLlFNeT0p+JOx05ckTBwcGJ5uwl9X2ZL18+5cuXL9l9JcXDw0OSkpxDlHAXZ0IfE3PnzpWzs7NatGhh1L9KlSqqUKGCVq9enaimBg0aOMyHe/7555U3b95kL7P9/fffeuWVV1S8eHFNnz49yT4J338scfH0IjghzWXMmFGBgYH6888/U/Q80zcmZ2fnJNtNfsEmd4y7J516eHho3bp1+umnn/T9999rxYoVWrBggV544QWtXLky2RpS6mHOJYGbm5saN26sWbNm6eDBgxo8eHCyfT/88EMNHDhQ7dq109ChQ5UpUyY5OTnp3XffNR5Zk1L2i1GStm/fbg8Yu3bt0muvvXbf5yQEudQIxKav893nlfCavP766woLC0tyHyVKlJB0Oxzv3btXy5Yt04oVK7Rw4UJNmjRJgwYNSjR/ybSeR/3LOmFuz/04Ozsra9askmS/2ePudY8S2jJlypTkaFRSrl27pkWLFqlWrVoKCAgwrjtXrlzau3ev/XHCXLmk9pEtW7Ykv4eOHTtmXyB3+fLlyY6QJzw3qflPeDoQnJAu1K9fX1OnTtXGjRtVsWLFe/bNkyeP4uPjtX//fhUpUsTefubMGUVFRdnvkEsN/v7+DnegJUjqL3gnJyfVrFlTNWvW1OjRo/Xhhx9qwIAB+umnn1SrVq0kz0OSwxt6gr///ltZsmRxGG1KTS1bttQXX3whJyene04e/uabb1SjRg19/vnnDu1RUVEOvxhS8xd2TEyM2rZtq6JFi6pSpUoaMWKEXnnlFfude8nJnTu3PDw8dOjQoVSrJaWyZs0qHx8fxcXFJfl/fjcvLy+1aNFCLVq00M2bN9W4cWMNGzZM/fv3t1/GMvEwPxN58uTRn3/+KcuyHP4fk/q+HDVqlNHNCHny5LGPYObMmVNZs2bVli1bEvXbtGlTitb9+u6773TlypV73k2XlIMHD9qDnHR7Ard0e+L63U6ePKnChQs7tEVGRio0NFQ3btzQmjVrkrzzN0HC99+d/w94ujDHCelCnz595OXlpQ4dOujMmTOJth84cEDjxo2TdPtSk6REd76NHj1akvTSSy+lWl358+fXpUuX9Mcff9jbTp06pUWLFjn0S+rW44RfCMnd5pwjRw6VKlVKs2bNcghnf/75p1auXGk/z0ehRo0aGjp0qCZOnOiwgN/dnJ2dE41qfP3114l+4SQEvKRCZkr17dtXR48e1axZszR69GgFBQUpLCzsvrfHu7i4qFy5ckn+gn5cnJ2d1aRJEy1cuDDJEdQ7V8pOmJOVwNXVVUWLFpVlWYqNjU3RcR/mZ+LFF1/UyZMn9c0339jbrl69muSlxgeZ4yRJTZo00bJly3Ts2DF725o1a7Rv3z41a9bM3hYbG6u///47ydEp6fYdoJ6ennrllVeS3J7USuTLly/X1q1bVbduXXtboUKFVLJkSS1ZssRhLtLKlSt17Ngx1a5d294WExOjF198USdOnNDy5ctVoECBJI+dYOvWrbLZbPf9AxBPLkackC7kz59f8+bNU4sWLVSkSBGHlcM3bNigr7/+Wm3atJEklSxZUmFhYZo6daqioqIUEhKiTZs2adasWWrUqFGyt7o/iFdffVV9+/bVK6+8onfeeUdXr17VZ599poIFCzpMjh4yZIjWrVunl156SXny5NHZs2c1adIkPfPMM6pSpUqy+x85cqTq1aunihUrqn379rp27ZomTJggX1/fe15Ce1hOTk7697//fd9+9evX15AhQ9S2bVtVqlRJu3bt0ty5cxPNc8mfP7/8/Pw0efJk+fj4yMvLSxUqVEg0B+h+1q5dq0mTJun999+3LyswY8YMVa9eXQMHDtSIESPu+fyGDRtqwIABunz5svGcr9T20Ucf6aefflKFChXUsWNHFS1aVBcuXNC2bdu0evVqe8gODQ1V9uzZVblyZQUEBGjPnj2aOHGiXnrpJeMbJRI8zM9Ex44dNXHiRLVu3Vpbt25Vjhw5NGfOHPvK2Xd6kDlOkvTee+/p66+/Vo0aNdStWzdFR0dr5MiRevbZZx1uGjhx4oSKFCmisLCwROudXbhwQT/88IOaNGmS7DpdlSpVUunSpVWuXDn5+vpq27Zt+uKLL5QrVy6HNdUkacyYMapdu7aqVKmit956S5cuXdLo0aNVsGBBderUyd6vVatW2rRpk9q1a6c9e/Y4rN3k7e2tRo0aOex31apVqly5cormAOIJk0Z38wFJ2rdvn9WxY0crKCjIcnV1tXx8fKzKlStbEyZMcLhlOTY21goPD7fy5s1rubi4WLly5bL69++f6LbmPHnyWC+99FKi49x9S3ZyyxFYlmWtXLnSKl68uOXq6moVKlTI+vLLLxMtR7BmzRqrYcOGVmBgoOXq6moFBgZar732mrVv375Ex7j7lv3Vq1dblStXtjw8PKyMGTNaDRo0sP766y+HPsmtIJ2wUvKhQ4eSfU0ty3E5guQktxxBz549rRw5clgeHh5W5cqVrY0bNya5jMCSJUusokWLWhkyZHA4z5CQkGRvu79zP5cvX7by5MljlSlTxoqNjXXo1717d8vJycnauHHjPc/hzJkzVoYMGaw5c+Yk2+dBVg5P6nWWZHXp0iXZOrp06WLlypXLcnFxsbJnz27VrFnTmjp1qr3PlClTrGrVqlmZM2e23NzcrPz581u9e/e2Ll269ED1mP5MJPV/d+TIEevll1+237rfrVs3a8WKFam2crhlWdaff/5phYaGWp6enpafn5/VqlUr6/Tp0w59Er4Hw8LCEj1/8uTJliTru+++S/YYAwYMsEqVKmX5+vpaLi4uVu7cua1OnTolOk6CVatWWc8//7zl7u5uZcqUyXrjjTesU6dOOfRJWNIkqa+7lyqJioqyXF1drenTp5u9KHgi2SwrFW5BAYB0on379tq3b5/Wr1+f1qXgH2bs2LEaMWKEDhw4kOIbIvDkIDgBeKocPXpUBQsW1Jo1a5K8tR94FGJjY5U/f37169dPnTt3Tuty8AgRnAAAAAxxVx0AAIAhghMAAIAhghMAAIAhghMAAIAhghMAAIChp3LlcI/SXdO6BADp1MXNE9O6BADpkLthImLECQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwBDBCQAAwFCGtC4AuFOvdqFq9EJJFQwK0LUbsfp950ENGLdE+4+ctfeZMOBVvVChkHJk9VX0tRv6785D+ve4Jdp3+IwkKZOvl2YMC9OzBXMqk6+nzl2I1rKf/9CgiUt1Jea6JKlSqXz6oFtDFQzKLk93Fx09dUGfL/xNE+b+5FDPW82rqXtYTQVkzqhd+06ox8dfa8vuI4/vBQHwwD6fNlXjx36iVq+3Vp/+A3TixHG9GFozyb4jR49VaJ169sdLFn2rObNn6Mjhw/Ly9lZoaF29N/D9x1U60jGCE9KVqmWCNXnBOm3dfUQZMjgrvGsDLfusq0o3/kBXr9+UJG3fc0zzf9isY6cuKpOvpwb86yUtm9RFheu/r/h4S/Hx8Vr2yx8Kn7RM5y9eUb5cWTW2X3NN8PVSm/dmSpJirt3U5AXrtGvfCcVcu6lKpfNr4r9fVcy1m/ri298kSU1Dy+jjnq/o7WELtPnPw+rasoa+m9RFJRsN0bmL0Wn1EgEw8OeuP/TN1/NVsGAhe1v27Dm05udfHfp98/UCzZrxuapUqWZvmz1zhmbP+kI9evbRsyVK6tq1qzp54sRjqx3pm82yLCuti0htHqW7pnUJSCVZ/L11bO1HqtV+jH7bdiDJPsULBGrzV++paIPBOnT8fJJ9Or8Wou6ta6lAvYHJHmv+qA6KuXZT7QfOliStm91LW3cfUfePv5Yk2Ww2RawYqs/m/6JRM1Y95JkhrVzcPDGtS8AjdjUmRi2aNdaAge9r2pTPVKhQYfXpPyDJvs2bNFKRokUVPvRDSdLlS5dU+4VqGv/pZFV4vuLjLBtpzN1wKIk5TkjXMnq7S5IuXrqa5HZPd1e1fvl5HTp+XsdPX0yyT46svmr4Qimt37o/2eOULPSMKpTMp/XbbvdxyeCs0kVyae3ve+19LMvS2t/3qnyJvA96OgAegw8/GKJq1UL0fMVK9+z31+4/tffvPXqlcVN728aNvyk+Pl5nz5xRowb1VPuFaurdo5tOnzr1qMvGEyJNL9WdP39eX3zxhTZu3KjTp09LkrJnz65KlSqpTZs2ypo1a1qWhzRms9k0sldTbdh+QH8dcHzTerNZVQ17t5G8Pd2099BpvdRpomJvxTn0mTW8jeqHlJCnh6uW/bJLnYbMS3SMiBVDlcXfWxmcnfXBlOWauWijpNsjXRkyOOvshSsO/c9GXlahoIBUPlMAqeWH5d9rz56/NG/BN/ftu2jhN8qXL79KlS5jbzt+7Lji4y1NnzZZffoNkI+PjyaOH6u3OrbVN99+JxdX10dZPp4AaTbitHnzZhUsWFDjx4+Xr6+vqlWrpmrVqsnX11fjx49X4cKFtWXLlvvu58aNG7p8+bLDlxUfd9/nIf0b27+5igXnUOt+MxJtm//DZj3/2u1LePuPntOXH7eTm6vj3wF9Ri1UxZYfq+m7U5TvmSz6uGfjRPup2W6sKrcaqbeHzVfXljXUvG7ZR3Y+AB6t06dOacRHwzT845Fyc3O7Z9/r16/rh+XL1KhJU4d2y4rXrVux6tv/36pcpapKlCylj0aO1tEjR7Rp0++Psnw8IdJsxOntt99Ws2bNNHnyZNlsNodtlmXpX//6l95++21t3LjxnvsZPny4wsPDHdqcA56TS47yqV4zHp8xfZvpxarFVav9WJ04G5Vo++Xo67ocfV0Hjp7Tpj8O69S6EWr4Qkl9tWKrvc+ZyCs6E3lF+w6f0cVLMVozo4c+mrZCp89ftvc5cjJSkrQ74qSyZfbRgLde1Fcrtur8xWjduhWnbJl8HI6bLXNGnY68LADpz19/7daFyEi92ux/fyTFxcVp65bNmv+fudq8fZecnZ0lSatWrtC1a9fV4OVGDvvI8v9XOvLnD7a3ZcqUSX7+/lyug6Q0HHHauXOnunfvnig0Sbcv0XTv3l07duy473769++vS5cuOXxlCGDU4Ek2pm8zvfxCSdV9a7w92NyLzWaTTTa5uiT/d4DN6fb32b36ODnZ7KNWsbfitH3PMdWo8L87cmw2m2qUL6hNfxwyPRUAj1GF55/XN4uXasHCxfavYsWK68X6DbRg4WJ7aJKkxd8uVPUaLyhTpkwO+0i4bHf48P9+zi9FRSnq4kXlCAx8PCeCdC3NRpyyZ8+uTZs2qXDhwklu37RpkwIC7j+XxM3NLdGQrM3JOZneSO/G9m+uFvXKqVn3qYqOua6AzLdHfC5FX9f1G7EKyplZTeuU1ZqNe3T+YrRyBvipZ9tQXbsRqx9/3S1JqlOlqLJlyqitu48o+uoNFc2fQx92b6QN2w/o6KkLkm6vz3Ts9AXt/f+1n6qUCda7b9TUpP/8Yq9l/JdrNW3IG9r611Ft+f/lCDw93DR7yX8f86sCwISXl7cKFCjo0Obh6Sk/Xz+H9qNHjmjrls369LOpifYRFJRXNV6oqY+HD9OgwUPk5e2t8WNGKyhvPj1XvsIjPwekf2kWnHr16qU333xTW7duVc2aNe0h6cyZM1qzZo2mTZumUaNGpVV5SCNvNb+9lsqq6e86tHccNEdfLv1dN27eUuXS+dW1ZXX5Z/TU2cgr+nVbhGq0+cS+ttK167Fq17iSRvRqLDeXDDp+JkpL1u7QqC/+t4SAk5NNQ95+WUE5M+vWrXgdPH5e/x6/RNO/+c3e55uV25TF31uDOr2kgMw++mPvCTXs8mmiCeMAniyLFy1UQEB2VaxcJcntHwwfoZEff6iund+Sk81JZZ97Tp9NmS4XF5fHXCnSozRdx2nBggUaM2aMtm7dqri42xO6nZ2dVbZsWfXo0UPNmzd/oP2yjhOA5LCOE4CkmK7jlC4WwIyNjdX587cXLsySJctDp3qCE4DkEJwAJMU0OKWLj1xxcXFRjhw50roMAACAe2LlcAAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEMEJwAAAEOpEpyioqJSYzcAAADpWoqD08cff6wFCxbYHzdv3lyZM2dWzpw5tXPnzlQtDgAAID1JcXCaPHmycuXKJUlatWqVVq1apR9++EH16tVT7969U71AAACA9CJDSp9w+vRpe3BatmyZmjdvrtDQUAUFBalChQqpXiAAAEB6keIRJ39/fx07dkyStGLFCtWqVUuSZFmW4uLiUrc6AACAdCTFI06NGzdWy5YtVaBAAUVGRqpevXqSpO3btys4ODjVCwQAAEgvUhycxowZo6CgIB07dkwjRoyQt7e3JOnUqVPq3LlzqhcIAACQXtgsy7LSuojU5lG6a1qXACCdurh5YlqXACAdcjccSjLq9t133xkf+OWXXzbuCwAA8CQxCk6NGjUy2pnNZmOCOAAAeGoZBaf4+PhHXQcAAEC691AfuXL9+vXUqgMAACDdS3FwiouL09ChQ5UzZ055e3vr4MGDkqSBAwfq888/T/UCAQAA0osUB6dhw4Zp5syZGjFihFxdXe3txYsX1/Tp01O1OAAAgPQkxcFp9uzZmjp1qlq1aiVnZ2d7e8mSJfX333+nanEAAADpSYqD04kTJ5JcITw+Pl6xsbGpUhQAAEB6lOLgVLRoUa1fvz5R+zfffKPSpUunSlEAAADpUYo/cmXQoEEKCwvTiRMnFB8fr2+//VZ79+7V7NmztWzZskdRIwAAQLqQ4hGnhg0baunSpVq9erW8vLw0aNAg7dmzR0uXLlXt2rUfRY0AAADpAp9VB+Afhc+qA5CUVP2suqRs2bJFe/bskXR73lPZsmUfdFcAAABPhBQHp+PHj+u1117Tb7/9Jj8/P0lSVFSUKlWqpPnz5+uZZ55J7RoBAADShRTPcerQoYNiY2O1Z88eXbhwQRcuXNCePXsUHx+vDh06PIoaAQAA0oUUz3Hy8PDQhg0bEi09sHXrVlWtWlVXr15N1QIfBHOcACSHOU4AkmI6xynFI065cuVKcqHLuLg4BQYGpnR3AAAAT4wUB6eRI0fq7bff1pYtW+xtW7ZsUbdu3TRq1KhULQ4AACA9MbpU5+/vL5vNZn8cExOjW7duKUOG2+NaCf/28vLShQsXHl21hrhUByA5XKoDkJRUXY5g7NixD1EKAADA08EoOIWFhT3qOgAAANK9B14AU5KuX7+umzdvOrRlzJjxoQoCAABIr1I8OTwmJkZdu3ZVtmzZ5OXlJX9/f4cvAACAp1WKg1OfPn20du1affbZZ3Jzc9P06dMVHh6uwMBAzZ49+1HUCAAAkC6k+FLd0qVLNXv2bFWvXl1t27ZV1apVFRwcrDx58mju3Llq1arVo6gTAAAgzaV4xOnChQvKly+fpNvzmRKWH6hSpYrWrVuXutUBAACkIykOTvny5dOhQ4ckSYULF9ZXX30l6fZIVMKH/gIAADyNUhyc2rZtq507d0qS+vXrp08//VTu7u7q3r27evfuneoFAgAApBcp/pDfux05ckRbt25VcHCwSpQokVp1PRRWDgeQHFYOB5AU05XDHzo4pUf7zlxN6xIApFNxcU/dWx6AVFAk0Muon1G+Gj9+vPGB33nnHeO+AAAATxKjEae8efOa7cxm08GDBx+6qIfFiBOA5DDiBCApqTrilHAXHQAAwD9Ziu+qAwAA+KciOAEAABgiOAEAABgiOAEAABgiOAEAABh6oOC0fv16vf7666pYsaJOnDghSZozZ45+/fXXVC0OAAAgPUlxcFq4cKHq1KkjDw8Pbd++XTdu3JAkXbp0SR9++GGqFwgAAJBepDg4ffDBB5o8ebKmTZsmFxcXe3vlypW1bdu2VC0OAAAgPUlxcNq7d6+qVauWqN3X11dRUVGpURMAAEC6lOLglD17dkVERCRq//XXX5UvX75UKQoAACA9SnFw6tixo7p166bff/9dNptNJ0+e1Ny5c9WrVy916tTpUdQIAACQLhh9Vt2d+vXrp/j4eNWsWVNXr15VtWrV5Obmpl69euntt99+FDUCAACkCzbLsh7oo8Jv3rypiIgIRUdHq2jRovL29k7t2h7YvjNX07oEAOlUXNwDveUBeMoVCfQy6pfiEacErq6uKlq06IM+HQAA4ImT4uBUo0YN2Wy2ZLevXbv2oQoCAABIr1IcnEqVKuXwODY2Vjt27NCff/6psLCw1KoLAAAg3UlxcBozZkyS7YMHD1Z0dPRDFwQAAJBePfDk8LtFRESofPnyunDhQmrs7qEwORxAcpgcDiApppPDH+hDfpOyceNGubu7p9buAAAA0p0UX6pr3Lixw2PLsnTq1Clt2bJFAwcOTLXCAAAA0psUBydfX1+Hx05OTipUqJCGDBmi0NDQVCsMAAAgvUlRcIqLi1Pbtm317LPPyt/f/1HVBAAAkC6laI6Ts7OzQkNDFRUV9YjKAQAASL9SPDm8ePHiOnjw4KOoBQAAIF1LcXD64IMP1KtXLy1btkynTp3S5cuXHb4AAACeVsbrOA0ZMkQ9e/aUj4/P/558x0evWJYlm82muLi41K8yhVjHCUByWMcJQFJM13EyDk7Ozs46deqU9uzZc89+ISEhRgd+lAhOAJJDcAKQFNPgZHxXXUK+Sg/BCAAAIC2kaI7TnZfmAAAA/mlStI5TwYIF7xue0sNn1QEAADwKKQpO4eHhiVYOBwAA+Kcwnhzu5OSk06dPK1u2bI+6pofG5HAAyWFyOICkmE4ON57jxPwmAADwT2ccnAwHpgAAAJ5axnOc4uPjH2UdAAAA6V6KP3IFAADgn4rgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYIjgBAAAYChDWhcA3MvyxV/ph8Xf6Mzpk5Kk3Hnz6dWwN1Xu+SqSpFMnjumLSWP01x/bFRsbqzIVKumtbn3lnymzJOnMqZNaMGuqdm7brKgLkcqUJauqh76o5m90kIuLi/042zZt0LwvJuvooQNycXVVsZJl1L5LTwXkCHz8Jw0gxRbOm6E50yaofpPX1KFrb0nSpE8+0M5tm3Tx/Dm5e3iocLGSav3WO3omd17783Zu/V3zZnymIwcj5O7uoRp16uv1Dl3k7Py/X4+HD+zTlHEfKeLvv5TRz18vvdJCjV9r87hPEemEzbIsK62LSG37zlxN6xKQSjb99oucnJwU+ExuWZLWrFiqRf+ZpbGfz1dA9kC93ba58uYvqJbt/iVJ+vLzSbpw/pxGTZ4tJycnbf39N61fu1LVatZV4DO5dORghCaOHKrqoS+pfZcekqTTJ0+oc+vGatT8ddV+qZFioqM1feIoXbt6VeM+/08anj0ehbi4p+4t7x9v/9+7NTK8rzw9vVS8dDl7cPpx6UI9kztIWQJyKPryJc2fNUWHIvZpyrylcnZ21qGIferd+Q01a9Ve1WrVVeS5c5o8ZpjKPl9VbTt1lyRdjYlW5zdeUcmy5dWkZTsdORShCSPC1b5LT9Vp0CQtTxuprEigl1E/LtUhXStfOUTlKlZVYK48ypkrj1p37Cp3D0/t3f2H/tq1Q2dPn9S774UrKH8BBeUvoO7vDVHE3r/0x7ZNkqSyFSrr3f7hKlO+orIHPqMKVarrlVdba+O6tfZjHNj3l+Lj4vV6hy7KkTOXggsVUeNXW+tQxF7duhWbVqcOwMC1a1c1ZtgAdek1UF4+GR221WnQRMVKllVA9kDlL1hErdp11vmzp3X2/0ewf/3pRwXlK6AWYW8qR87cKl6qrFq/1U0/LP5K167GSJJ+Wf2Dbt2KVdc+g5U7b35VfaGO6jd+Vd99PfexnyvSB4ITnhhxcXFat2aFrl+/psLFS+hW7E3JZpOLi6u9j6urm2xOTvrrjx3J7icmOlo+Gf/3Bpu/YFHZnGxavXyJ4uLiFBN9RWtXfq+SZSsoQwaXZPcDIO1NHfuRyj5fRSXLVrhnv+vXrmnNiu8UkCOnsmTLLkmKjY2Vi6urQz83N3fdvHlDEfv2SJL27v5DRUuUcbi0X/q5ijpx7LCir1xO5bPBkyBdB6djx46pXbt2aV0G0tjhA/vVrE4lNa5VQZM+GaYBH3yi3EH5VajYs3J399DMyeN0/fo1Xb92TV9MGq34uDhdiDyf5L5OHj+qZd/OV92Xm9rbsgfm1JBPJmnOtIlqXKuCXn2xmiLPnlHf8BGP6xQBPID1a3/Ugf1/642ObyfbZ/nir/Rqvcp69cXK2vb7Bg0eOckegko/V1F7d/+hdWtWKC4uTpHnzmrB7KmSpIv//x5y8WKk/PwzOezTz//2HMqLF5J+n8HTLV0HpwsXLmjWrFn37HPjxg1dvnzZ4evmjRuPqUI8DjlzB2nc5/P1yeTZqtewmcZ8OEhHDx+Qr18m9Q0foU0b1ql5ncpq8WJVRUdHK3/BInJysiXaT+S5sxrcu6sqV6+lOg0a29svRp7XxBFD9ULdBho95UsNHz9dGVxc9NGgXnoKpwACT4VzZ09r+sSR6jHgA7m6uiXbL6RWPY2e9h8NGztNgblya2R4X928eft3ROnnKirsrXc1ecyHahb6vDq3bqSyFW7feOJkS/weAkhpfFfdd999d8/tBw8evO8+hg8frvDwcIe2rj3f09u9BzxUbUg/XFxcFPhMbklScKGi2v/3bn339X/Utfe/VaZ8RU2bv1SXoi7K2TmDvH189EajWsoeWMdhH5Hnz+q9bh1VuHgJde090GHb94sWyNPbW207vWtv6/nvYWrbtK72/rVLhYuVeOTnCCBlDuzbo0sXL6jHm63sbfHxcfrrj21avugrfb3yv3J2dpaXt4+8vH0U+ExuFSxaQq+/HKL/rv9J1WrWlSQ1bP66Xm7WShcjz8vLx0dnT5/UnGkTFBD4jCTJ3z+zoi5ecDh21MXI29syZXlMZ4v0JE2DU6NGjWSz2e75V73tPqm/f//+6tGjh0Pb0ai4VKkP6ZMVbyk29qZDm6+fvyRp59ZNunTxgspXDrFvizx3OzQFFyqibv3C5eTkONB64/p1Odkc2xL6WPHxj+IUADykkmXKa9wXXzm0Tfh4sHLmDlLj19rI2dk58ZMsS5alRO8fNptNmbJklSStX/OjsmTLrnwFCkuSChUrobmff6pbt2Ltcx53bPmvcuYKkvddk9Hxz5CmwSlHjhyaNGmSGjZsmOT2HTt2qGzZsvfch5ubm9zcHIdpXa+xHMHTYtaU8SpbobKyBuTQtasx+mX1D9q1Y4vCR02SJK1evkTP5MkrXz9//b37D00bP1INm7XSM7mDJN0OTf3f6aBs2XOoXeceuhx10b5v/8y3/1osV7Gqlnw9V/+ZOUUhNevq6tWrmjNtorJlz6F8BQs/9nMGcH8enl7KkzfYoc3N3UM+GX2VJ2+wTp88rl9/WqlS5Z6Xr5+/Is+d1cL/zJCbm5v9cpwkLZo/S6XLV5KTzUkb16/Vt/+ZoV7vf2wPXtVq1tWCWVM1ccQQNX6tjY4eitCyb/+jdp17PtbzRfqRpsGpbNmy2rp1a7LB6X6jUXj6Xbp4QWM+HKgLkefl5eWtoPwFFD5qkko/97wk6fjRw5o1dYKiL19StuyBav5GezVs/rr9+du3/FenThzTqRPH1KaJ4+W7peu2S5JKli2vXoM+1MJ5s/Ttf2bJzc1dhYuV0OCRn8rNzf3xnSyAVOPq6qa/dm3X0oXzFHPlsnz9M6tYiTL6aMIMh8ne2zb9pq+//Fy3YmMVlL+A+n8wRmUrVLZv9/L20eCRn2rKuI/U861Wyujrpxat32QNp3+wNF0Ac/369YqJiVHdunWT3B4TE6MtW7YoJCQkye3JYQFMAMlhAUwASTFdAJOVwwH8oxCcACSFlcMBAABSGcEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAkM2yLCutiwAelRs3bmj48OHq37+/3Nzc0rocAOkE7w14UAQnPNUuX74sX19fXbp0SRkzZkzrcgCkE7w34EFxqQ4AAMAQwQkAAMAQwQkAAMAQwQlPNTc3N73//vtM/gTggPcGPCgmhwMAABhixAkAAMAQwQkAAMAQwQkAAMAQwQlPrU8//VRBQUFyd3dXhQoVtGnTprQuCUAaW7dunRo0aKDAwEDZbDYtXrw4rUvCE4bghKfSggUL1KNHD73//vvatm2bSpYsqTp16ujs2bNpXRqANBQTE6OSJUvq008/TetS8ITirjo8lSpUqKDnnntOEydOlCTFx8crV65cevvtt9WvX780rg5AemCz2bRo0SI1atQorUvBE4QRJzx1bt68qa1bt6pWrVr2NicnJ9WqVUsbN25Mw8oAAE86ghOeOufPn1dcXJwCAgIc2gMCAnT69Ok0qgoA8DQgOAEAABgiOOGpkyVLFjk7O+vMmTMO7WfOnFH27NnTqCoAwNOA4ISnjqurq8qWLas1a9bY2+Lj47VmzRpVrFgxDSsDADzpMqR1AcCj0KNHD4WFhalcuXIqX768xo4dq5iYGLVt2zatSwOQhqKjoxUREWF/fOjQIe3YsUOZMmVS7ty507AyPClYjgBPrYkTJ2rkyJE6ffq0SpUqpfHjx6tChQppXRaANPTzzz+rRo0aidrDwsI0c+bMx18QnjgEJwAAAEPMcQIAADBEcAIAADBEcAIAADBEcAIAADBEcAIAADBEcAIAADBEcAIAADBEcAIAADBEcAKQptq0aaNGjRrZH1evXl3vvvvuY6/j559/ls1mU1RUVLJ9bDabFi9ebLzPwYMHq1SpUg9V1+HDh2Wz2bRjx46H2g+A1EFwApBImzZtZLPZZLPZ5OrqquDgYA0ZMkS3bt165Mf+9ttvNXToUKO+JmEHAFITH/ILIEl169bVjBkzdOPGDS1fvlxdunSRi4uL+vfvn6jvzZs35erqmirHzZQpU6rsBwAeBUacACTJzc1N2bNnV548edSpUyfVqlVL3333naT/XV4bNmyYAgMDVahQIUnSsWPH1Lx5c/n5+SlTpkxq2LChDh8+bN9nXFycevToIT8/P2XOnFl9+vTR3R+Xefeluhs3bqhv377KlSuX3NzcFBwcrM8//1yHDx+2f1irv7+/bDab2rRpI0mKj4/X8OHDlTdvXnl4eKhkyZL65ptvHI6zfPlyFSxYUB4eHqpRo4ZDnab69u2rggULytPTU/ny5dPAgQMVGxubqN+UKVOUK1cueXp6qnnz5rp06ZLD9unTp6tIkSJyd3dX4cKFNWnSpGSPefHiRbVq1UpZs2aVh4eHChQooBkzZqS4dgAPhhEnAEY8PDwUGRlpf7xmzRplzJhRq1atkiTFxsaqTp06qlixotavX68MGTLogw8+UN26dfXHH3/I1dVVn3zyiWbOnKkvvvhCRYoU0SeffKJFixbphRdeSPa4rVu31saNGzV+/HiVLFlShw4d0vnz55UrVy4tXLhQTZo00d69e5UxY0Z5eHhIkoYPH64vv/xSkydPVoECBbRu3Tq9/vrrypo1q0JCQnTs2DE1btxYXbp00ZtvvqktW7aoZ8+eKX5NfHx8NHPmTAUGBmrXrl3q2LGjfHx81KdPH3ufiIgIffXVV1q6dKkuX76s9u3bq3Pnzpo7d64kae7cuRo0aJAmTpyo0qVLa/v27erYsaO8vLwUFhaW6JgDBw7UX3/9pR9++EFZsmRRRESErl27luLaATwgCwDuEhYWZjVs2NCyLMuKj4+3Vq1aZbm5uVm9evWybw8ICLBu3Lhhf86cOXOsQoUKWfHx8fa2GzduWB4eHtaPP/5oWZZl5ciRwxoxYoR9e2xsrPXMM8/Yj2VZlhUSEmJ169bNsizL2rt3ryXJWrVqVZJ1/vTTT5Yk6+LFi/a269evW56entaGDRsc+rZv39567bXXLMuyrP79+1tFixZ12N63b99E+7qbJGvRokXJbh85cqRVtmxZ++P333/fcnZ2to4fP25v++GHHywnJyfr1KlTlmVZVv78+a158+Y57Gfo0KFWxYoVLcuyrEOHDlmSrO3bt1uWZVkNGjSw2rZtm2wNAB4tRpwAJGnZsmXy9vZWbGys4uPj1bJlSw0ePNi+/dlnn3WY17Rz505FRETIx8fHYT/Xr1/XgQMHdOnSJZ06dUoVKlSwb8uQIYPKlSuX6HJdgh07dsjZ2VkhISHGdUdEROjq1auqXbu2Q/vNmzdVunRpSdKePXsc6pCkihUrGh8jwYIFCzR+/HgdOHBA0dHRunXrljJmzOjQJ3fu3MqZM6fDceLj47V37175+PjowIEDat++vTp27Gjvc+vWLfn6+iZ5zE6dOqlJkybatm2bQkND1ahRI1WqVCnFtQN4MAQnAEmqUaOGPvvsM7m6uiowMFAZMji+XXh5eTk8jo6OVtmyZe2XoO6UNWvWB6oh4dJbSkRHR0uSvv/+e4fAIt2et5VaNm7cqFatWik8PFx16tSRr6+v5s+fr08++STFtU6bNi1RkHN2dk7yOfXq1dORI0e0fPlyrVq1SjVr1lSXLl00atSoBz8ZAMYITgCS5OXlpeDgYOP+ZcqU0YIFC5QtW7ZEoy4JcuTIod9//13VqlWTdHtkZevWrSpTpkyS/Z999lnFx8frl19+Ua1atRJtTxjxiouLs7cVLVpUbm5uOnr0aLIjVUWKFLFPdE/w3//+9/4neYcNGzYoT548GjBggL3tyJEjifodPXpUJ0+eVGBgoP04Tk5OKlSokAICAhQYGKiDBw+qVatWxsfOmjWrwsLCFBYWpqpVq6p3794EJ+Ax4a46AKmiVatWypIlixo2bKj169fr0KFD+vnnn/XOO+/o+PHjkqRu3brpo48+0uLFi/X333+rc+fO91yDKSgoSGFhYWrXrp0WL15s3+dXX30lScqTJ49sNpuWLVumc+fOKTo6Wj4+PurVq5e6d++uWbNm6cCBA9q2bZsmTJigWbNmSZL+9a9/af/+/erdu7f27t2refPmaebMmSk63wIFCujo0aOaP3++Dhw4oPHjx2vRokWJ+rm7uyssLEw7d+7U+vXr9c4776h58+bKnj27JCk8PFzDhw/X+PHjtW/fPu3atUszZszQ6NGjkzzuoEGDtGTJEkVERGj37t1atmyZihQpkqLaATw4ghOAVOHp6al169Ypd+7caty4sYoUKaL27dvr+vXr9hGonj176o033lBYWJgqVqwoHx8fvfLKK/fc72effaamTZuqc+fOKly4sDp27KiYmBhJUs6cORUeHq5+/fopICBAXbt2lSQNHTpUAwcO1PDhw1WkSBHVrVtX33//vfLmzSvp9ryjhQsXavHixSpZsqQmT56sDz/8MEXn+/LLL6t79+7q2rWrSpUqpQ0bNmjgwIGJ+gUHB6tx48Z68cUXFRoaqhIlSjgsN9ChQwdNnz5dM2bM0LPPPquQkBDNnDnTXuvdXF1d1b9/f5UoUULVqlWTs7Oz5s+fn6LaATw4m5XcrEwAAAA4YMQJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADAEMEJAADA0P8B8myMn16BQn8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed Confusion Matrix plot.\n",
      "Logged Confusion Matrix plot artifact.\n",
      "Logging classification report artifact...\n",
      "Logged classification report artifact: classification_report_val.json\n",
      "Logging the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 11:58:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged the trained model using mlflow.sklearn.\n",
      "MLflow Run completed: 57e20e4c199e4dc1a80c35a10b327e62\n",
      "View the run in the MLflow UI.\n"
     ]
    }
   ],
   "source": [
    "from utils.mlflow_ml_model_logger import log_classification_model\n",
    "log_classification_model(\n",
    "    model=model,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val_scaled,\n",
    "    y_val=y_val,\n",
    "    run_name='xgboost_run',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLflow Run: xgboost_run (45fc81d851a648e59f724e99c4f3d409)\n",
      "Logged model parameters.\n",
      "Training the model...\n",
      "Model training complete.\n",
      "Evaluating the model on the validation set...\n",
      "Attempting to find custom threshold using find_threshold_binary_search for Recall[0] >= 0.9800\n",
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7606726\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Using threshold: Custom threshold 0.7607 aiming for Recall[0] >= 0.9800 (func achieved 0.9800)\n",
      "Calculating performance metrics...\n",
      "Validation Accuracy: 0.8585\n",
      "Validation Weighted F1-Score: 0.8439\n",
      "Validation Macro F1-Score: 0.7813\n",
      "Validation Recall Class 0: 0.9800\n",
      "Validation Recall Class 1: 0.5106\n",
      "Validation Precision Class 0: 0.8514\n",
      "Validation Precision Class 1: 0.8992\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8514    0.9800    0.9112    102026\n",
      "           1     0.8992    0.5106    0.6513     35648\n",
      "\n",
      "    accuracy                         0.8585    137674\n",
      "   macro avg     0.8753    0.7453    0.7813    137674\n",
      "weighted avg     0.8638    0.8585    0.8439    137674\n",
      "\n",
      "Logged validation metrics (rounded to 4 decimals).\n",
      "Generating Confusion Matrix plot...\n",
      "Saved Confusion Matrix plot to: confusion_matrix_val.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed Confusion Matrix plot.\n",
      "Logged Confusion Matrix plot artifact.\n",
      "Logging classification report artifact...\n",
      "Logged classification report artifact: classification_report_val.json\n",
      "Logging the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 11:58:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged the trained model using mlflow.sklearn.\n",
      "MLflow Run completed: 45fc81d851a648e59f724e99c4f3d409\n",
      "View the run in the MLflow UI.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(seed = 0, **best)\n",
    "from utils.mlflow_ml_model_logger import log_classification_model\n",
    "log_classification_model(\n",
    "    model=model,\n",
    "    X_train=X_train_scaled,\n",
    "    y_train=y_train,\n",
    "    X_val=X_test_scaled,\n",
    "    y_val=y_test,\n",
    "    run_name='xgboost_run',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9202    0.9281    0.9241    102026\n",
      "           1     0.7890    0.7695    0.7791     35648\n",
      "\n",
      "    accuracy                         0.8870    137674\n",
      "   macro avg     0.8546    0.8488    0.8516    137674\n",
      "weighted avg     0.8862    0.8870    0.8866    137674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection - Boruta\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t84\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t25\n",
      "Rejected: \t26\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t25\n",
      "Rejected: \t26\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t25\n",
      "Rejected: \t26\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t33\n",
      "Tentative: \t25\n",
      "Rejected: \t26\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t21\n",
      "Rejected: \t26\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t21\n",
      "Rejected: \t26\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t21\n",
      "Rejected: \t26\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t37\n",
      "Tentative: \t21\n",
      "Rejected: \t26\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t41\n",
      "Tentative: \t17\n",
      "Rejected: \t26\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t41\n",
      "Tentative: \t17\n",
      "Rejected: \t26\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t41\n",
      "Tentative: \t16\n",
      "Rejected: \t27\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t44\n",
      "Tentative: \t13\n",
      "Rejected: \t27\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t12\n",
      "Rejected: \t27\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t45\n",
      "Tentative: \t11\n",
      "Rejected: \t28\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t46\n",
      "Tentative: \t10\n",
      "Rejected: \t28\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t9\n",
      "Rejected: \t28\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t8\n",
      "Rejected: \t29\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t47\n",
      "Tentative: \t3\n",
      "Rejected: \t34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=0.9007742037358686,\n",
       "                                 colsample_bynode=0.7869045948709822,\n",
       "                                 colsample_bytree=0.7960310510235896,\n",
       "                                 device=None, early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.9386086236457385,\n",
       "                                 grow_policy=None, importance_type=None,\n",
       "                                 i...\n",
       "                                 learning_rate=0.01760309617897438,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=10, max_leaves=None,\n",
       "                                 min_child_weight=10, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=104, n_jobs=None,\n",
       "                                 num_parallel_tree=None, random_state=733088935, ...),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x25D0FAEDB40, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BorutaPy<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=0.9007742037358686,\n",
       "                                 colsample_bynode=0.7869045948709822,\n",
       "                                 colsample_bytree=0.7960310510235896,\n",
       "                                 device=None, early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.9386086236457385,\n",
       "                                 grow_policy=None, importance_type=None,\n",
       "                                 i...\n",
       "                                 learning_rate=0.01760309617897438,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=10, max_leaves=None,\n",
       "                                 min_child_weight=10, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=104, n_jobs=None,\n",
       "                                 num_parallel_tree=None, random_state=733088935, ...),\n",
       "         n_estimators=&#x27;auto&#x27;,\n",
       "         random_state=RandomState(MT19937) at 0x25D0FAEDB40, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.9007742037358686,\n",
       "              colsample_bynode=0.7869045948709822,\n",
       "              colsample_bytree=0.7960310510235896, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.9386086236457385,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01760309617897438,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=104, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=1869981846, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=0.9007742037358686,\n",
       "              colsample_bynode=0.7869045948709822,\n",
       "              colsample_bytree=0.7960310510235896, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0.9386086236457385,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01760309617897438,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=104, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=1610098866, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                                 colsample_bylevel=0.9007742037358686,\n",
       "                                 colsample_bynode=0.7869045948709822,\n",
       "                                 colsample_bytree=0.7960310510235896,\n",
       "                                 device=None, early_stopping_rounds=None,\n",
       "                                 enable_categorical=False, eval_metric=None,\n",
       "                                 feature_types=None, gamma=0.9386086236457385,\n",
       "                                 grow_policy=None, importance_type=None,\n",
       "                                 i...\n",
       "                                 learning_rate=0.01760309617897438,\n",
       "                                 max_bin=None, max_cat_threshold=None,\n",
       "                                 max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                 max_depth=10, max_leaves=None,\n",
       "                                 min_child_weight=10, missing=nan,\n",
       "                                 monotone_constraints=None, multi_strategy=None,\n",
       "                                 n_estimators=104, n_jobs=None,\n",
       "                                 num_parallel_tree=None,\n",
       "                                 random_state=2102472150, ...),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x25D0FAEDB40, verbose=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_df = pd.DataFrame({'Feature': X_train_scaled.columns, 'Importance': feat_selector.ranking_})\n",
    "boruta_df = boruta_df.sort_values(by='Importance', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_df.to_csv('../../utils/selected_features/boruta_features_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
