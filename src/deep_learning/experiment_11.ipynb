{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "\n",
    "#trying to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/mod_train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "# with h5py.File('../../data/3d_array/test_data_3d_h5.h5', 'r') as f:\n",
    "#     test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X, nan = 0.0)\n",
    "val_X = np.nan_to_num(val_X, nan = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2018-03-31    289115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_16284\\639591509.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_16284\\639591509.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289110</th>\n",
       "      <td>fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289111</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289112</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289113</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289114</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID end_of_month  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31       0\n",
       "1       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31       0\n",
       "2       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2018-03-31       0\n",
       "3       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2018-03-31       0\n",
       "4       0000f99513770170a1aba690daeeb8a96da4a39f11fc27...   2018-03-31       1\n",
       "...                                                   ...          ...     ...\n",
       "289110  fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...   2018-03-31       1\n",
       "289111  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...   2018-03-31       0\n",
       "289112  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2018-03-31       0\n",
       "289113  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31       0\n",
       "289114  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31       0\n",
       "\n",
       "[289115 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 13, 86), (289115, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32124, 13, 86), (32124, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3):\n",
    "        super(MDC, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_scales = len(kernel_sizes)\n",
    "        self.num_kernels_per_scale = num_kernels_per_scale\n",
    "        self.total_kernels = self.num_scales * self.num_kernels_per_scale\n",
    "\n",
    "        # Attention mechanism to generate weights for kernels [cite: 142, 143, 145]\n",
    "        self.attention_pool = nn.AdaptiveAvgPool1d(1) # Pool across time dimension\n",
    "        # Conv1d to generate temporal attention map\n",
    "        self.attention_conv = nn.Conv1d(in_channels, self.total_kernels, kernel_size=1, bias=False)\n",
    "        self.attention_gap = nn.AdaptiveAvgPool1d(1) # Pool attention map to get weights\n",
    "        self.attention_activation = nn.Sigmoid()\n",
    "\n",
    "        # Store the kernels for each scale and each instance per scale\n",
    "        self.weights = nn.Parameter(torch.Tensor(self.total_kernels, out_channels, in_channels, 1)) # Use kernel_size=1 here, will expand later\n",
    "        nn.init.kaiming_uniform_(self.weights, a=np.sqrt(5)) # Initialize weights\n",
    "\n",
    "        # Store kernel sizes correctly\n",
    "        self.k_sizes = []\n",
    "        for k in kernel_sizes:\n",
    "            for _ in range(num_kernels_per_scale):\n",
    "                self.k_sizes.append(k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, T = x.size()\n",
    "\n",
    "        # Calculate attention weights [cite: 142, 145]\n",
    "        pooled_x = self.attention_pool(x) # B x C_in x 1\n",
    "        # The paper's diagram (Fig 3) suggests GAP -> Conv -> GAP -> Sigmoid for attention\n",
    "        # Let's follow the diagram logic more closely:\n",
    "        # GAP on input: B x C_in x T -> B x C_in x 1\n",
    "        att_gap1 = self.attention_pool(x)\n",
    "        # Conv1d on pooled input: B x C_in x 1 -> B x total_kernels x 1 (This seems different from Fig 3's BxmxnxT output)\n",
    "        # Let's reinterpret Fig 3: GAP(x) [B,Cin,T]->[B,Cin,1], then Conv [B,Cin,1]->[B,mxn,1] (This doesn't match BxmxnxT)\n",
    "        # Let's try the alternative interpretation from the text (Section 3.2.1, Eq 2 implies GAP -> Conv -> GAP)\n",
    "        # GAP(x) -> B x Cin x 1\n",
    "        # wa * GAP(x) -> B x mxn x 1 (This still feels off from Fig 3 which applies conv before second GAP)\n",
    "\n",
    "        # Let's follow Fig 3 literally (ignoring the first GAP shown before Conv in the Attention block):\n",
    "        # Conv on input x: B x Cin x T -> B x mxn x T [cite: 143]\n",
    "        attention_map = self.attention_conv(x) # B x total_kernels x T\n",
    "        # GAP on attention_map: B x mxn x T -> B x mxn x 1 [cite: 145]\n",
    "        attention_vector = self.attention_gap(attention_map)\n",
    "        # Sigmoid activation: B x mxn x 1 [cite: 145]\n",
    "        attention_weights = self.attention_activation(attention_vector) # Shape: (batch_size, total_kernels, 1)\n",
    "\n",
    "        # Fuse kernels based on attention weights [cite: 140]\n",
    "        # Reshape weights for broadcasting: (batch_size, total_kernels, 1) -> (batch_size, total_kernels, 1, 1, 1)\n",
    "        # Reshape kernels: (total_kernels, out_c, in_c, 1)\n",
    "        # We need to perform convolution dynamically. PyTorch doesn't easily support dynamic kernel *shapes*.\n",
    "        # A common approach is to have fixed-size kernels and combine their *outputs*, or combine *weights* for a fixed kernel size.\n",
    "        # The paper seems to imply combining weights *before* convolution (Eq 1). This requires all kernels w_i^j to have the same size k.\n",
    "        # However, the goal is *multi-scale*.\n",
    "\n",
    "        # Let's implement the multi-scale aspect by having separate convolutions and combining outputs weighted by attention.\n",
    "        # This deviates slightly from Eq 1 but achieves the multi-scale goal.\n",
    "\n",
    "        outputs = []\n",
    "        current_kernel_idx = 0\n",
    "        for k_size in self.kernel_sizes:\n",
    "            padding = k_size // 2\n",
    "            for i in range(self.num_kernels_per_scale):\n",
    "                # Get the weights for this specific kernel instance (across all batches)\n",
    "                # attention_weights shape: B x total_kernels x 1\n",
    "                # kernel_weights shape: B x 1 x out_c x in_c x k_size\n",
    "                kernel_idx = current_kernel_idx + i\n",
    "                kernel_weight = self.weights[kernel_idx] # out_c x in_c x 1\n",
    "                # Manually create the kernel for Conv1d for this size\n",
    "                dynamic_kernel = kernel_weight.repeat(1, 1, k_size) # out_c x in_c x k_size\n",
    "                \n",
    "                # Perform convolution with this specific kernel\n",
    "                output_i = F.conv1d(x, dynamic_kernel, padding=padding) # B x out_c x T\n",
    "                \n",
    "                # Apply attention weight for this kernel\n",
    "                # attention_weights[:, kernel_idx, :] shape: B x 1 x 1\n",
    "                weighted_output = output_i * attention_weights[:, kernel_idx, :].unsqueeze(-1) # B x out_c x T\n",
    "                outputs.append(weighted_output)\n",
    "                \n",
    "            current_kernel_idx += self.num_kernels_per_scale\n",
    "\n",
    "        # Sum the weighted outputs from all kernels\n",
    "        # This is an alternative interpretation to fusing weights first.\n",
    "        out = torch.sum(torch.stack(outputs), dim=0) # B x out_c x T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3, stride=1):\n",
    "        super(MDCResBlock, self).__init__()\n",
    "        \n",
    "        # Use Conv1d for the residual connection if dimensions change\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.mdc1 = MDC(in_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Paper uses PReLU, let's use ReLU for simplicity or add PReLU if needed. Using PReLU as per paper.\n",
    "        self.prelu1 = nn.PReLU(out_channels)\n",
    "\n",
    "        self.mdc2 = MDC(out_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu2 = nn.PReLU(out_channels) # Activation after final BN before adding shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out = self.mdc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "\n",
    "        out = self.mdc2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.prelu2(out) # Final activation after adding shortcut\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, block_channels=[128, 128, 128], kernel_sizes=[3,5,7], num_kernels_per_scale=2, dropout_rate=0.3, reduction=16):\n",
    "        super(MDCNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        current_channels = input_channels\n",
    "        \n",
    "        # Configuration from paper/Figure 2: 3 Blocks [cite: 130]\n",
    "        # Each block: MDC ResBlock -> MaxPool -> SE -> Dropout\n",
    "        for i, channels in enumerate(block_channels):\n",
    "            # Stride only applied if pooling happens, MaxPooling handles stride=2\n",
    "            res_block = MDCResBlock(current_channels, channels, kernel_sizes, num_kernels_per_scale, stride=1)\n",
    "            max_pool = nn.MaxPool1d(kernel_size=2, stride=2) # Halve the length [cite: 132]\n",
    "            se_block = SEBlock(channels, reduction) # SE block [cite: 133]\n",
    "            dropout = nn.Dropout(dropout_rate) # Dropout [cite: 134]\n",
    "            \n",
    "            block = nn.Sequential(\n",
    "                res_block,\n",
    "                max_pool,\n",
    "                se_block,\n",
    "                dropout\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            current_channels = channels # Update channels for next block\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1) # Global Average Pooling [cite: 130]\n",
    "        # The original ConvModel in experiment_10 has FC layers after pooling.\n",
    "        # MDCNet in the paper feeds features to DPNet or directly to Softmax.\n",
    "        # To make it a component usable in the existing structure, we output features before FC layers.\n",
    "        self.output_channels = current_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: B x T x C_in (e.g., B x 10 x 115)\n",
    "        # Conv1D expects B x C_in x T\n",
    "        x = x.permute(0, 2, 1) # B x C_in x T (e.g., B x 115 x 10)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x) # B x C_out x 1\n",
    "        x = x.view(x.size(0), -1) # Flatten: B x C_out\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedConvModel(nn.Module):\n",
    "    def __init__(self, input_size, time_steps, num_classes=1, mdc_block_channels=[64, 64, 64], mdc_kernel_sizes=[3,5,7], mdc_kernels_per_scale=2, dropout_rate=0.2, fc_size=32):\n",
    "        super(ModifiedConvModel, self).__init__()\n",
    "        \n",
    "        # Instantiate MDCNet feature extractor\n",
    "        self.mdc_net = MDCNet(input_channels=input_size,\n",
    "                              num_classes=num_classes, # Not directly used by MDCNet output layer here\n",
    "                              block_channels=mdc_block_channels,\n",
    "                              kernel_sizes=mdc_kernel_sizes,\n",
    "                              num_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                              dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Get the output feature dimension from MDCNet\n",
    "        mdc_output_channels = self.mdc_net.output_channels\n",
    "\n",
    "        # Fully connected layers (similar to original experiment_10)\n",
    "        self.fc1 = nn.Linear(mdc_output_channels, fc_size)\n",
    "        self.relu_fc = nn.ReLU() # Added ReLU after FC1\n",
    "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "        \n",
    "        # Pass through MDCNet feature extractor\n",
    "        features = self.mdc_net(x) # Output: B x mdc_output_channels\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(features)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Modified ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features (115)\n",
    "time_steps = train_X.shape[1]  # Number of time steps (10)\n",
    "output_size = 1  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=86, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# --- MDCNet Hyperparameters ---\n",
    "# Using smaller channels than paper's example for potentially faster training/less memory\n",
    "mdc_block_channels = [32, 32, 32] # Example channel sizes for each block\n",
    "# Using kernel sizes mentioned in paper, and n=2 as found via cross-validation in paper [cite: 242, 243]\n",
    "mdc_kernel_sizes = [3, 5, 7]\n",
    "mdc_kernels_per_scale = 2\n",
    "dropout_rate = 0.2 # Adjusted dropout\n",
    "fc_size = 16 # Adjusted FC size\n",
    "\n",
    "# Create model instance\n",
    "model = ModifiedConvModel(input_size=input_size,\n",
    "                          time_steps=time_steps,\n",
    "                          num_classes=output_size,\n",
    "                          mdc_block_channels=mdc_block_channels,\n",
    "                          mdc_kernel_sizes=mdc_kernel_sizes,\n",
    "                          mdc_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          fc_size=fc_size)\n",
    "\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "===========================================================================================================================================================\n",
       "ModifiedConvModel                                       [10000, 13, 86]           [10000, 1]                --                        --\n",
       "â”œâ”€MDCNet: 1-1                                           [10000, 13, 86]           [10000, 32]               --                        --\n",
       "â”‚    â””â”€ModuleList: 2-1                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-1                             [10000, 86, 13]           [10000, 32, 6]            26,500                    453,640,000\n",
       "â”‚    â”‚    â””â”€Sequential: 3-2                             [10000, 32, 6]            [10000, 32, 3]            12,992                    26,240,000\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                             [10000, 32, 3]            [10000, 32, 1]            12,992                    14,720,000\n",
       "â”‚    â””â”€AdaptiveAvgPool1d: 2-2                           [10000, 32, 1]            [10000, 32, 1]            --                        --\n",
       "â”œâ”€Linear: 1-2                                           [10000, 32]               [10000, 16]               528                       5,280,000\n",
       "â”œâ”€ReLU: 1-3                                             [10000, 16]               [10000, 16]               --                        --\n",
       "â”œâ”€Linear: 1-4                                           [10000, 16]               [10000, 1]                17                        170,000\n",
       "â”œâ”€Sigmoid: 1-5                                          [10000, 1]                [10000, 1]                --                        --\n",
       "===========================================================================================================================================================\n",
       "Total params: 53,029\n",
       "Trainable params: 53,029\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 500.05\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 44.72\n",
       "Forward/backward pass size (MB): 322.48\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 367.22\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10000 # Or a smaller representative batch size\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], depth=3) # Increased depth to see inside MDCNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([0.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([1.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812fde90611d43a9a167c885ef249822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d52946efae4ddb9b86c08388cae12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.5602, Val Loss: 0.4572, Val AUC: 0.9229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5130e4166b9b49d8b337ccd0bc796df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45068bfb1aa43d3a5ae0b7de4c5c584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.3551, Val Loss: 0.3022, Val AUC: 0.9305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32345ba66f2243c894c2c003a7bb618f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a628229a86e4e2aa2e27fee324641ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.2976, Val Loss: 0.2887, Val AUC: 0.9336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa13382857241bcb0d5ade42229d230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b30edbb1104e86aad28d8f277af1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.2921, Val Loss: 0.2949, Val AUC: 0.9342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380f2a48b1b145e287e16ebd66c2b757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8abbc0fce3468cbbfe538c9cb9b1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.2893, Val Loss: 0.2863, Val AUC: 0.9358\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3ee607db334fd6975f2d6c4da1efa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b228f1657cdc434e9df3164b31032161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2858, Val Loss: 0.2888, Val AUC: 0.9373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e244fc57c404c4b8b37b8086d1d5930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5435ecb09b2b4b91a117672d84dc782a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2868, Val Loss: 0.2886, Val AUC: 0.9368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdcdc100959d46fda6316edfd8e3883c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eddaaad42e4b29888f0c1cd12aea17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2842, Val Loss: 0.2799, Val AUC: 0.9374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d75d00c7bda4c5ab9d74ce56c44a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c53d29d58894570b6d34f477eed9bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.2861, Val Loss: 0.2837, Val AUC: 0.9371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6ed3b114ad4e57b6953c819f9a89fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0dc64a350e4974831f4428d42c52a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.2802, Val Loss: 0.2810, Val AUC: 0.9396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd0d886b4af40b29c9f9a3728612225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fb2d45dd0a4bb1bf46984069172c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Valid]:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.2772, Val Loss: 0.2804, Val AUC: 0.9407\n",
      "Early stopping triggered after 11 epochs\n",
      "Training completed in 20m 39s\n",
      "Best val loss: 0.2799, Best val AUC: 0.9374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20 # Adjust as needed\n",
    "patience = 3  # Early stopping patience\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_val_auc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Use state_dict()\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# For tracking metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Training on {device}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for inputs, labels in train_pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_val_loss = running_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    all_preds = [p[0] for p in all_preds]\n",
    "    all_labels = [l[0] for l in all_labels]\n",
    "    # Handle case where validation set might only have one class temporarily during testing/debugging\n",
    "    if len(np.unique(all_labels)) > 1:\n",
    "        epoch_val_auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        epoch_val_auc = 0.0 # Or handle as appropriate, e.g., skip AUC calculation\n",
    "    val_aucs.append(epoch_val_auc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "          f\"Val AUC: {epoch_val_auc:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_val_auc = epoch_val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "# Training complete\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "print(f\"Best val loss: {best_val_loss:.4f}, Best val AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/deep_learning\\experiment_11.pth\n",
      "Checkpoint saved to ../../models/deep_learning\\experiment_11.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model weights\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "save_dir = '../../models/deep_learning'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model state dictionary\n",
    "model_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save additional information for later reference\n",
    "checkpoint_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Checkpoint saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions obtained.\n",
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7396237\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.8330    0.9800    0.9005     23806\n",
      "     Class 1     0.8844    0.4377    0.5856      8318\n",
      "\n",
      "    accuracy                         0.8396     32124\n",
      "   macro avg     0.8587    0.7089    0.7431     32124\n",
      "weighted avg     0.8463    0.8396    0.8190     32124\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHHCAYAAABHp6kXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRxklEQVR4nO3dfVyN9/8H8NcpOqU6lbsSLaUbReRutNx+NSHGMItmMfFjYYrczF3u5vtlhszNxiaMudnGJoYmNMQwkZsaidxUTCpF99fvD9+u746ydVwnXc55Pfe4Hg/nuj7X53pfZ6e8fd6fz3UUgiAIICIiInrFGVR3AERERETawKSGiIiIdAKTGiIiItIJTGqIiIhIJzCpISIiIp3ApIaIiIh0ApMaIiIi0glMaoiIiEgnMKkhIiIincCkhugVdPXqVfTo0QMWFhZQKBTYvXu3Vvu/ceMGFAoFIiMjtdrvq6xr167o2rVrdYdBRH+DSQ3RC0pOTsb//d//wdHREcbGxlCpVPD29saKFSvw5MmTKr12YGAgEhISsHDhQmzevBlt27at0uu9TMOHD4dCoYBKparwfbx69SoUCgUUCgU+/fRTjfu/e/cuwsPDER8fr4VoiUhOalR3AESvor179+Kdd96BUqnE+++/j+bNm6OwsBDHjh1DWFgYLl26hC+//LJKrv3kyRPExcVhxowZGDduXJVcw97eHk+ePEHNmjWrpP9/UqNGDTx+/Bh79uzB4MGD1Y5t2bIFxsbGyM/Pf6G+7969i7lz56Jx48bw9PSs9HkHDx58oesR0cvDpIZIQykpKfD394e9vT1iYmLQoEED8VhwcDCuXbuGvXv3Vtn179+/DwCwtLSssmsoFAoYGxtXWf//RKlUwtvbG99++225pGbr1q3w8/PD999//1Jiefz4MWrVqgUjI6OXcj0ienEsPxFpaPHixcjNzcVXX32lltCUcXJywkcffSS+Li4uxvz589GkSRMolUo0btwYH3/8MQoKCtTOa9y4Mfr06YNjx47h9ddfh7GxMRwdHbFp0yaxTXh4OOzt7QEAYWFhUCgUaNy4MYCnZZuyP/9VeHg4FAqF2r7o6Gh07NgRlpaWMDMzg6urKz7++GPx+PPm1MTExKBTp04wNTWFpaUl+vXrhytXrlR4vWvXrmH48OGwtLSEhYUFRowYgcePHz//jX3G0KFD8fPPPyMrK0vcd/r0aVy9ehVDhw4t1z4zMxOTJ0+Gh4cHzMzMoFKp0KtXL5w/f15sc+TIEbRr1w4AMGLECLGMVXafXbt2RfPmzXH27Fl07twZtWrVEt+XZ+fUBAYGwtjYuNz9+/r6wsrKCnfv3q30vRKRdjCpIdLQnj174OjoiDfeeKNS7YOCgjB79my0bt0ay5YtQ5cuXbBo0SL4+/uXa3vt2jUMGjQIb775JpYuXQorKysMHz4cly5dAgAMGDAAy5YtAwAMGTIEmzdvxvLlyzWK/9KlS+jTpw8KCgowb948LF26FG+99RaOHz/+t+f98ssv8PX1xb179xAeHo7Q0FCcOHEC3t7euHHjRrn2gwcPxqNHj7Bo0SIMHjwYkZGRmDt3bqXjHDBgABQKBX744Qdx39atW9G0aVO0bt26XPvr169j9+7d6NOnDz777DOEhYUhISEBXbp0ERMMNzc3zJs3DwAwevRobN68GZs3b0bnzp3Ffh48eIBevXrB09MTy5cvR7du3SqMb8WKFahXrx4CAwNRUlICAPjiiy9w8OBBrFy5Era2tpW+VyLSEoGIKi07O1sAIPTr169S7ePj4wUAQlBQkNr+yZMnCwCEmJgYcZ+9vb0AQIiNjRX33bt3T1AqlcKkSZPEfSkpKQIAYcmSJWp9BgYGCvb29uVimDNnjvDXH/Vly5YJAIT79+8/N+6ya2zYsEHc5+npKdSvX1948OCBuO/8+fOCgYGB8P7775e73gcffKDW59tvvy3UqVPnudf8632YmpoKgiAIgwYNErp37y4IgiCUlJQINjY2wty5cyt8D/Lz84WSkpJy96FUKoV58+aJ+06fPl3u3sp06dJFACCsXbu2wmNdunRR23fgwAEBgLBgwQLh+vXrgpmZmdC/f/9/vEciqhocqSHSQE5ODgDA3Ny8Uu337dsHAAgNDVXbP2nSJAAoN/fG3d0dnTp1El/Xq1cPrq6uuH79+gvH/KyyuTg//vgjSktLK3VOWloa4uPjMXz4cNSuXVvc36JFC7z55pviff7VmDFj1F536tQJDx48EN/Dyhg6dCiOHDmC9PR0xMTEID09vcLSE/B0Ho6BwdNfaSUlJXjw4IFYWvv9998rfU2lUokRI0ZUqm2PHj3wf//3f5g3bx4GDBgAY2NjfPHFF5W+FhFpF5MaIg2oVCoAwKNHjyrV/ubNmzAwMICTk5PafhsbG1haWuLmzZtq+1977bVyfVhZWeHhw4cvGHF57777Lry9vREUFARra2v4+/tjx44df5vglMXp6upa7pibmxv+/PNP5OXlqe1/9l6srKwAQKN76d27N8zNzbF9+3Zs2bIF7dq1K/deliktLcWyZcvg7OwMpVKJunXrol69erhw4QKys7Mrfc2GDRtqNCn4008/Re3atREfH4+IiAjUr1+/0ucSkXYxqSHSgEqlgq2tLS5evKjRec9O1H0eQ0PDCvcLgvDC1yib71HGxMQEsbGx+OWXXzBs2DBcuHAB7777Lt58881ybaWQci9llEolBgwYgI0bN2LXrl3PHaUBgE8++QShoaHo3LkzvvnmGxw4cADR0dFo1qxZpUekgKfvjybOnTuHe/fuAQASEhI0OpeItItJDZGG+vTpg+TkZMTFxf1jW3t7e5SWluLq1atq+zMyMpCVlSWuZNIGKysrtZVCZZ4dDQIAAwMDdO/eHZ999hkuX76MhQsXIiYmBocPH66w77I4k5KSyh1LTExE3bp1YWpqKu0GnmPo0KE4d+4cHj16VOHk6jLfffcdunXrhq+++gr+/v7o0aMHfHx8yr0nlU0wKyMvLw8jRoyAu7s7Ro8ejcWLF+P06dNa65+INMOkhkhDU6ZMgampKYKCgpCRkVHueHJyMlasWAHgafkEQLkVSp999hkAwM/PT2txNWnSBNnZ2bhw4YK4Ly0tDbt27VJrl5mZWe7csofQPbvMvEyDBg3g6emJjRs3qiUJFy9exMGDB8X7rArdunXD/Pnz8fnnn8PGxua57QwNDcuNAu3cuRN37txR21eWfFWUAGpq6tSpSE1NxcaNG/HZZ5+hcePGCAwMfO77SERViw/fI9JQkyZNsHXrVrz77rtwc3NTe6LwiRMnsHPnTgwfPhwA0LJlSwQGBuLLL79EVlYWunTpgt9++w0bN25E//79n7tc+EX4+/tj6tSpePvttzFhwgQ8fvwYa9asgYuLi9pE2Xnz5iE2NhZ+fn6wt7fHvXv3sHr1ajRq1AgdO3Z8bv9LlixBr1694OXlhZEjR+LJkydYuXIlLCwsEB4errX7eJaBgQFmzpz5j+369OmDefPmYcSIEXjjjTeQkJCALVu2wNHRUa1dkyZNYGlpibVr18Lc3BympqZo3749HBwcNIorJiYGq1evxpw5c8Ql5hs2bEDXrl0xa9YsLF68WKP+iEgLqnn1FdEr648//hBGjRolNG7cWDAyMhLMzc0Fb29vYeXKlUJ+fr7YrqioSJg7d67g4OAg1KxZU7CzsxOmT5+u1kYQni7p9vPzK3edZ5cSP29JtyAIwsGDB4XmzZsLRkZGgqurq/DNN9+UW9J96NAhoV+/foKtra1gZGQk2NraCkOGDBH++OOPctd4dtnzL7/8Inh7ewsmJiaCSqUS+vbtK1y+fFmtTdn1nl0yvmHDBgGAkJKS8tz3VBDUl3Q/z/OWdE+aNElo0KCBYGJiInh7ewtxcXEVLsX+8ccfBXd3d6FGjRpq99mlSxehWbNmFV7zr/3k5OQI9vb2QuvWrYWioiK1diEhIYKBgYEQFxf3t/dARNqnEAQNZu0RERERyRTn1BAREZFOYFJDREREOoFJDREREekEJjVERESkE5jUEBERkU5gUkNEREQ6gQ/fq2KlpaW4e/cuzM3Ntfp4diIiejkEQcCjR49ga2srfhO8tuXn56OwsFArfRkZGcHY2Fgrfb1qmNRUsbt378LOzq66wyAiIolu3bqFRo0aab3f/Px8mJjXAYofa6U/GxsbpKSk6GViw6SmipmbmwMAjNwDoTA0quZoiKpG6pFPqzsEoirzKCcHTg524u9zbSssLASKH0PpHghI/XuipBDplzeisLCQSQ1pX1nJSWFoxKSGdJZKparuEIiqXJVPIahhLPnvCUGh31NlmdQQERHJgQKA1MRJz6duMqkhIiKSA4XB001qH3pMv++eiIiIdAZHaoiIiORAodBC+Um/609MaoiIiOSA5SfJ9PvuiYiISGdwpIaIiEgOWH6SjEkNERGRLGih/KTnBRj9vnsiIiLSGRypISIikgOWnyRjUkNERCQHXP0kmX7fPREREekMjtQQERHJActPkjGpISIikgOWnyRjUkNERCQHHKmRTL9TOiIiItIZHKkhIiKSA5afJGNSQ0REJAcKhRaSGpafiIiIiF55HKkhIiKSAwPF001qH3qMSQ0REZEccE6NZPp990RERKQzOFJDREQkB3xOjWRMaoiIiOSA5SfJ9PvuiYiISGdwpIaIiEgOWH6SjEkNERGRHLD8JBmTGiIiIjngSI1k+p3SERERkc7gSA0REZEcsPwkGZMaIiIiOWD5STL9TumIiIhIZ3CkhoiISBa0UH7S87EKJjVERERywPKTZPqd0hEREZHO4EgNERGRHCgUWlj9pN8jNUxqiIiI5IBLuiXT77snIiIincGRGiIiIjngRGHJmNQQERHJActPkjGpISIikgOO1Eim3ykdERER6QyO1BAREckBy0+SMakhIiKSA5afJNPvlI6IiIh0BkdqiIiIZEChUEDBkRpJmNQQERHJAJMa6Vh+IiIi0lOLFi1Cu3btYG5ujvr166N///5ISkpSa5Ofn4/g4GDUqVMHZmZmGDhwIDIyMtTapKamws/PD7Vq1UL9+vURFhaG4uJitTZHjhxB69atoVQq4eTkhMjIyHLxrFq1Co0bN4axsTHat2+P3377TaP7YVJDREQkBwotbRo4evQogoODcfLkSURHR6OoqAg9evRAXl6e2CYkJAR79uzBzp07cfToUdy9excDBgwQj5eUlMDPzw+FhYU4ceIENm7ciMjISMyePVtsk5KSAj8/P3Tr1g3x8fGYOHEigoKCcODAAbHN9u3bERoaijlz5uD3339Hy5Yt4evri3v37lX+LRQEQdDsLSBN5OTkwMLCAkqPUVAYGlV3OERV4uHpz6s7BKIqk5OTA+s6FsjOzoZKpaqS/i0sLFCr/2ooappI6ksoeoLHuz984Vjv37+P+vXr4+jRo+jcuTOys7NRr149bN26FYMGDQIAJCYmws3NDXFxcejQoQN+/vln9OnTB3fv3oW1tTUAYO3atZg6dSru378PIyMjTJ06FXv37sXFixfFa/n7+yMrKwv79+8HALRv3x7t2rXD558//X1SWloKOzs7jB8/HtOmTatU/BypISIi0jE5OTlqW0FBQaXOy87OBgDUrl0bAHD27FkUFRXBx8dHbNO0aVO89tpriIuLAwDExcXBw8NDTGgAwNfXFzk5Obh06ZLY5q99lLUp66OwsBBnz55Va2NgYAAfHx+xTWUwqSEiIpKBsonCUjcAsLOzg4WFhbgtWrToH69fWlqKiRMnwtvbG82bNwcApKenw8jICJaWlmptra2tkZ6eLrb5a0JTdrzs2N+1ycnJwZMnT/Dnn3+ipKSkwjZlfVQGVz8RERHJgDZXP926dUut/KRUKv/x1ODgYFy8eBHHjh2TFkM1YlJDREQkA9pMalQqlUZzasaNG4eoqCjExsaiUaNG4n4bGxsUFhYiKytLbbQmIyMDNjY2YptnVymVrY76a5tnV0xlZGRApVLBxMQEhoaGMDQ0rLBNWR+VwfITERGRnhIEAePGjcOuXbsQExMDBwcHteNt2rRBzZo1cejQIXFfUlISUlNT4eXlBQDw8vJCQkKC2iql6OhoqFQquLu7i23+2kdZm7I+jIyM0KZNG7U2paWlOHTokNimMjhSQ0REJAcvsCS7wj40EBwcjK1bt+LHH3+Eubm5OH/FwsICJiYmsLCwwMiRIxEaGoratWtDpVJh/Pjx8PLyQocOHQAAPXr0gLu7O4YNG4bFixcjPT0dM2fORHBwsFj2GjNmDD7//HNMmTIFH3zwAWJiYrBjxw7s3btXjCU0NBSBgYFo27YtXn/9dSxfvhx5eXkYMWJEpe+HSQ0REZEMVMcThdesWQMA6Nq1q9r+DRs2YPjw4QCAZcuWwcDAAAMHDkRBQQF8fX2xevVqsa2hoSGioqIwduxYeHl5wdTUFIGBgZg3b57YxsHBAXv37kVISAhWrFiBRo0aYf369fD19RXbvPvuu7h//z5mz56N9PR0eHp6Yv/+/eUmD//t7fM5NVWLz6khfcDn1JAue1nPqVG986VWnlOTs3N0lcUqdxypISIikgGFAloYqdFOLK8qJjVEREQyoIAWyk96ntVw9RMRERHpBI7UEBERyUB1TBTWNUxqiIiI5KAalnTrGpafiIiISCdwpIaIiEgOtFB+Elh+IiIiouqmjTk10ldPvdqY1BAREckAkxrpOKeGiIiIdAJHaoiIiOSAq58kY1JDREQkAyw/ScfyExEREekEjtQQERHJAEdqpGNSQ0REJANMaqRj+YmIiIh0AkdqiIiIZIAjNdIxqSEiIpIDLumWjOUnIiIi0gkcqSEiIpIBlp+kY1JDREQkA0xqpGNSQ0REJANMaqTjnBoiIiLSCRypISIikgOufpKMSQ0REZEMsPwkHctPREREpBNeiZEahUKBXbt2oX///tUdClWBkOE90KdbSzjbWyO/oAi/XbiO8M9/xLWb98Q2y6b7o8vrrrCpa4G8JwX47UIKwlf+iKs3MwAAVham+HJ+IJo5NURti1r482Eu9h29gPmr9+BRXj4AoENLR4SP7wdnexuYGNfErfRMRP5wHGu+PawWT9A7nTH+ve6oX0eFi1fvYOqSnfj98s2X94aQ3lsWeRDzVv2EMf5dsWjSIKTefYCW/eZU2HbDog/Q36e1+HrrnpNYtTUGyan3YG5qjH7dW+HTqe++rNBJAo7USFftSU16ejoWLlyIvXv34s6dO6hfvz48PT0xceJEdO/evbrDgyAImDNnDtatW4esrCx4e3tjzZo1cHZ2ru7QdMYbrZ2wfmcszl2+iRqGhpj1YV/8sHIcOgxegMf5hQCA+MRb2Ln/NG6lP4SVqhamjfbDD58Ho2W/OSgtFVBaWoqfj17AwjVRePDwERzs6mHJlMGwUpli1KxIAEDek0Ks2xGLS9fuIO9JIbw8m+Cz6f54nF+IjbuOAwDefrM1Fkx8G6H/3o6zF29gzJBu+H5lMNoNmoc/H+ZW11tEeuT3SzcRues4mjk3FPc1tLZC4s+fqLXbuOs4Vn7zC3zeaCbuW7XlEFZticHcCf3Rtnlj5D0pROrdBy8tdpJGAS0kNXo+qaZak5obN27A29sblpaWWLJkCTw8PFBUVIQDBw4gODgYiYmJ1RkeAGDx4sWIiIjAxo0b4eDggFmzZsHX1xeXL1+GsbFxdYenE96ZsFrt9Ydzv8G16H/D080OJ84lA4CYdADArbRMLFyzB8e+/RivNaiDG3f+RPajJ/j6+2P/a5P+EF999ysmDPMR9yX8cRsJf9xW66dPt5bw8mwi9v/h0H9h0+4T2LrnJAAgdNE29PBuhvfe8sLyjdHav3miv8h9XIDRsyOx4uMh+PTr/eJ+Q0MDWNdVqbWNOnIe/X1aw6yWEgCQlfMYC9dE4dvPxqDL665iu+Z/SY6IdF21zqn58MMPoVAo8Ntvv2HgwIFwcXFBs2bNEBoaipMnTz73vKlTp8LFxQW1atWCo6MjZs2ahaKiIvH4+fPn0a1bN5ibm0OlUqFNmzY4c+YMAODmzZvo27cvrKysYGpqimbNmmHfvn0VXkcQBCxfvhwzZ85Ev3790KJFC2zatAl3797F7t27tfpe0P+ozJ4miw9zHld4vJaxEYb27YAbd/7EnYyHFbaxqWuBvt08cfz3q8+9jodLI7zewlFsU7OGITyb2uHIb0liG0EQcPS3JLTzcHjR2yGqtLDF29HDuzm6tm/6t+3ir6Qi4Y/beO8tL3Hf4VOJKBUEpN3PQvt35qOZ30yMmP4VbqdX/DNC8lNWfpK66bNqG6nJzMzE/v37sXDhQpiampY7bmlp+dxzzc3NERkZCVtbWyQkJGDUqFEwNzfHlClTAAABAQFo1aoV1qxZA0NDQ8THx6NmzZoAgODgYBQWFiI2Nhampqa4fPkyzMzMKrxOSkoK0tPT4ePzv3/tW1hYoH379oiLi4O/v7+Ed4AqolAosCh0EE7GJ+NKcprasZGDOiF8fH+Y1VLijxvpeDv4cxQVl6i1Wb9gOHp1aYFaxkb4OTYBExZsLXeNi1HzUdfKDDUMDfHvdfuw+cc4AEAdSzPUqGGI+5mP1Nrfz8yBc2NrLd8pkbrvD57B+cRbiNk45R/bbv4xDq4ONmjf0lHcd+POnygtFfDZhoNYNGkgVGYmWLgmCgPGfY5j306HUc1qn21A/4RLuiWrtk/5tWvXIAgCmjb9+3+RVGTmzJninxs3bozJkydj27ZtYlKTmpqKsLAwse+/zn9JTU3FwIED4eHhAQBwdHTE86SnpwMArK3V/0KztrYWjz2roKAABQUF4uucnBxNbk3vfTplMNyaNECvUcvKHdv582kcPpUIm7oqjHvPBxsWfYCeQZ+hoLBYbPPxsu/xn3U/w8m+PmYFv4WFIQMw+T871PrpPXo5zEyUaOvRGHOC+yHl1n18f/Bsld8b0fPcTn+I6Uu/xw+fj4Oxsubftn2SX4jvDpxB2MieavtLBQFFxSX49+RB+FcHNwDA+oXD4drzY/x65g9093KvsviJ5KLakhpBEF743O3btyMiIgLJycnIzc1FcXExVKr/1ZtDQ0MRFBSEzZs3w8fHB++88w6aNGkCAJgwYQLGjh2LgwcPwsfHBwMHDkSLFi0k30+ZRYsWYe7cuVrrT58sDnsHvp2ao/fo5bh7L6vc8Zy8fOTk5eP6rfs4nXADKTGL0adrS7WE5N6DR7j34BGu3szAw+w8/Lw+FEvW70fGg/8ll2UTJy8n30W92uaYOro3vj94Fg+yclFcXIJ6tc3Vrluvtgr3HjA5papzPjEV9zMfoeuw/4j7SkpKceJcMtbtjEXG8eUwNHw6W+DHmHg8yS+Ev9/ran3Y1Hn6O9DVwUbcV9fKHHUszViCekVw9ZN01TanxtnZGQqFQuPJwHFxcQgICEDv3r0RFRWFc+fOYcaMGSgsLBTbhIeH49KlS/Dz80NMTAzc3d2xa9cuAEBQUBCuX7+OYcOGISEhAW3btsXKlSsrvJaNzdNfDhkZGWr7MzIyxGPPmj59OrKzs8Xt1q1bGt2fvloc9g78urbEW2MjKrVao+yH38jo+Xm5gcHTH+5/aqP877B8UXEJ4hNvoUu7/02yVCgU6NzOBacTUip7K0Qa69zOFce//Rix30wTt1Zur+Gdnm0R+800MaEBgG9+PIFenT1Q10o9+S4rRf31UQgPs/PwICsXdg1qv5wbIUk4p0a6ahupqV27Nnx9fbFq1SpMmDCh3LyarKysCufVnDhxAvb29pgxY4a47+bN8s8QcXFxgYuLC0JCQjBkyBBs2LABb7/9NgDAzs4OY8aMwZgxYzB9+nSsW7cO48ePL9eHg4MDbGxscOjQIXh6egJ4Wk46deoUxo4dW+F9KZVKKJXKyr4NBODTqYMxyLcthk7+ErmP81G/ztNf1jm5+cgvKIJ9wzoY8GYbxJy8ggcPc2FrbYmJgT2Qn1+E6OOXAABvvuGOenVUOHf5JnIfF8DNsQHmTuiPk/HJuJWWCeDp82dup2fijxtPk9Q3WjlhXEB3fLn9qBjL6q0xWD1nGM5dScXvl25g7JBuMDVRYsue509cJ5LK3NQY7k62avtqmRihtoWp2v7rt+7jxLlk7Fhe/vePk701endpgWlLv8Pyj4fA3NQY81b9BBd7a3Rq61Ll90DSKRRPN6l96LNqnTm2atUqeHt74/XXX8e8efPQokULFBcXIzo6GmvWrMGVK1fKnePs7IzU1FRs27YN7dq1w969e8VRGAB48uQJwsLCMGjQIDg4OOD27ds4ffo0Bg4cCACYOHEievXqBRcXFzx8+BCHDx+Gm5tbhfEpFApMnDgRCxYsgLOzs7ik29bWlg8C1KKRgzoDAPZ+MVFt/4dzN+PbqFMoKCiGl2cTjPHvCktVLdzPfIQT567BN2ip+OyYJwVFCOz/Bj4JGQCjmjVwJyMLUUfisSzyf8uwFQoFZge/hdds66CkpBQpt//E3M9/xIYf/rdcfFf076hraYaP/88P9euYI+GPOxg0YVW5ycNE1eGbn+JgW98S/+pQ8VzENeHDMGPZD3g3ZA0MDBTwbuWMnRHBqFnD8CVHSlQ9FIKUyS1akJaWhoULFyIqKgppaWmoV68e2rRpg5CQEHTt2vVpkM88UXjKlCn4+uuvUVBQAD8/P3To0AHh4eHIyspCYWEhAgMDcfz4cWRkZKBu3boYMGAAlixZAmNjY4wfPx4///wzbt++DZVKhZ49e2LZsmWoU6dOhfGVPXzvyy+/RFZWFjp27IjVq1fDxaVy//LJycmBhYUFlB6joDA00sZbRiQ7D09/Xt0hEFWZnJwcWNexQHZ2ttr8TW32b2FhAcfx38FAWX41sCZKC/JwfeWgKotV7qo9qdF1TGpIHzCpIV320pKaCd/BUGJSU1KQh+sR+pvU8AstiYiISCfwaUxEREQywCXd0jGpISIikgGufpKO5SciIiLSCRypISIikgEDA4X40NAXJUg8/1XHpIaIiEgGWH6SjuUnIiIi0gkcqSEiIpIBrn6SjkkNERGRDLD8JB2TGiIiIhngSI10nFNDREREOoEjNURERDLAkRrpmNQQERHJAOfUSMfyExEREekEjtQQERHJgAJaKD9Bv4dqmNQQERHJAMtP0rH8RERERDqBIzVEREQywNVP0jGpISIikgGWn6Rj+YmIiIh0AkdqiIiIZIDlJ+mY1BAREckAy0/SMakhIiKSAY7USMc5NURERKQTOFJDREQkB1ooP+n5A4WZ1BAREckBy0/SsfxEREREOoEjNURERDLA1U/SMakhIiKSAZafpGP5iYiIiHQCR2qIiIhkgOUn6ZjUEBERyQDLT9Kx/ERERKSnYmNj0bdvX9ja2kKhUGD37t1qx4cPHy4mW2Vbz5491dpkZmYiICAAKpUKlpaWGDlyJHJzc9XaXLhwAZ06dYKxsTHs7OywePHicrHs3LkTTZs2hbGxMTw8PLBv3z6N74dJDRERkQw8mzy86KaJvLw8tGzZEqtWrXpum549eyItLU3cvv32W7XjAQEBuHTpEqKjoxEVFYXY2FiMHj1aPJ6Tk4MePXrA3t4eZ8+exZIlSxAeHo4vv/xSbHPixAkMGTIEI0eOxLlz59C/f3/0798fFy9e1Oh+WH4iIiKSgeqYU9OrVy/06tXrb9solUrY2NhUeOzKlSvYv38/Tp8+jbZt2wIAVq5cid69e+PTTz+Fra0ttmzZgsLCQnz99dcwMjJCs2bNEB8fj88++0xMflasWIGePXsiLCwMADB//nxER0fj888/x9q1ayt9PxypISIikgFtjtTk5OSobQUFBS8c15EjR1C/fn24urpi7NixePDggXgsLi4OlpaWYkIDAD4+PjAwMMCpU6fENp07d4aRkZHYxtfXF0lJSXj48KHYxsfHR+26vr6+iIuL0yhWJjVEREQ6xs7ODhYWFuK2aNGiF+qnZ8+e2LRpEw4dOoT//Oc/OHr0KHr16oWSkhIAQHp6OurXr692To0aNVC7dm2kp6eLbaytrdXalL3+pzZlxyuL5SciIiIZ0Gb56datW1CpVOJ+pVL5Qv35+/uLf/bw8ECLFi3QpEkTHDlyBN27d5cUa1XgSA0REZEMaLP8pFKp1LYXTWqe5ejoiLp16+LatWsAABsbG9y7d0+tTXFxMTIzM8V5ODY2NsjIyFBrU/b6n9o8by7P8zCpISIiokq5ffs2Hjx4gAYNGgAAvLy8kJWVhbNnz4ptYmJiUFpaivbt24ttYmNjUVRUJLaJjo6Gq6srrKysxDaHDh1Su1Z0dDS8vLw0io9JDRERkQwo8L8S1AtvGl4zNzcX8fHxiI+PBwCkpKQgPj4eqampyM3NRVhYGE6ePIkbN27g0KFD6NevH5ycnODr6wsAcHNzQ8+ePTFq1Cj89ttvOH78OMaNGwd/f3/Y2toCAIYOHQojIyOMHDkSly5dwvbt27FixQqEhoaKcXz00UfYv38/li5disTERISHh+PMmTMYN26cRvfDpIaIiEgGDBQKrWyaOHPmDFq1aoVWrVoBAEJDQ9GqVSvMnj0bhoaGuHDhAt566y24uLhg5MiRaNOmDX799Ve1ctaWLVvQtGlTdO/eHb1790bHjh3VnkFjYWGBgwcPIiUlBW3atMGkSZMwe/ZstWfZvPHGG9i6dSu+/PJLtGzZEt999x12796N5s2ba3Q/CkEQBI3OII3k5OTAwsICSo9RUBga/fMJRK+gh6c/r+4QiKpMTk4OrOtYIDs7W23yrTb7t7CwQNfFv6CGiamkvoqf5OHIFJ8qi1XuuPqJiIhIBviFltIxqSEiIpIBfqGldExqiIiIZMBA8XST2oc+40RhIiIi0gkcqSEiIpIDhRbKR3o+UsOkhoiISAY4UVg6lp+IiIhIJ3CkhoiISAYU//1Pah/6jEkNERGRDHD1k3QsPxEREZFO4EgNERGRDPDhe9JVKqn56aefKt3hW2+99cLBEBER6SuufpKuUklN//79K9WZQqFASUmJlHiIiIiIXkilkprS0tKqjoOIiEivGSgUMJA41CL1/FedpDk1+fn5MDY21lYsREREeovlJ+k0Xv1UUlKC+fPno2HDhjAzM8P169cBALNmzcJXX32l9QCJiIj0QdlEYambPtM4qVm4cCEiIyOxePFiGBkZifubN2+O9evXazU4IiIiosrSOKnZtGkTvvzySwQEBMDQ0FDc37JlSyQmJmo1OCIiIn1RVn6SuukzjefU3LlzB05OTuX2l5aWoqioSCtBERER6RtOFJZO45Ead3d3/Prrr+X2f/fdd2jVqpVWgiIiIiLSlMYjNbNnz0ZgYCDu3LmD0tJS/PDDD0hKSsKmTZsQFRVVFTESERHpPMV/N6l96DONR2r69euHPXv24JdffoGpqSlmz56NK1euYM+ePXjzzTerIkYiIiKdx9VP0r3Qc2o6deqE6OhobcdCRERE9MJe+OF7Z86cwZUrVwA8nWfTpk0brQVFRESkbwwUTzepfegzjZOa27dvY8iQITh+/DgsLS0BAFlZWXjjjTewbds2NGrUSNsxEhER6Tx+S7d0Gs+pCQoKQlFREa5cuYLMzExkZmbiypUrKC0tRVBQUFXESERERPSPNB6pOXr0KE6cOAFXV1dxn6urK1auXIlOnTppNTgiIiJ9oucDLZJpnNTY2dlV+JC9kpIS2NraaiUoIiIifcPyk3Qal5+WLFmC8ePH48yZM+K+M2fO4KOPPsKnn36q1eCIiIj0RdlEYambPqvUSI2VlZVa9peXl4f27dujRo2npxcXF6NGjRr44IMP0L9//yoJlIiIiOjvVCqpWb58eRWHQUREpN9YfpKuUklNYGBgVcdBRESk1/g1CdK98MP3ACA/Px+FhYVq+1QqlaSAiIiIiF6ExklNXl4epk6dih07duDBgwfljpeUlGglMCIiIn1ioFDAQGL5SOr5rzqNVz9NmTIFMTExWLNmDZRKJdavX4+5c+fC1tYWmzZtqooYiYiIdJ5CoZ1Nn2k8UrNnzx5s2rQJXbt2xYgRI9CpUyc4OTnB3t4eW7ZsQUBAQFXESURERPS3NB6pyczMhKOjI4Cn82cyMzMBAB07dkRsbKx2oyMiItITZaufpG76TOOkxtHRESkpKQCApk2bYseOHQCejuCUfcElERERaYblJ+k0TmpGjBiB8+fPAwCmTZuGVatWwdjYGCEhIQgLC9N6gERERESVofGcmpCQEPHPPj4+SExMxNmzZ+Hk5IQWLVpoNTgiIiJ9wdVP0kl6Tg0A2Nvbw97eXhuxEBER6S1tlI/0PKepXFITERFR6Q4nTJjwwsEQERHpK35NgnSVSmqWLVtWqc4UCgWTGiIiIqoWlUpqylY70Ys7vD0cZub8CgnSTbczn1R3CERV5tGjl/P5NsALrN6poA99JnlODREREUnH8pN0+p7UERERkY7gSA0REZEMKBSAAVc/ScKkhoiISAYMtJDUSD3/VcfyExEREemEF0pqfv31V7z33nvw8vLCnTt3AACbN2/GsWPHtBocERGRvuAXWkqncVLz/fffw9fXFyYmJjh37hwKCgoAANnZ2fjkk0+0HiAREZE+KCs/Sd30mcZJzYIFC7B27VqsW7cONWvWFPd7e3vj999/12pwRERERJWl8UThpKQkdO7cudx+CwsLZGVlaSMmIiIivcPvfpJO45EaGxsbXLt2rdz+Y8eOwdHRUStBERER6Zuyb+mWuukzjZOaUaNG4aOPPsKpU6egUChw9+5dbNmyBZMnT8bYsWOrIkYiIiKdZ6ClTZ9pXH6aNm0aSktL0b17dzx+/BidO3eGUqnE5MmTMX78+KqIkYiIiOgfaZzUKBQKzJgxA2FhYbh27Rpyc3Ph7u4OMzOzqoiPiIhIL3BOjXQv/ERhIyMjuLu7azMWIiIivWUA6XNiDKDfWY3GSU23bt3+9uE+MTExkgIiIiIiehEaJzWenp5qr4uKihAfH4+LFy8iMDBQW3ERERHpFZafpNM4qVm2bFmF+8PDw5Gbmys5ICIiIn3EL7SUTmurv9577z18/fXX2uqOiIiISCMvPFH4WXFxcTA2NtZWd0RERHpFoYDkicIsP2lowIABaq8FQUBaWhrOnDmDWbNmaS0wIiIifcI5NdJpnNRYWFiovTYwMICrqyvmzZuHHj16aC0wIiIiIk1olNSUlJRgxIgR8PDwgJWVVVXFREREpHc4UVg6jSYKGxoaokePHvw2biIiIi1TaOk/fabx6qfmzZvj+vXrVRELERGR3iobqZG66TONk5oFCxZg8uTJiIqKQlpaGnJyctQ2IiIioupQ6aRm3rx5yMvLQ+/evXH+/Hm89dZbaNSoEaysrGBlZQVLS0vOsyEiInpB1TFSExsbi759+8LW1hYKhQK7d+9WOy4IAmbPno0GDRrAxMQEPj4+uHr1qlqbzMxMBAQEQKVSwdLSEiNHjiz3MN4LFy6gU6dOMDY2hp2dHRYvXlwulp07d6Jp06YwNjaGh4cH9u3bp9nNQIOJwnPnzsWYMWNw+PBhjS9CREREf0+hUPztdytWtg9N5OXloWXLlvjggw/KPbIFABYvXoyIiAhs3LgRDg4OmDVrFnx9fXH58mXx2XQBAQFIS0tDdHQ0ioqKMGLECIwePRpbt24FAOTk5KBHjx7w8fHB2rVrkZCQgA8++ACWlpYYPXo0AODEiRMYMmQIFi1ahD59+mDr1q3o378/fv/9dzRv3rzy9y8IglCZhgYGBkhPT0f9+vUr3Tk9/Z9pYWGBE5fvwMxcVd3hEFUJEyPD6g6BqMo8epSD1k42yM7Ohkql/d/jZX9PzIuKh7GpuaS+8vMeYXYfzxeKVaFQYNeuXejfvz+Ap6M0tra2mDRpEiZPngwAyM7OhrW1NSIjI+Hv748rV67A3d0dp0+fRtu2bQEA+/fvR+/evXH79m3Y2tpizZo1mDFjBtLT02FkZAQAmDZtGnbv3o3ExEQAwLvvvou8vDxERUWJ8XTo0AGenp5Yu3Ztpe9Bozk1UjNIIiIiqpjcJgqnpKQgPT0dPj4+4j4LCwu0b98ecXFxAJ5+m4ClpaWY0ACAj48PDAwMcOrUKbFN586dxYQGAHx9fZGUlISHDx+Kbf56nbI2ZdepLI2eU+Pi4vKPiU1mZqZGARAREZF2nyj87MIdpVIJpVKpUV/p6ekAAGtra7X91tbW4rGKKjg1atRA7dq11do4ODiU66PsmJWVFdLT0//2OpWlUVIzd+7cck8UJiIiInmxs7NTez1nzhyEh4dXTzAvkUZJjb+/P+fUEBERVQEDhULyF1qWnX/r1i21OTWajtIAgI2NDQAgIyMDDRo0EPdnZGTA09NTbHPv3j2184qLi5GZmSmeb2Njg4yMDLU2Za//qU3Z8cqq9JwazqchIiKqOtqcU6NSqdS2F0lqHBwcYGNjg0OHDon7cnJycOrUKXh5eQEAvLy8kJWVhbNnz4ptYmJiUFpaivbt24ttYmNjUVRUJLaJjo6Gq6ur+CgYLy8vteuUtSm7TmVVOqmp5CIpIiIiekXk5uYiPj4e8fHxAJ5ODo6Pj0dqaioUCgUmTpyIBQsW4KeffkJCQgLef/992Nraiiuk3Nzc0LNnT4waNQq//fYbjh8/jnHjxsHf3x+2trYAgKFDh8LIyAgjR47EpUuXsH37dqxYsQKhoaFiHB999BH279+PpUuXIjExEeHh4Thz5gzGjRun0f1UuvxUWlqqUcdERESkAS1MFNb0q5/OnDmDbt26ia/LEo3AwEBERkZiypQpyMvLw+jRo5GVlYWOHTti//794jNqAGDLli0YN24cunfvDgMDAwwcOBARERHicQsLCxw8eBDBwcFo06YN6tati9mzZ4vPqAGAN954A1u3bsXMmTPx8ccfw9nZGbt379boGTWABs+poRfD59SQPuBzakiXvazn1Cw5cAEmEp9T8yTvEcJ8W1RZrHKn0URhIiIiqhraXNKtrzT+QksiIiIiOeJIDRERkQxo44nA2nyi8KuISQ0REZEMaPM5NfqK5SciIiLSCRypISIikgFOFJaOSQ0REZEMGEAL5SdNH1SjY1h+IiIiIp3AkRoiIiIZYPlJOiY1REREMmAA6eUTfS+/6Pv9ExERkY7gSA0REZEMKBQKKCTWj6Se/6pjUkNERCQDCmj8JdsV9qHPmNQQERHJAJ8oLB3n1BAREZFO4EgNERGRTOj3OIt0TGqIiIhkgM+pkY7lJyIiItIJHKkhIiKSAS7plo5JDRERkQzwicLS6fv9ExERkY7gSA0REZEMsPwkHZMaIiIiGeAThaVj+YmIiIh0AkdqiIiIZIDlJ+mY1BAREckAVz9Jx6SGiIhIBjhSI52+J3VERESkIzhSQ0REJANc/SQdkxoiIiIZ4BdaSsfyExEREekEjtQQERHJgAEUMJBYQJJ6/quOSQ0REZEMsPwkHctPREREpBM4UkNERCQDiv/+J7UPfcakhoiISAZYfpKO5SciIiLSCRypISIikgGFFlY/sfxERERE1Y7lJ+mY1BAREckAkxrpOKeGiIiIdAJHaoiIiGSAS7qlY1JDREQkAwaKp5vUPvQZy09ERESkEzhSQ0REJAMsP0nHpIaIiEgGuPpJOpafiIiISCdwpIaIiEgGFJBePtLzgRomNURERHLA1U/SsfxEREREOuGVGKlRKBTYtWsX+vfvX92hUDXYuPMIVm3aD/+3vBE6qq+4/0LiTazZfACXkm7B0MAAzo4NEDF3JIyVNXE2IRljP15XYX+RS4Ph7mKHL7dGY/23h8odN1bWROx386vsfoi27zmB7XvjcDfjIQCgib01xgS8iU7tmopt4i/fwMrI/UhITIWBoQFcHW3xxSejYKysqdZXYWExhn4UgaTradi5eiKaNmkIACgoLMK8iO9x+eodpKTeQ+f2bogIH/7S7pE0x9VP0lV7UpOeno6FCxdi7969uHPnDurXrw9PT09MnDgR3bt3r+7w8MMPP2Dt2rU4e/YsMjMzce7cOXh6elZ3WHrj8h+38MP+U3BqbKO2/0LiTXw052sMH9QNk0f3Qw1DA/yRkgaD/469tmhqj32bZqid88U3B3H6fDLcnBsBAN57uzMG9Oqg1iZ4xjq4//c4UVWxrmeJiR/0hn3DuhAE4KfoM5gQHomdqybCqbEN4i/fwNgZX2GkfzdM/7A/DA0NkHQ9DQYVLG357Ku9qFfHAknX09T2l5QKMDaqiYB+HfHLsQsv69ZIAq5+kq5ak5obN27A29sblpaWWLJkCTw8PFBUVIQDBw4gODgYiYmJ1RkeACAvLw8dO3bE4MGDMWrUqOoOR688flKAWUu3Y8b4Afh6e4zaseXro/BuX28EvtNV3GffqJ7455o1a6Culbn4uri4BLGnLmNwnzeg+O9PfS0TJWqZKMU2f6TcRcqte5gW/HYV3RHRU107uKu9njCiF7ZHxeFCYiqcGttgyRd7MLS/N4Le/ZfYxsGufrl+fj2diBNn/8CyWe/j2Gn135e1jI0wa8JAAMC5yyl4lJtfBXdC2qSA9Im+ep7TVO+cmg8//BAKhQK//fYbBg4cCBcXFzRr1gyhoaE4efLkc8+bOnUqXFxcUKtWLTg6OmLWrFkoKioSj58/fx7dunWDubk5VCoV2rRpgzNnzgAAbt68ib59+8LKygqmpqZo1qwZ9u3b99xrDRs2DLNnz4aPj4/2bpwqZfHaH+Hd1hWvezqr7c/MysXFpFuwsjDFyLDV6DlsAf5v2heIv3TjuX3FnrqM7EeP0cen7XPb/HjwNF5rWBetmjlo6xaI/lFJSSl+PhKPJwWFaOlmjwdZubiQmIralmZ4b+Ln6PLuXAyfvAa/X0xRO+/Ph48Qvvw7LJriX64kRaSvqm2kJjMzE/v378fChQthampa7rilpeVzzzU3N0dkZCRsbW2RkJCAUaNGwdzcHFOmTAEABAQEoFWrVlizZg0MDQ0RHx+PmjWf/tAHBwejsLAQsbGxMDU1xeXLl2FmZqa1+yooKEBBQYH4OicnR2t965ODseeRlHwHkZ+NK3fsTnomAGDdt4fw0Qe94eLQAHtjfkfwzHX4dlUIXrOtW+6cn6LPoEMrF1jXtajwegWFRThwJB7vD+qq1fsgep4/UtLw3sTPUVhYjFomRlg+OxBN7K1x/spNAMCazdGYNKoPmjaxxU+/nEXQtC+w64tJsG9YD4IgYOan2zHYrwOaudiJPxP0ajOAosISo6Z96LNqS2quXbsGQRDQtGnTf278jJkzZ4p/bty4MSZPnoxt27aJSU1qairCwsLEvp2d//cv/dTUVAwcOBAeHh4AAEdHRym3Uc6iRYswd+5crfapbzLuZ+GzdXuwct5IKI3K/wtUEAQAwICer6Pvf0deXJs0xJkLydgTfQbBgT3V+/szGyfP/YFPpgx97jWPxF1C3pMC+P2rtRbvhOj5HBrVw3erQ/DocT6if72AmZ9ux4YlYyGUPv18v9O7A972bQcAcHNqiFPxV7HrwGlM/KA3tv54HI+fFKiVp+jVx/KTdNWW1JT9xfQitm/fjoiICCQnJyM3NxfFxcVQqVTi8dDQUAQFBWHz5s3w8fHBO++8gyZNmgAAJkyYgLFjx+LgwYPw8fHBwIED0aJFC8n3U2b69OkIDQ0VX+fk5MDOzk5r/euDK9fuIDMrF+9PXCnuKyktxblLN7AzKg47104CADjYWaud17hRfaTfzyrXX9QvZ2BhXgud27uXO1bmx4On0bFdU9T5yzwcoqpUs2YNvNbw6ahiM+dGuJh0C9/s/hUj/5uoONqrz6FxtLNG2r0sAMCp+Gs4f+Um2vSZrtbGf1wE/P7VCgvD/Kv+BohkqNrm1Dg7O0OhUGg8GTguLg4BAQHo3bs3oqKicO7cOcyYMQOFhYVim/DwcFy6dAl+fn6IiYmBu7s7du3aBQAICgrC9evXMWzYMCQkJKBt27ZYuXLl8y6nMaVSCZVKpbaRZtq1dMK3n0/ENxETxM3NqRF6dvHENxET0NCmNurVVuHmnftq56XevY8G9S3V9gmCgD2/nEXvbq1Ro4Zhhde7k56JswnX8dab7arqloj+kSAIKCwqRkNrK9Svo8KN2+qf75t37sO2vhUAYPqH/fDdmlDsXBOCnWtCsHrBBwCAJR8HYPzwnuX6pleEQkubHqu2pKZ27drw9fXFqlWrkJeXV+54VlZWheedOHEC9vb2mDFjBtq2bQtnZ2fcvHmzXDsXFxeEhITg4MGDGDBgADZs2CAes7Ozw5gxY/DDDz9g0qRJWLeu4ueZUPUwraVEE3sbtc3EuCYsVLXQxN4GCoUC7w3ojO17juPQ8QTcuvsn1n5zEDdv3y+XmJy+kIy7GZno1+P5CcueX86grpU53mjjWtW3RgQAWP71PpxJuI476Zn4IyUNy7/eh9MXrsOvW2soFAoMH9QVW3cfx8FfLyD1zp9YuXE/Um7dw4CeTz/HDepbwbmxjbjZN3y68s/Otg5s6lmK10m+mYHE5DvIefQEuXn5SEy+g8TkO9Vxy1QJCi39p8+qdUn3qlWr4O3tjddffx3z5s1DixYtUFxcjOjoaKxZswZXrlwpd46zszNSU1Oxbds2tGvXDnv37hVHYQDgyZMnCAsLw6BBg+Dg4IDbt2/j9OnTGDjw6dLGiRMnolevXnBxccHDhw9x+PBhuLm5PTfGzMxMpKam4u7duwCApKQkAICNjQ1sbGyeex5VrSH9OqKwsBjL1kch59FjODs0wMp5QWjUoI5au58OnkYLN3s0rmA5LACUlpYi6tBZ+HVvA0NDPmCbXo7MrFzMWLIN9zNzYF7LGM4ODbB2YRDeaOMCABg2oBMKioqweO1PyHn0GC6Otvhy0WjYVTAJ/u98OOsr8QF/APDOh8sBAAkHlmjtXojkRCFImdyiBWlpaVi4cCGioqKQlpaGevXqoU2bNggJCUHXrl2fBvnME4WnTJmCr7/+GgUFBfDz80OHDh0QHh6OrKwsFBYWIjAwEMePH0dGRgbq1q2LAQMGYMmSJTA2Nsb48ePx888/4/bt21CpVOjZsyeWLVuGOnXqVBhfZGQkRowYUW7/nDlzEB4e/o/3l5OTAwsLC5y4fAdm5ixFkW4yMaq4tEekCx49ykFrJxtkZ2dXyZSCsr8nDsWnSv57IvdRDrp7vlZlscpdtSc1uo5JDekDJjWky15WUhOjpaTmX3qc1HC8nYiIiHRCtX/3ExEREYEPqtECJjVEREQywG/plo5JDRERkQzwW7ql45waIiIi0gkcqSEiIpIBTqmRjkkNERGRHDCrkYzlJyIiItIJTGqIiIhkoDq++yk8PBwKhUJta9q0qXg8Pz8fwcHBqFOnDszMzDBw4EBkZGSo9ZGamgo/Pz/UqlUL9evXR1hYGIqLi9XaHDlyBK1bt4ZSqYSTkxMiIyNf+H36O0xqiIiIZKBs9ZPUTVPNmjVDWlqauB07dkw8FhISgj179mDnzp04evQo7t69iwEDBojHS0pK4Ofnh8LCQpw4cQIbN25EZGQkZs+eLbZJSUmBn58funXrhvj4eEycOBFBQUE4cOCApPerIpxTQ0REpMdq1KhR4Rc0Z2dn46uvvsLWrVvxr3/9CwCwYcMGuLm54eTJk+jQoQMOHjyIy5cv45dffoG1tTU8PT0xf/58TJ06FeHh4TAyMsLatWvh4OCApUuXAgDc3Nxw7NgxLFu2DL6+vlq9F47UEBERyYBCS5umrl69CltbWzg6OiIgIACpqakAgLNnz6KoqAg+Pj5i26ZNm+K1115DXFwcACAuLg4eHh6wtrYW2/j6+iInJweXLl0S2/y1j7I2ZX1oE0dqiIiI5ECLq59ycnLUdiuVSiiVynLN27dvj8jISLi6uiItLQ1z585Fp06dcPHiRaSnp8PIyAiWlpZq51hbWyM9PR0AkJ6erpbQlB0vO/Z3bXJycvDkyROYmJi88O0+i0kNERGRjrGzs1N7PWfOHISHh5dr16tXL/HPLVq0QPv27WFvb48dO3ZoNdl4WZjUEBERyYA2v/vp1q1bUKlU4v6KRmkqYmlpCRcXF1y7dg1vvvkmCgsLkZWVpTZak5GRIc7BsbGxwW+//abWR9nqqL+2eXbFVEZGBlQqldYTJ86pISIikgFtrn5SqVRqW2WTmtzcXCQnJ6NBgwZo06YNatasiUOHDonHk5KSkJqaCi8vLwCAl5cXEhIScO/ePbFNdHQ0VCoV3N3dxTZ/7aOsTVkf2sSkhoiISAaqY6Lw5MmTcfToUdy4cQMnTpzA22+/DUNDQwwZMgQWFhYYOXIkQkNDcfjwYZw9exYjRoyAl5cXOnToAADo0aMH3N3dMWzYMJw/fx4HDhzAzJkzERwcLCZSY8aMwfXr1zFlyhQkJiZi9erV2LFjB0JCQqS9YRVg+YmIiEhP3b59G0OGDMGDBw9Qr149dOzYESdPnkS9evUAAMuWLYOBgQEGDhyIgoIC+Pr6YvXq1eL5hoaGiIqKwtixY+Hl5QVTU1MEBgZi3rx5YhsHBwfs3bsXISEhWLFiBRo1aoT169drfTk3ACgEQRC03iuJcnJyYGFhgROX78DMXPXPJxC9gkyMDKs7BKIq8+hRDlo72SA7O1ttnoq2lP09EXdF+t8TuY9y4OXWsMpilTuO1BAREcmANicK6yvOqSEiIiKdwJEaIiIiGXjR7256tg99xqSGiIhIBrT4QGG9xfITERER6QSO1BAREckBh2okY1JDREQkA1z9JB3LT0RERKQTOFJDREQkA1z9JB2TGiIiIhnglBrpmNQQERHJAbMayTinhoiIiHQCR2qIiIhkgKufpGNSQ0REJAdamCis5zkNy09ERESkGzhSQ0REJAOcJywdkxoiIiI5YFYjGctPREREpBM4UkNERCQDXP0kHZMaIiIiGeDXJEjH8hMRERHpBI7UEBERyQDnCUvHpIaIiEgOmNVIxqSGiIhIBjhRWDrOqSEiIiKdwJEaIiIiGVBAC6uftBLJq4tJDRERkQxwSo10LD8RERGRTuBIDRERkQzw4XvSMakhIiKSBRagpGL5iYiIiHQCR2qIiIhkgOUn6ZjUEBERyQCLT9Kx/EREREQ6gSM1REREMsDyk3RMaoiIiGSA3/0kHZMaIiIiOeCkGsk4p4aIiIh0AkdqiIiIZIADNdIxqSEiIpIBThSWjuUnIiIi0gkcqSEiIpIBrn6SjkkNERGRHHBSjWQsPxEREZFO4EgNERGRDHCgRjomNURERDLA1U/SsfxEREREOoEjNURERLIgffWTvhegmNQQERHJAMtP0rH8RERERDqBSQ0RERHpBJafiIiIZIDlJ+mY1BAREckAvyZBOpafiIiISCdwpIaIiEgGWH6SjkkNERGRDPBrEqRj+YmIiIh0AkdqiIiI5IBDNZIxqSEiIpIBrn6SjuUnIiIi0gkcqSEiIpIBrn6SjkkNERGRDHBKjXRMaoiIiOSAWY1knFNDREREOoEjNURERDLA1U/SMakhIiKSAU4Ulo5JTRUTBAEAkJf7qJojIao6xUaG1R0CUZXJffT093fZ7/OqkpOTI4s+XmVMaqrYo//+MLz5etNqjoSIiKR49OgRLCwstN6vkZERbGxs4Oxgp5X+bGxsYGRkpJW+XjUKoapTTz1XWlqKu3fvwtzcHAp9Hxd8CXJycmBnZ4dbt25BpVJVdzhEWsfP+MsnCAIePXoEW1tbGBhUzfqa/Px8FBYWaqUvIyMjGBsba6WvVw1HaqqYgYEBGjVqVN1h6B2VSsVf+KTT+Bl/uapihOavjI2N9TYR0SYu6SYiIiKdwKSGiIiIdAKTGtIpSqUSc+bMgVKprO5QiKoEP+NEz8eJwkRERKQTOFJDREREOoFJDREREekEJjVERESkE5jUkKwpFArs3r27usMgqhL8fBNpF5Maqjbp6ekYP348HB0doVQqYWdnh759++LQoUPVHRqAp08RnT17Nho0aAATExP4+Pjg6tWr1R0WvSLk/vn+4Ycf0KNHD9SpUwcKhQLx8fHVHRKRZExqqFrcuHEDbdq0QUxMDJYsWYKEhATs378f3bp1Q3BwcHWHBwBYvHgxIiIisHbtWpw6dQqmpqbw9fVFfn5+dYdGMvcqfL7z8vLQsWNH/Oc//6nuUIi0RyCqBr169RIaNmwo5Obmljv28OFD8c8AhF27domvp0yZIjg7OwsmJiaCg4ODMHPmTKGwsFA8Hh8fL3Tt2lUwMzMTzM3NhdatWwunT58WBEEQbty4IfTp00ewtLQUatWqJbi7uwt79+6tML7S0lLBxsZGWLJkibgvKytLUCqVwrfffivx7knXyf3z/VcpKSkCAOHcuXMvfL9EcsHvfqKXLjMzE/v378fChQthampa7rilpeVzzzU3N0dkZCRsbW2RkJCAUaNGwdzcHFOmTAEABAQEoFWrVlizZg0MDQ0RHx+PmjVrAgCCg4NRWFiI2NhYmJqa4vLlyzAzM6vwOikpKUhPT4ePj4+4z8LCAu3bt0dcXBz8/f0lvAOky16FzzeRrmJSQy/dtWvXIAgCmjZtqvG5M2fOFP/cuHFjTJ48Gdu2bRN/6aempiIsLEzs29nZWWyfmpqKgQMHwsPDAwDg6Oj43Oukp6cDAKytrdX2W1tbi8eIKvIqfL6JdBXn1NBLJ0h4iPX27dvh7e0NGxsbmJmZYebMmUhNTRWPh4aGIigoCD4+Pvj3v/+N5ORk8diECROwYMECeHt7Y86cObhw4YKk+yCqCD/fRNWHSQ29dM7OzlAoFEhMTNTovLi4OAQEBKB3796IiorCuXPnMGPGDBQWFoptwsPDcenSJfj5+SEmJgbu7u7YtWsXACAoKAjXr1/HsGHDkJCQgLZt22LlypUVXsvGxgYAkJGRobY/IyNDPEZUkVfh802ks6p3Sg/pq549e2o8kfLTTz8VHB0d1dqOHDlSsLCweO51/P39hb59+1Z4bNq0aYKHh0eFx8omCn/66afivuzsbE4UpkqR++f7rzhRmHQJR2qoWqxatQolJSV4/fXX8f333+Pq1au4cuUKIiIi4OXlVeE5zs7OSE1NxbZt25CcnIyIiAjxX6kA8OTJE4wbNw5HjhzBzZs3cfz4cZw+fRpubm4AgIkTJ+LAgQNISUnB77//jsOHD4vHnqVQKDBx4kQsWLAAP/30ExISEvD+++/D1tYW/fv31/r7QbpF7p9v4OmE5vj4eFy+fBkAkJSUhPj4eM4Zo1dbdWdVpL/u3r0rBAcHC/b29oKRkZHQsGFD4a233hIOHz4stsEzS17DwsKEOnXqCGZmZsK7774rLFu2TPyXbEFBgeDv7y/Y2dkJRkZGgq2trTBu3DjhyZMngiAIwrhx44QmTZoISqVSqFevnjBs2DDhzz//fG58paWlwqxZswRra2tBqVQK3bt3F5KSkqrirSAdJPfP94YNGwQA5bY5c+ZUwbtB9HIoBEHCrDYiIiIimWD5iYiIiHQCkxoiIiLSCUxqiIiISCcwqSEiIiKdwKSGiIiIdAKTGiIiItIJTGqIiIhIJzCpIdIDw4cPV3sScteuXTFx4sSXHseRI0egUCiQlZX13DYKhQK7d++udJ/h4eHw9PSUFNeNGzegUCgQHx8vqR8iql5MaoiqyfDhw6FQKKBQKGBkZAQnJyfMmzcPxcXFVX7tH374AfPnz69U28okIkREclCjugMg0mc9e/bEhg0bUFBQgH379iE4OBg1a9bE9OnTy7UtLCyEkZGRVq5bu3ZtrfRDRCQnHKkhqkZKpRI2Njawt7fH2LFj4ePjg59++gnA/0pGCxcuhK2tLVxdXQEAt27dwuDBg2FpaYnatWujX79+uHHjhthnSUkJQkNDYWlpiTp16mDKlCl49ttQni0/FRQUYOrUqbCzs4NSqYSTkxO++uor3LhxA926dQMAWFlZQaFQYPjw4QCA0tJSLFq0CA4ODjAxMUHLli3x3XffqV1n3759cHFxgYmJCbp166YWZ2VNnToVLi4uqFWrFhwdHTFr1iwUFRWVa/fFF1/Azs4OtWrVwuDBg5Gdna12fP369XBzc4OxsTGaNm2K1atXaxwLEckbkxoiGTExMUFhYaH4+tChQ0hKSkJ0dDSioqJQVFQEX19fmJub49dff8Xx48dhZmaGnj17iuctXboUkZGR+Prrr3Hs2DFkZmaqfdtzRd5//318++23iIiIwJUrV/DFF1/AzMwMdnZ2+P777wE8/RbntLQ0rFixAgCwaNEibNq0CWvXrsWlS5cQEhKC9957D0ePHgXwNPkaMGAA+vbti/j4eAQFBWHatGkavyfm5uaIjIzE5cuXsWLFCqxbtw7Lli1Ta3Pt2jXs2LEDe/bswf79+3Hu3Dl8+OGH4vEtW7Zg9uzZWLhwIa5cuYJPPvkEs2bNwsaNGzWOh4hkrJq/UJNIbwUGBgr9+vUTBOHpN4JHR0cLSqVSmDx5snjc2tpaKCgoEM/ZvHmz4OrqKpSWlor7CgoKBBMTE+HAgQOCIAhCgwYNhMWLF4vHi4qKhEaNGonXEgRB6NKli/DRRx8JgiAISUlJAgAhOjq6wjgPHz4sABAePnwo7svPzxdq1aolnDhxQq3tyJEjhSFDhgiCIAjTp08X3N3d1Y5PnTq1XF/PwjPfXP2sJUuWCG3atBFfz5kzRzA0NBRu374t7vv5558FAwMDIS0tTRAEQWjSpImwdetWtX7mz58veHl5CYIgCCkpKQIA4dy5c8+9LhHJH+fUEFWjqKgomJmZoaioCKWlpRg6dCjCw8PF4x4eHmrzaM6fP49r167B3NxcrZ/8/HwkJycjOzsbaWlpaN++vXisRo0aaNu2bbkSVJn4+HgYGhqiS5culY772rVrePz4Md588021/YWFhWjVqhUA4MqVK2pxAICXl1elr1Fm+/btiIiIQHJyMnJzc1FcXAyVSqXW5rXXXkPDhg3VrlNaWoqkpCSYm5sjOTkZI0eOxKhRo8Q2xcXFsLCw0DgeIpIvJjVE1ahbt25Ys2YNjIyMYGtrixo11H8kTU1N1V7n5uaiTZs22LJlS7m+6tWr90IxmJiYaHxObm4uAGDv3r1qyQTwdJ6QtsTFxSEgIABz586Fr68vLCwssG3bNixdulTjWNetW1cuyTI0NNRarERU/ZjUEFUjU1NTODk5Vbp969atsX37dtSvX7/caEWZBg0a4NSpU+jcuTOApyMSZ8+eRevWrSts7+HhgdLSUhw9ehQ+Pj7ljpeNFJWUlIj73N3doVQqkZqa+twRHjc3N3HSc5mTJ0/+803+xYkTJ2Bvb48ZM2aI+27evFmuXWpqKu7evQtbW1vxOgYGBnB1dYW1tTVsbW1x/fp1BAQEaHR9Inq1cKIw0SskICAAdevWRb9+/fDrr78iJSUFR44cwYQJE3D79m0AwEcffYR///vf2L17NxITE/Hhhx/+7TNmGjdujMDAQHzwwQfYvXu32OeOHTsAAPb29lAoFIiKisL9+/eRm5sLc3NzTJ48GSEhIdi4cSOSk5Px+++/Y+XKleLk2zFjxuDq1asICwtDUlIStm7disjISI3u19nZGampqdi2bRuSk5MRERFR4aRnY2NjBAYG4vz58/j1118xYcIEDB48GDY2NgCAuXPnYtGiRYiIiMAff/yBhIQEbNiwAZ999plG8RCRvDGpIXqF1KpVC7GxsXjttdcwYMAAuLm5YeTIkcjPzxdHbiZNmoRhw4YhMDAQXl5eMDc3x9tvv/23/a5ZswaDBg3Chx9+iKZNm2LUqFHIy8sDADRs2BBz587FtGnTYG1tjXHjxgEA5s+fj1mzZmHRokVwc3NDz549sXfvXjg4OAB4Os/l+++/x+7du9GyZUusXbsWn3zyiUb3+9ZbbyEkJATjxo2Dp6cnTpw4gVmzZpVr5+TkhAEDBqB3797o0aMHWrRoobZkOygoCOvXr8eGDRvg4eGBLl26IDIyUoyViHSDQnje7EEiIiKiVwhHaoiIiEgnMKkhIiIincCkhoiIiHQCkxoiIiLSCUxqiIiISCcwqSEiIiKdwKSGiIiIdAKTGiIiItIJTGqIiIhIJzCpISIiIp3ApIaIiIh0ApMaIiIi0gn/D66XqMn9tUWeAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7396236658096313"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "val_predictions = []\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Flatten the predictions\n",
    "val_predictions = [p[0] for p in val_predictions]\n",
    "print(\"Validation predictions obtained.\")\n",
    "\n",
    "from utils.eval_helpers import evaluate_model_for_recall\n",
    "evaluate_model_for_recall(target_class=0, desired_recall=0.98, y_true=np.array(all_labels).astype('int'), y_pred_proba=np.array(val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
