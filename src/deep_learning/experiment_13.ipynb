{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "#trying to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/mod_train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "# with h5py.File('../../data/3d_array/test_data_3d_h5.h5', 'r') as f:\n",
    "#     test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2018-03-31    289115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X, nan = 0.0)\n",
    "val_X = np.nan_to_num(val_X, nan = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_3196\\639591509.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_3196\\639591509.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289110</th>\n",
       "      <td>fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289111</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289112</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289113</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289114</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID end_of_month  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31       0\n",
       "1       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31       0\n",
       "2       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2018-03-31       0\n",
       "3       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2018-03-31       0\n",
       "4       0000f99513770170a1aba690daeeb8a96da4a39f11fc27...   2018-03-31       1\n",
       "...                                                   ...          ...     ...\n",
       "289110  fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...   2018-03-31       1\n",
       "289111  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...   2018-03-31       0\n",
       "289112  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2018-03-31       0\n",
       "289113  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31       0\n",
       "289114  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31       0\n",
       "\n",
       "[289115 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 13, 86), (289115, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32124, 13, 86), (32124, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3):\n",
    "        super(MDC, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_scales = len(kernel_sizes)\n",
    "        self.num_kernels_per_scale = num_kernels_per_scale\n",
    "        self.total_kernels = self.num_scales * self.num_kernels_per_scale\n",
    "\n",
    "        # Attention mechanism to generate weights for kernels [cite: 142, 143, 145]\n",
    "        self.attention_pool = nn.AdaptiveAvgPool1d(1) # Pool across time dimension\n",
    "        # Conv1d to generate temporal attention map\n",
    "        self.attention_conv = nn.Conv1d(in_channels, self.total_kernels, kernel_size=1, bias=False)\n",
    "        self.attention_gap = nn.AdaptiveAvgPool1d(1) # Pool attention map to get weights\n",
    "        self.attention_activation = nn.Sigmoid()\n",
    "\n",
    "        # Store the kernels for each scale and each instance per scale\n",
    "        self.weights = nn.Parameter(torch.Tensor(self.total_kernels, out_channels, in_channels, 1)) # Use kernel_size=1 here, will expand later\n",
    "        nn.init.kaiming_uniform_(self.weights, a=np.sqrt(5)) # Initialize weights\n",
    "\n",
    "        # Store kernel sizes correctly\n",
    "        self.k_sizes = []\n",
    "        for k in kernel_sizes:\n",
    "            for _ in range(num_kernels_per_scale):\n",
    "                self.k_sizes.append(k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, T = x.size()\n",
    "\n",
    "        # Calculate attention weights [cite: 142, 145]\n",
    "        pooled_x = self.attention_pool(x) # B x C_in x 1\n",
    "        # The paper's diagram (Fig 3) suggests GAP -> Conv -> GAP -> Sigmoid for attention\n",
    "        # Let's follow the diagram logic more closely:\n",
    "        # GAP on input: B x C_in x T -> B x C_in x 1\n",
    "        att_gap1 = self.attention_pool(x)\n",
    "        # Conv1d on pooled input: B x C_in x 1 -> B x total_kernels x 1 (This seems different from Fig 3's BxmxnxT output)\n",
    "        # Let's reinterpret Fig 3: GAP(x) [B,Cin,T]->[B,Cin,1], then Conv [B,Cin,1]->[B,mxn,1] (This doesn't match BxmxnxT)\n",
    "        # Let's try the alternative interpretation from the text (Section 3.2.1, Eq 2 implies GAP -> Conv -> GAP)\n",
    "        # GAP(x) -> B x Cin x 1\n",
    "        # wa * GAP(x) -> B x mxn x 1 (This still feels off from Fig 3 which applies conv before second GAP)\n",
    "\n",
    "        # Let's follow Fig 3 literally (ignoring the first GAP shown before Conv in the Attention block):\n",
    "        # Conv on input x: B x Cin x T -> B x mxn x T [cite: 143]\n",
    "        attention_map = self.attention_conv(x) # B x total_kernels x T\n",
    "        # GAP on attention_map: B x mxn x T -> B x mxn x 1 [cite: 145]\n",
    "        attention_vector = self.attention_gap(attention_map)\n",
    "        # Sigmoid activation: B x mxn x 1 [cite: 145]\n",
    "        attention_weights = self.attention_activation(attention_vector) # Shape: (batch_size, total_kernels, 1)\n",
    "\n",
    "        # Fuse kernels based on attention weights [cite: 140]\n",
    "        # Reshape weights for broadcasting: (batch_size, total_kernels, 1) -> (batch_size, total_kernels, 1, 1, 1)\n",
    "        # Reshape kernels: (total_kernels, out_c, in_c, 1)\n",
    "        # We need to perform convolution dynamically. PyTorch doesn't easily support dynamic kernel *shapes*.\n",
    "        # A common approach is to have fixed-size kernels and combine their *outputs*, or combine *weights* for a fixed kernel size.\n",
    "        # The paper seems to imply combining weights *before* convolution (Eq 1). This requires all kernels w_i^j to have the same size k.\n",
    "        # However, the goal is *multi-scale*.\n",
    "\n",
    "        # Let's implement the multi-scale aspect by having separate convolutions and combining outputs weighted by attention.\n",
    "        # This deviates slightly from Eq 1 but achieves the multi-scale goal.\n",
    "\n",
    "        outputs = []\n",
    "        current_kernel_idx = 0\n",
    "        for k_size in self.kernel_sizes:\n",
    "            padding = k_size // 2\n",
    "            for i in range(self.num_kernels_per_scale):\n",
    "                # Get the weights for this specific kernel instance (across all batches)\n",
    "                # attention_weights shape: B x total_kernels x 1\n",
    "                # kernel_weights shape: B x 1 x out_c x in_c x k_size\n",
    "                kernel_idx = current_kernel_idx + i\n",
    "                kernel_weight = self.weights[kernel_idx] # out_c x in_c x 1\n",
    "                # Manually create the kernel for Conv1d for this size\n",
    "                dynamic_kernel = kernel_weight.repeat(1, 1, k_size) # out_c x in_c x k_size\n",
    "                \n",
    "                # Perform convolution with this specific kernel\n",
    "                output_i = F.conv1d(x, dynamic_kernel, padding=padding) # B x out_c x T\n",
    "                \n",
    "                # Apply attention weight for this kernel\n",
    "                # attention_weights[:, kernel_idx, :] shape: B x 1 x 1\n",
    "                weighted_output = output_i * attention_weights[:, kernel_idx, :].unsqueeze(-1) # B x out_c x T\n",
    "                outputs.append(weighted_output)\n",
    "                \n",
    "            current_kernel_idx += self.num_kernels_per_scale\n",
    "\n",
    "        # Sum the weighted outputs from all kernels\n",
    "        # This is an alternative interpretation to fusing weights first.\n",
    "        out = torch.sum(torch.stack(outputs), dim=0) # B x out_c x T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3, stride=1):\n",
    "        super(MDCResBlock, self).__init__()\n",
    "        \n",
    "        # Use Conv1d for the residual connection if dimensions change\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.mdc1 = MDC(in_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Paper uses PReLU, let's use ReLU for simplicity or add PReLU if needed. Using PReLU as per paper.\n",
    "        self.prelu1 = nn.PReLU(out_channels)\n",
    "\n",
    "        self.mdc2 = MDC(out_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu2 = nn.PReLU(out_channels) # Activation after final BN before adding shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out = self.mdc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "\n",
    "        out = self.mdc2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.prelu2(out) # Final activation after adding shortcut\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, block_channels=[128, 128, 128], kernel_sizes=[3,5,7], num_kernels_per_scale=2, dropout_rate=0.3, reduction=16):\n",
    "        super(MDCNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        current_channels = input_channels\n",
    "        \n",
    "        # Configuration from paper/Figure 2: 3 Blocks [cite: 130]\n",
    "        # Each block: MDC ResBlock -> MaxPool -> SE -> Dropout\n",
    "        for i, channels in enumerate(block_channels):\n",
    "            # Stride only applied if pooling happens, MaxPooling handles stride=2\n",
    "            res_block = MDCResBlock(current_channels, channels, kernel_sizes, num_kernels_per_scale, stride=1)\n",
    "            max_pool = nn.MaxPool1d(kernel_size=2, stride=2) # Halve the length [cite: 132]\n",
    "            se_block = SEBlock(channels, reduction) # SE block [cite: 133]\n",
    "            dropout = nn.Dropout(dropout_rate) # Dropout [cite: 134]\n",
    "            \n",
    "            block = nn.Sequential(\n",
    "                res_block,\n",
    "                max_pool,\n",
    "                se_block,\n",
    "                dropout\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            current_channels = channels # Update channels for next block\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1) # Global Average Pooling [cite: 130]\n",
    "        # The original ConvModel in experiment_10 has FC layers after pooling.\n",
    "        # MDCNet in the paper feeds features to DPNet or directly to Softmax.\n",
    "        # To make it a component usable in the existing structure, we output features before FC layers.\n",
    "        self.output_channels = current_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: B x T x C_in (e.g., B x 10 x 115)\n",
    "        # Conv1D expects B x C_in x T\n",
    "        x = x.permute(0, 2, 1) # B x C_in x T (e.g., B x 115 x 10)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x) # B x C_out x 1\n",
    "        x = x.view(x.size(0), -1) # Flatten: B x C_out\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedConvModel(nn.Module):\n",
    "    def __init__(self, input_size, time_steps, num_classes=1, mdc_block_channels=[64, 64, 64], mdc_kernel_sizes=[3,5,7], mdc_kernels_per_scale=2, dropout_rate=0.2, fc_size=32):\n",
    "        super(ModifiedConvModel, self).__init__()\n",
    "        \n",
    "        # Instantiate MDCNet feature extractor\n",
    "        self.mdc_net = MDCNet(input_channels=input_size,\n",
    "                              num_classes=num_classes, # Not directly used by MDCNet output layer here\n",
    "                              block_channels=mdc_block_channels,\n",
    "                              kernel_sizes=mdc_kernel_sizes,\n",
    "                              num_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                              dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Get the output feature dimension from MDCNet\n",
    "        mdc_output_channels = self.mdc_net.output_channels\n",
    "\n",
    "        # Fully connected layers (similar to original experiment_10)\n",
    "        self.fc1 = nn.Linear(mdc_output_channels, fc_size)\n",
    "        self.relu_fc = nn.ReLU() # Added ReLU after FC1\n",
    "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "        \n",
    "        # Pass through MDCNet feature extractor\n",
    "        features = self.mdc_net(x) # Output: B x mdc_output_channels\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(features)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Modified ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features (115)\n",
    "time_steps = train_X.shape[1]  # Number of time steps (10)\n",
    "output_size = 1  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=86, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# --- MDCNet Hyperparameters ---\n",
    "# Using smaller channels than paper's example for potentially faster training/less memory\n",
    "mdc_block_channels = [16, 32, 64] # Example channel sizes for each block\n",
    "# Using kernel sizes mentioned in paper, and n=2 as found via cross-validation in paper [cite: 242, 243]\n",
    "mdc_kernel_sizes = [3, 5, 7]\n",
    "mdc_kernels_per_scale = 2\n",
    "dropout_rate = 0.2 # Adjusted dropout\n",
    "fc_size = 16 # Adjusted FC size\n",
    "\n",
    "# Create model instance\n",
    "model = ModifiedConvModel(input_size=input_size,\n",
    "                          time_steps=time_steps,\n",
    "                          num_classes=output_size,\n",
    "                          mdc_block_channels=mdc_block_channels,\n",
    "                          mdc_kernel_sizes=mdc_kernel_sizes,\n",
    "                          mdc_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          fc_size=fc_size)\n",
    "\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "===========================================================================================================================================================\n",
       "ModifiedConvModel                                       [2048, 13, 86]            [2048, 1]                 --                        --\n",
       "â”œâ”€MDCNet: 1-1                                           [2048, 13, 86]            [2048, 64]                --                        --\n",
       "â”‚    â””â”€ModuleList: 2-1                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-1                             [2048, 86, 13]            [2048, 16, 6]             11,940                    53,256,192\n",
       "â”‚    â”‚    â””â”€Sequential: 3-2                             [2048, 16, 6]             [2048, 32, 3]             10,400                    10,616,832\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                             [2048, 32, 3]             [2048, 64, 1]             40,512                    18,219,008\n",
       "â”‚    â””â”€AdaptiveAvgPool1d: 2-2                           [2048, 64, 1]             [2048, 64, 1]             --                        --\n",
       "â”œâ”€Linear: 1-2                                           [2048, 64]                [2048, 16]                1,040                     2,129,920\n",
       "â”œâ”€ReLU: 1-3                                             [2048, 16]                [2048, 16]                --                        --\n",
       "â”œâ”€Linear: 1-4                                           [2048, 16]                [2048, 1]                 17                        34,816\n",
       "â”œâ”€Sigmoid: 1-5                                          [2048, 1]                 [2048, 1]                 --                        --\n",
       "===========================================================================================================================================================\n",
       "Total params: 63,909\n",
       "Trainable params: 63,909\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 84.26\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 9.16\n",
       "Forward/backward pass size (MB): 64.75\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 73.94\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], depth=3) # Increased depth to see inside MDCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([0.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([1.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de68fad16e324cbba77e0416daed718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f81911ae614780a25f1f44047b4a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.3507, Val Loss: 0.3300, Val AUC: 0.9348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548a60ca658041d9b4fd8e74f62c11b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc1615fcea941429784fdfb11516c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.2818, Val Loss: 0.2752, Val AUC: 0.9413\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537d317d32f14195aa23ed096d7adef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15fe152dcdd4d8ebf87bf8bf06c4eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.2697, Val Loss: 0.2748, Val AUC: 0.9455\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216926a93096494a805341ff7b9d4aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f167a8189604a879056ae05a19e6d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.2639, Val Loss: 0.2805, Val AUC: 0.9472\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77bcf57cd934df0914e144189ffc525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0e8daf07704191ac438f464195041f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.2602, Val Loss: 0.2519, Val AUC: 0.9490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc18bae26ded49fca4aa87f58d27c545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb60d7b146184d8080d5c83ab6fa7a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2570, Val Loss: 0.2673, Val AUC: 0.9488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f882ec2ca504d12a0eaa37f67a821b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c8413695ae4e26ac0002f8d789647d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2554, Val Loss: 0.2515, Val AUC: 0.9501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd3fd8c98194516baf7921fea18fb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe7641d190c44ed923b0251069a927a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2534, Val Loss: 0.2495, Val AUC: 0.9505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f9b825e21c483691f9a1c14fa3c70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f4b3ae76b4423cb0f09c8a6e0f414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.2518, Val Loss: 0.2688, Val AUC: 0.9497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c00b031a504e728599841d80471c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe25c6feb03b43aa9c73c45aa4078301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.2508, Val Loss: 0.2466, Val AUC: 0.9509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66b567a8510438a94b666bd30ebe1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68190011cd2412eb0ff70c5c6698349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.2494, Val Loss: 0.2474, Val AUC: 0.9510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d58a3d882a14c8987629646ebf9eb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bd5ba7cfbc4532a01a5b376e6d2fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.2495, Val Loss: 0.2532, Val AUC: 0.9512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd97f847c2e494fa6a495252d53169f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e202c3c3eaf40c986260fac3fcb8bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.2480, Val Loss: 0.2506, Val AUC: 0.9513\n",
      "Early stopping triggered after 13 epochs\n",
      "Training completed in 1m 53s\n",
      "Best val loss: 0.2466, Best val AUC: 0.9509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20 # Adjust as needed\n",
    "patience = 3  # Early stopping patience\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_val_auc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Use state_dict()\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# For tracking metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Training on {device}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for inputs, labels in train_pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_val_loss = running_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    all_preds = [p[0] for p in all_preds]\n",
    "    all_labels = [l[0] for l in all_labels]\n",
    "    # Handle case where validation set might only have one class temporarily during testing/debugging\n",
    "    if len(np.unique(all_labels)) > 1:\n",
    "        epoch_val_auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        epoch_val_auc = 0.0 # Or handle as appropriate, e.g., skip AUC calculation\n",
    "    val_aucs.append(epoch_val_auc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "          f\"Val AUC: {epoch_val_auc:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_val_auc = epoch_val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "# Training complete\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "print(f\"Best val loss: {best_val_loss:.4f}, Best val AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/deep_learning\\experiment_13.pth\n",
      "Checkpoint saved to ../../models/deep_learning\\experiment_13.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model weights\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "save_dir = '../../models/deep_learning'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model state dictionary\n",
    "model_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save additional information for later reference\n",
    "checkpoint_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Checkpoint saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions obtained.\n",
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.6999279\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.8537    0.9800    0.9125     23806\n",
      "     Class 1     0.9008    0.5194    0.6588      8318\n",
      "\n",
      "    accuracy                         0.8607     32124\n",
      "   macro avg     0.8772    0.7497    0.7857     32124\n",
      "weighted avg     0.8659    0.8607    0.8468     32124\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6999279260635376"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "val_predictions = []\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Flatten the predictions\n",
    "val_predictions = [p[0] for p in val_predictions]\n",
    "print(\"Validation predictions obtained.\")\n",
    "\n",
    "from utils.eval_helpers import evaluate_model_for_recall\n",
    "evaluate_model_for_recall(target_class=0, desired_recall=0.98, y_true=np.array(all_labels).astype('int'), y_pred_proba=np.array(val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
