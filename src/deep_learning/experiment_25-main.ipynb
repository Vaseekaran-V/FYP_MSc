{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#trying to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/mod_train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_test_data_3d_h5.h5', 'r') as f:\n",
    "    test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')\n",
    "test_y = pd.read_parquet('../../data/3d_array/test_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X, nan=0.0)\n",
    "val_X = np.nan_to_num(val_X, nan=0.0)\n",
    "test_X = np.nan_to_num(test_X, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2018-03-31    289115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_24720\\847019464.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_24720\\847019464.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_24720\\847019464.py:3: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n",
    "test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289110</th>\n",
       "      <td>fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289111</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289112</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289113</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289114</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID end_of_month  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31       0\n",
       "1       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31       0\n",
       "2       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2018-03-31       0\n",
       "3       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2018-03-31       0\n",
       "4       0000f99513770170a1aba690daeeb8a96da4a39f11fc27...   2018-03-31       1\n",
       "...                                                   ...          ...     ...\n",
       "289110  fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...   2018-03-31       1\n",
       "289111  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...   2018-03-31       0\n",
       "289112  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2018-03-31       0\n",
       "289113  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31       0\n",
       "289114  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31       0\n",
       "\n",
       "[289115 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 13, 86), (289115, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32124, 13, 86), (32124, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], dropout_rate=0.2):\n",
    "        \"\"\"\n",
    "        Parallel Convolutional Block that processes input through multiple convolutional paths\n",
    "        with different kernel sizes and concatenates the results.\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Number of input channels\n",
    "            out_channels: Number of output channels\n",
    "            kernel_sizes: List of kernel sizes for parallel convolutions\n",
    "            dropout_rate: Dropout probability\n",
    "        \"\"\"\n",
    "        super(ParallelConvBlock, self).__init__()\n",
    "        \n",
    "        self.n_paths = len(kernel_sizes)\n",
    "        # Calculate channels per path\n",
    "        path_channels = out_channels // self.n_paths\n",
    "        \n",
    "        # Create parallel convolutional paths\n",
    "        self.paths = nn.ModuleList()\n",
    "        for k_size in kernel_sizes:\n",
    "            padding = k_size // 2  # Same padding to maintain sequence length\n",
    "            path = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, path_channels, kernel_size=k_size, padding=padding),\n",
    "                nn.BatchNorm1d(path_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            self.paths.append(path)\n",
    "            \n",
    "        # Projection layer to ensure output has exactly out_channels\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv1d(path_channels * self.n_paths, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Process input through parallel paths\n",
    "        outputs = [path(x) for path in self.paths]\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        # print(f\"Outputs shape before concatenation: {[out.shape for out in outputs]}\")\n",
    "        x = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        # Apply projection to get final output\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, pool=True, dropout=0.3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) if pool else None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        if self.pool:\n",
    "            x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size=64, num_lstm_layers=1, output_size=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of features in the input sequence (feature dimension).\n",
    "            lstm_hidden_size (int): Hidden size for the LSTM layer.\n",
    "            num_lstm_layers (int): Number of layers for the LSTM.\n",
    "            output_size (int): Size of the final output (e.g., 1 for binary classification).\n",
    "        \"\"\"\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "\n",
    "        # --- CNN Path ---\n",
    "        # First convolutional block (Parallel)\n",
    "        # Input channels = input_size (features)\n",
    "        cnn_out_channels_1 = 100\n",
    "        self.parallel_conv = ParallelConvBlock(input_size, cnn_out_channels_1, kernel_sizes=[3, 5, 7, 9], dropout_rate=0.2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        cnn_out_channels_2 = 64\n",
    "        self.block2 = ConvBlock(cnn_out_channels_1, cnn_out_channels_2, dropout=0.2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.cnn_final_channels = 32\n",
    "        self.block3 = ConvBlock(cnn_out_channels_2, self.cnn_final_channels, pool=False, dropout=0.2) # No pooling in the last block\n",
    "\n",
    "        # Global pooling for CNN path\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # --- LSTM Path ---\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=num_lstm_layers,\n",
    "                            batch_first=True, # Crucial: input shape (batch, seq_len, features)\n",
    "                            bidirectional=False) # Set to True if needed, adjust feature concatenation below\n",
    "\n",
    "        # --- Combined Path ---\n",
    "        # Calculate the combined feature size after CNN pooling and LSTM\n",
    "        combined_features = self.cnn_final_channels + lstm_hidden_size # Add *2 if bidirectional LSTM\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(combined_features, 16) # Input size adjusted\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout_fc1 = nn.Dropout(0.3) # Added dropout for FC layer\n",
    "        self.fc2 = nn.Linear(16, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "\n",
    "        # --- CNN Path ---\n",
    "        # For Conv1D: convert to batch_size x features(channels) x time_steps\n",
    "        x_cnn = x.permute(0, 2, 1)\n",
    "        # Pass through convolutional blocks\n",
    "        cnn_out = self.parallel_conv(x_cnn)\n",
    "        cnn_out = self.block2(cnn_out)\n",
    "        cnn_out = self.block3(cnn_out)\n",
    "        # Global pooling to get fixed-size representation for CNN path\n",
    "        cnn_pooled = self.global_avg_pool(cnn_out)\n",
    "        cnn_features = cnn_pooled.view(cnn_pooled.size(0), -1) # Flatten: batch_size x cnn_final_channels\n",
    "\n",
    "        # --- LSTM Path ---\n",
    "        # Input shape expected by LSTM (batch_first=True): batch_size x time_steps x features\n",
    "        # No permutation needed for LSTM path if input is already in this format\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # We typically use the last hidden state\n",
    "        # h_n shape: (num_layers * num_directions, batch_size, lstm_hidden_size)\n",
    "        # Get the hidden state of the last layer\n",
    "        lstm_features = h_n[-1] # Shape: batch_size x lstm_hidden_size (if not bidirectional)\n",
    "        # If bidirectional: h_n shape is (num_layers*2, batch, hidden_size)\n",
    "        # You might want to concatenate the last forward and backward hidden states:\n",
    "        # lstm_features = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1) # If bidirectional\n",
    "\n",
    "        # --- Concatenate Features ---\n",
    "        combined_features = torch.cat((cnn_features, lstm_features), dim=1)\n",
    "\n",
    "        # --- Fully Connected Layers ---\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu_fc1(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=86, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features\n",
    "output_size = 1  # Binary classification\n",
    "lstm_hidden_size = 128\n",
    "num_lstm_layers = 1\n",
    "\n",
    "# Create model instance\n",
    "model = ConvLSTMModel(input_size=input_size, output_size=output_size, lstm_hidden_size=lstm_hidden_size, num_lstm_layers=num_lstm_layers)\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters loaded successfully from ../../models/deep_learning/experiment_25.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_24720\\4247502569.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Define the model path\n",
    "model_path = f'../../models/deep_learning/experiment_{experiment_num}.pth'\n",
    "\n",
    "# Load the model parameters\n",
    "try:\n",
    "    # Load the saved dictionary\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # Extract model parameters from the 'model_state_dict' key\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model parameters loaded successfully from {model_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "    print(\"Please specify the correct path to the model parameters\")\n",
    "except KeyError:\n",
    "    print(f\"'model_state_dict' key not found in the checkpoint file\")\n",
    "    print(\"The file may have been saved with a different structure\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model parameters: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Kernel Shape              Output Shape              Param #\n",
       "============================================================================================================================================\n",
       "ConvLSTMModel                            [2048, 13, 86]            --                        [2048, 1]                 --\n",
       "â”œâ”€ParallelConvBlock: 1-1                 [2048, 86, 13]            --                        [2048, 100, 13]           62,200\n",
       "â”œâ”€ConvBlock: 1-2                         [2048, 100, 13]           --                        [2048, 64, 6]             19,392\n",
       "â”œâ”€ConvBlock: 1-3                         [2048, 64, 6]             --                        [2048, 32, 6]             6,240\n",
       "â”œâ”€AdaptiveAvgPool1d: 1-4                 [2048, 32, 6]             --                        [2048, 32, 1]             --\n",
       "â”œâ”€LSTM: 1-5                              [2048, 13, 86]            --                        [2048, 13, 128]           110,592\n",
       "â”œâ”€Linear: 1-6                            [2048, 160]               --                        [2048, 16]                2,576\n",
       "â”œâ”€ReLU: 1-7                              [2048, 16]                --                        [2048, 16]                --\n",
       "â”œâ”€Dropout: 1-8                           [2048, 16]                --                        [2048, 16]                --\n",
       "â”œâ”€Linear: 1-9                            [2048, 16]                --                        [2048, 1]                 17\n",
       "â”œâ”€Sigmoid: 1-10                          [2048, 1]                 --                        [2048, 1]                 --\n",
       "============================================================================================================================================\n",
       "Total params: 201,017\n",
       "Trainable params: 201,017\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.19\n",
       "============================================================================================================================================\n",
       "Input size (MB): 9.16\n",
       "Forward/backward pass size (MB): 146.29\n",
       "Params size (MB): 0.80\n",
       "Estimated Total Size (MB): 156.26\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"kernel_size\",\"output_size\", \"num_params\"], depth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataset(test_X, test_y['target'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([0.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([1.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# # Set model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Check if CUDA is available and move model to the appropriate device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# model = model.to(device)\n",
    "\n",
    "# # Lists to store predictions and true values\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "\n",
    "# # Perform inference without gradient calculation\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in test_loader:\n",
    "#         # Move inputs and labels to the appropriate device\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs)\n",
    "        \n",
    "#         # Store predictions and labels\n",
    "#         all_preds.append(outputs.cpu().numpy())\n",
    "#         all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# # Concatenate all batches\n",
    "# all_preds = np.concatenate(all_preds)\n",
    "# all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# # Convert predictions to binary (0 or 1) using threshold of 0.5\n",
    "# pred_classes = (all_preds > 0.5).astype(int)\n",
    "# true_classes = all_labels.astype(int)\n",
    "\n",
    "# # Generate classification report\n",
    "\n",
    "# # Print classification report\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(true_classes, pred_classes, digits = 4))\n",
    "\n",
    "# # Calculate and print accuracy\n",
    "# accuracy = accuracy_score(true_classes, pred_classes)\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# # Calculate and print ROC-AUC score\n",
    "# auc = roc_auc_score(true_classes, all_preds)\n",
    "# print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "\n",
    "# # Print confusion matrix\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(confusion_matrix(true_classes, pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7502944\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8597    0.9800    0.9159    102026\n",
      "           1     0.9046    0.5424    0.6782     35648\n",
      "\n",
      "    accuracy                         0.8667    137674\n",
      "   macro avg     0.8822    0.7612    0.7971    137674\n",
      "weighted avg     0.8713    0.8667    0.8544    137674\n",
      "\n",
      "Accuracy: 0.8667\n",
      "ROC-AUC Score: 0.9530\n",
      "\n",
      "Confusion Matrix:\n",
      "[[99986  2040]\n",
      " [16312 19336]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from utils.threshold import find_threshold_binary_search\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the given data loader and print evaluation metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model to evaluate.\n",
    "        data_loader: DataLoader containing the dataset to evaluate on.\n",
    "        device: Device to run the evaluation on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing evaluation metrics (classification report, accuracy, ROC-AUC score, confusion matrix).\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Lists to store predictions and true values\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Perform inference without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move inputs and labels to the appropriate device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Store predictions and labels\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Convert predictions to binary (0 or 1) using threshold of 0.5\n",
    "    threshold, _ = find_threshold_binary_search(all_labels, all_preds, target_recall=0.98, target_class=0)\n",
    "    pred_classes = (all_preds > threshold).astype(int)\n",
    "    true_classes = all_labels.astype(int)\n",
    "\n",
    "    # Generate classification report\n",
    "    classification_rep = classification_report(true_classes, pred_classes, digits=4)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_classes, pred_classes)\n",
    "\n",
    "    # Calculate ROC-AUC score\n",
    "    auc = roc_auc_score(true_classes, all_preds)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_classes, pred_classes)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_rep)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Return metrics as a dictionary\n",
    "    return {\n",
    "        \"classification_report\": classification_rep,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"roc_auc_score\": auc,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "metrics = evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7528384\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8614    0.9800    0.9169     23806\n",
      "           1     0.9056    0.5488    0.6834      8318\n",
      "\n",
      "    accuracy                         0.8684     32124\n",
      "   macro avg     0.8835    0.7644    0.8002     32124\n",
      "weighted avg     0.8729    0.8684    0.8564     32124\n",
      "\n",
      "Accuracy: 0.8684\n",
      "ROC-AUC Score: 0.9545\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23330   476]\n",
      " [ 3753  4565]]\n"
     ]
    }
   ],
   "source": [
    "val_metrics = evaluate_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7270852\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8705    0.9800    0.9220    214253\n",
      "           1     0.9106    0.5827    0.7106     74862\n",
      "\n",
      "    accuracy                         0.8771    289115\n",
      "   macro avg     0.8905    0.7813    0.8163    289115\n",
      "weighted avg     0.8809    0.8771    0.8673    289115\n",
      "\n",
      "Accuracy: 0.8771\n",
      "ROC-AUC Score: 0.9588\n",
      "\n",
      "Confusion Matrix:\n",
      "[[209968   4285]\n",
      " [ 31240  43622]]\n"
     ]
    }
   ],
   "source": [
    "train_metrics = evaluate_model(model, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.eval_helpers import evaluate_model_for_recall\n",
    "# evaluate_model_for_recall(target_class=0, desired_recall=0.98, y_true=true_classes, y_pred_proba=all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: '' \t Module Type: ConvLSTMModel\n",
      "Name: 'parallel_conv' \t Module Type: ParallelConvBlock\n",
      "Name: 'parallel_conv.paths' \t Module Type: ModuleList\n",
      "Name: 'parallel_conv.paths.0' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.0.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.0.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.0.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.0.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.1' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.1.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.1.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.1.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.1.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.2' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.2.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.2.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.2.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.2.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.3' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.3.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.3.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.3.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.3.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.projection' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.projection.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.projection.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.projection.2' \t Module Type: ReLU\n",
      "Name: 'block2' \t Module Type: ConvBlock\n",
      "Name: 'block2.conv' \t Module Type: Conv1d\n",
      "Name: 'block2.bn' \t Module Type: BatchNorm1d\n",
      "Name: 'block2.relu' \t Module Type: ReLU\n",
      "Name: 'block2.pool' \t Module Type: MaxPool1d\n",
      "Name: 'block2.dropout' \t Module Type: Dropout\n",
      "Name: 'block3' \t Module Type: ConvBlock\n",
      "Name: 'block3.conv' \t Module Type: Conv1d\n",
      "Name: 'block3.bn' \t Module Type: BatchNorm1d\n",
      "Name: 'block3.relu' \t Module Type: ReLU\n",
      "Name: 'block3.dropout' \t Module Type: Dropout\n",
      "Name: 'global_avg_pool' \t Module Type: AdaptiveAvgPool1d\n",
      "Name: 'lstm' \t Module Type: LSTM\n",
      "Name: 'fc1' \t Module Type: Linear\n",
      "Name: 'relu_fc1' \t Module Type: ReLU\n",
      "Name: 'dropout_fc1' \t Module Type: Dropout\n",
      "Name: 'fc2' \t Module Type: Linear\n",
      "Name: 'sigmoid' \t Module Type: Sigmoid\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    # 'name' is the hierarchical string name\n",
    "    # 'module' is the actual layer/module object\n",
    "    print(f\"Name: '{name}' \\t Module Type: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader # For type hinting\n",
    "\n",
    "def extract_features_with_hook_no_labels(model: nn.Module, target_layer_name: str, data_loader: DataLoader, device: torch.device) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs inference and extracts features from a specific layer using hooks.\n",
    "    Assumes no labels are needed or available in the output.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    captured_features = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        captured_features.append(output.detach().cpu().numpy())\n",
    "\n",
    "    hook_handle = None\n",
    "    target_layer = None\n",
    "    try:\n",
    "        # Use model.get_submodule(target_name) for robustness if needed\n",
    "        # For simplicity, assuming direct attribute access works:\n",
    "        module_dict = dict(model.named_modules())\n",
    "        if target_layer_name in module_dict:\n",
    "             target_layer = module_dict[target_layer_name]\n",
    "        else:\n",
    "             raise KeyError(f\"Layer '{target_layer_name}' not found.\")\n",
    "\n",
    "        hook_handle = target_layer.register_forward_hook(hook_fn)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Available named modules:\")\n",
    "        for name, _ in model.named_modules():\n",
    "             print(f\"- {name}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during hook registration: {e}\")\n",
    "        if hook_handle: # Clean up if hook was partially registered\n",
    "             hook_handle.remove()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Extracting features from '{target_layer_name}' using device: {device}\")\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Extracting Features\")\n",
    "        for batch in pbar:\n",
    "            # Handle variable dataloader output (with or without labels)\n",
    "            if isinstance(batch, (list, tuple)):\n",
    "                inputs = batch[0].to(device) # Assume inputs are the first element\n",
    "            else:\n",
    "                inputs = batch.to(device) # Assume loader yields only inputs\n",
    "\n",
    "            # Run forward pass to trigger the hook\n",
    "            _ = model(inputs)\n",
    "\n",
    "    if hook_handle:\n",
    "        hook_handle.remove()\n",
    "\n",
    "    if not captured_features:\n",
    "        print(\"Warning: No features were captured.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_features_np = np.concatenate(captured_features, axis=0)\n",
    "\n",
    "    num_features = all_features_np.shape[1]\n",
    "    feature_columns = [f'DL_{i}' for i in range(num_features)]\n",
    "    features_df = pd.DataFrame(all_features_np, columns=feature_columns)\n",
    "\n",
    "    print(f\"Feature extraction complete. DataFrame shape: {features_df.shape}\")\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 'dropout_fc1' using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5beadaad96be4ef29bc29850af51d055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. DataFrame shape: (137674, 16)\n"
     ]
    }
   ],
   "source": [
    "target_layer_name = 'dropout_fc1' # Make sure this matches!\n",
    "\n",
    "test_extracted_df = extract_features_with_hook_no_labels(\n",
    "    model,\n",
    "    target_layer_name,\n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_0</th>\n",
       "      <th>DL_1</th>\n",
       "      <th>DL_2</th>\n",
       "      <th>DL_3</th>\n",
       "      <th>DL_4</th>\n",
       "      <th>DL_5</th>\n",
       "      <th>DL_6</th>\n",
       "      <th>DL_7</th>\n",
       "      <th>DL_8</th>\n",
       "      <th>DL_9</th>\n",
       "      <th>DL_10</th>\n",
       "      <th>DL_11</th>\n",
       "      <th>DL_12</th>\n",
       "      <th>DL_13</th>\n",
       "      <th>DL_14</th>\n",
       "      <th>DL_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.035169</td>\n",
       "      <td>5.707216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.636570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.809452</td>\n",
       "      <td>5.764231</td>\n",
       "      <td>6.173485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.153308</td>\n",
       "      <td>4.215621</td>\n",
       "      <td>6.063298</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.716325</td>\n",
       "      <td>4.411739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.441925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.319164</td>\n",
       "      <td>4.509210</td>\n",
       "      <td>4.714250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.894351</td>\n",
       "      <td>3.420918</td>\n",
       "      <td>4.600852</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970655</td>\n",
       "      <td>3.554694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.736287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.512755</td>\n",
       "      <td>3.706461</td>\n",
       "      <td>3.885978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.245215</td>\n",
       "      <td>2.843341</td>\n",
       "      <td>3.793341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.287063</td>\n",
       "      <td>4.879447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.274143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.075306</td>\n",
       "      <td>5.021643</td>\n",
       "      <td>5.275514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.387375</td>\n",
       "      <td>3.880430</td>\n",
       "      <td>5.249128</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.338976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.966514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.390673</td>\n",
       "      <td>1.96816</td>\n",
       "      <td>2.084374</td>\n",
       "      <td>1.777916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.780722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DL_0      DL_1      DL_2      DL_3      DL_4      DL_5      DL_6  \\\n",
       "0  6.035169  5.707216  0.000000  5.636570  0.000000  6.809452  5.764231   \n",
       "1  4.716325  4.411739  0.000000  4.441925  0.000000  5.319164  4.509210   \n",
       "2  3.970655  3.554694  0.000000  3.736287  0.000000  4.512755  3.706461   \n",
       "3  5.287063  4.879447  0.000000  5.274143  0.000000  6.075306  5.021643   \n",
       "4  0.000000  0.000000  3.338976  0.000000  1.966514  0.000000  0.000000   \n",
       "\n",
       "       DL_7      DL_8     DL_9     DL_10     DL_11     DL_12     DL_13  \\\n",
       "0  6.173485  0.000000  0.00000  0.000000  0.000000  6.153308  4.215621   \n",
       "1  4.714250  0.000000  0.00000  0.000000  0.000000  4.894351  3.420918   \n",
       "2  3.885978  0.000000  0.00000  0.000000  0.000000  4.245215  2.843341   \n",
       "3  5.275514  0.000000  0.00000  0.000000  0.000000  5.387375  3.880430   \n",
       "4  0.000000  2.390673  1.96816  2.084374  1.777916  0.000000  0.000000   \n",
       "\n",
       "      DL_14     DL_15  \n",
       "0  6.063298  0.000000  \n",
       "1  4.600852  0.000000  \n",
       "2  3.793341  0.000000  \n",
       "3  5.249128  0.000000  \n",
       "4  0.000000  1.780722  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 'dropout_fc1' using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb6fad631ff4adf911944711c890c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. DataFrame shape: (32124, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_0</th>\n",
       "      <th>DL_1</th>\n",
       "      <th>DL_2</th>\n",
       "      <th>DL_3</th>\n",
       "      <th>DL_4</th>\n",
       "      <th>DL_5</th>\n",
       "      <th>DL_6</th>\n",
       "      <th>DL_7</th>\n",
       "      <th>DL_8</th>\n",
       "      <th>DL_9</th>\n",
       "      <th>DL_10</th>\n",
       "      <th>DL_11</th>\n",
       "      <th>DL_12</th>\n",
       "      <th>DL_13</th>\n",
       "      <th>DL_14</th>\n",
       "      <th>DL_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.432674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110735</td>\n",
       "      <td>0.708074</td>\n",
       "      <td>0.931448</td>\n",
       "      <td>0.595479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.783689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.209517</td>\n",
       "      <td>4.857351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.162995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.157306</td>\n",
       "      <td>5.006511</td>\n",
       "      <td>5.400367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.437877</td>\n",
       "      <td>3.900988</td>\n",
       "      <td>5.449194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.426666</td>\n",
       "      <td>4.134310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.974846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.069541</td>\n",
       "      <td>4.251059</td>\n",
       "      <td>4.530725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.512188</td>\n",
       "      <td>3.168711</td>\n",
       "      <td>4.593558</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.357077</td>\n",
       "      <td>3.836432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.303031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.963942</td>\n",
       "      <td>3.954748</td>\n",
       "      <td>4.305258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.441238</td>\n",
       "      <td>3.117230</td>\n",
       "      <td>4.063981</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.237704</td>\n",
       "      <td>1.519138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.060107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.624698</td>\n",
       "      <td>2.026786</td>\n",
       "      <td>2.129326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.546600</td>\n",
       "      <td>1.503630</td>\n",
       "      <td>2.158355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DL_0      DL_1      DL_2      DL_3      DL_4      DL_5      DL_6  \\\n",
       "0  0.000000  0.000000  1.432674  0.000000  0.804038  0.000000  0.000000   \n",
       "1  5.209517  4.857351  0.000000  5.162995  0.000000  6.157306  5.006511   \n",
       "2  4.426666  4.134310  0.000000  3.974846  0.000000  5.069541  4.251059   \n",
       "3  4.357077  3.836432  0.000000  4.303031  0.000000  4.963942  3.954748   \n",
       "4  2.237704  1.519138  0.000000  2.060107  0.000000  2.624698  2.026786   \n",
       "\n",
       "       DL_7      DL_8      DL_9     DL_10     DL_11     DL_12     DL_13  \\\n",
       "0  0.000000  1.110735  0.708074  0.931448  0.595479  0.000000  0.000000   \n",
       "1  5.400367  0.000000  0.000000  0.000000  0.000000  5.437877  3.900988   \n",
       "2  4.530725  0.000000  0.000000  0.000000  0.000000  4.512188  3.168711   \n",
       "3  4.305258  0.000000  0.000000  0.000000  0.000000  4.441238  3.117230   \n",
       "4  2.129326  0.000000  0.000000  0.000000  0.000000  2.546600  1.503630   \n",
       "\n",
       "      DL_14     DL_15  \n",
       "0  0.000000  0.783689  \n",
       "1  5.449194  0.000000  \n",
       "2  4.593558  0.000000  \n",
       "3  4.063981  0.000000  \n",
       "4  2.158355  0.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_extracted_df = extract_features_with_hook_no_labels(\n",
    "    model,\n",
    "    target_layer_name,\n",
    "    val_loader,\n",
    "    device\n",
    ")\n",
    "val_extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 'dropout_fc1' using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c692400a404a7aace3e73b723f9f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. DataFrame shape: (289115, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_0</th>\n",
       "      <th>DL_1</th>\n",
       "      <th>DL_2</th>\n",
       "      <th>DL_3</th>\n",
       "      <th>DL_4</th>\n",
       "      <th>DL_5</th>\n",
       "      <th>DL_6</th>\n",
       "      <th>DL_7</th>\n",
       "      <th>DL_8</th>\n",
       "      <th>DL_9</th>\n",
       "      <th>DL_10</th>\n",
       "      <th>DL_11</th>\n",
       "      <th>DL_12</th>\n",
       "      <th>DL_13</th>\n",
       "      <th>DL_14</th>\n",
       "      <th>DL_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.894572</td>\n",
       "      <td>6.484050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.806992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.981942</td>\n",
       "      <td>6.737336</td>\n",
       "      <td>7.320887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.951766</td>\n",
       "      <td>4.875103</td>\n",
       "      <td>7.235418</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.679119</td>\n",
       "      <td>6.465893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.333076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.625560</td>\n",
       "      <td>6.486637</td>\n",
       "      <td>6.799274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.007101</td>\n",
       "      <td>4.792603</td>\n",
       "      <td>6.760164</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.606601</td>\n",
       "      <td>3.107703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.207478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.238704</td>\n",
       "      <td>3.384953</td>\n",
       "      <td>3.755443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.777967</td>\n",
       "      <td>2.448155</td>\n",
       "      <td>3.791546</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.138242</td>\n",
       "      <td>1.050633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.541710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.647928</td>\n",
       "      <td>1.205866</td>\n",
       "      <td>1.268733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.247360</td>\n",
       "      <td>0.901859</td>\n",
       "      <td>1.331760</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.944834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.209252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.523999</td>\n",
       "      <td>1.312626</td>\n",
       "      <td>1.391679</td>\n",
       "      <td>1.093533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.151772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DL_0      DL_1      DL_2      DL_3      DL_4      DL_5      DL_6  \\\n",
       "0  6.894572  6.484050  0.000000  6.806992  0.000000  7.981942  6.737336   \n",
       "1  6.679119  6.465893  0.000000  6.333076  0.000000  7.625560  6.486637   \n",
       "2  3.606601  3.107703  0.000000  3.207478  0.000000  4.238704  3.384953   \n",
       "3  1.138242  1.050633  0.000000  1.541710  0.000000  1.647928  1.205866   \n",
       "4  0.000000  0.000000  1.944834  0.000000  1.209252  0.000000  0.000000   \n",
       "\n",
       "       DL_7      DL_8      DL_9     DL_10     DL_11     DL_12     DL_13  \\\n",
       "0  7.320887  0.000000  0.000000  0.000000  0.000000  6.951766  4.875103   \n",
       "1  6.799274  0.000000  0.000000  0.000000  0.000000  7.007101  4.792603   \n",
       "2  3.755443  0.000000  0.000000  0.000000  0.000000  3.777967  2.448155   \n",
       "3  1.268733  0.000000  0.000000  0.000000  0.000000  1.247360  0.901859   \n",
       "4  0.000000  1.523999  1.312626  1.391679  1.093533  0.000000  0.000000   \n",
       "\n",
       "      DL_14     DL_15  \n",
       "0  7.235418  0.000000  \n",
       "1  6.760164  0.000000  \n",
       "2  3.791546  0.000000  \n",
       "3  1.331760  0.000000  \n",
       "4  0.000000  1.151772  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extracted_df = extract_features_with_hook_no_labels(\n",
    "    model,\n",
    "    target_layer_name,\n",
    "    train_loader,\n",
    "    device\n",
    ")\n",
    "train_extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13, 86)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[:20, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 13, 86)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inference example: randomly sample 50 datapoints from test_X\n",
    "sample_indices = np.random.choice(test_X.shape[0], 50, replace=False)\n",
    "sampled_data = test_X[sample_indices, :, :]\n",
    "sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([[0.]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_dataset = TimeSeriesDataset(sampled_data, np.zeros((50, 1)))\n",
    "sample_loader = DataLoader(sample_dataset, batch_size=batch_size, shuffle=False)\n",
    "sample_loader.dataset.__getitem__(0)[0].shape, sample_loader.dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 'dropout_fc1' using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9713ae23c440d7b71b4bd6d4789b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete. DataFrame shape: (50, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_0</th>\n",
       "      <th>DL_1</th>\n",
       "      <th>DL_2</th>\n",
       "      <th>DL_3</th>\n",
       "      <th>DL_4</th>\n",
       "      <th>DL_5</th>\n",
       "      <th>DL_6</th>\n",
       "      <th>DL_7</th>\n",
       "      <th>DL_8</th>\n",
       "      <th>DL_9</th>\n",
       "      <th>DL_10</th>\n",
       "      <th>DL_11</th>\n",
       "      <th>DL_12</th>\n",
       "      <th>DL_13</th>\n",
       "      <th>DL_14</th>\n",
       "      <th>DL_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.626980</td>\n",
       "      <td>6.059169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.516596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.494190</td>\n",
       "      <td>6.364658</td>\n",
       "      <td>6.831047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.539848</td>\n",
       "      <td>4.856055</td>\n",
       "      <td>6.567194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.374995</td>\n",
       "      <td>1.885042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.324354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.690286</td>\n",
       "      <td>2.123864</td>\n",
       "      <td>2.248994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.462363</td>\n",
       "      <td>1.614155</td>\n",
       "      <td>2.299339</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.915730</td>\n",
       "      <td>2.613201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.844631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.583123</td>\n",
       "      <td>3.657589</td>\n",
       "      <td>3.899049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.058995</td>\n",
       "      <td>2.977775</td>\n",
       "      <td>3.588254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.387104</td>\n",
       "      <td>5.036843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.802422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.086957</td>\n",
       "      <td>5.229789</td>\n",
       "      <td>5.430710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.625329</td>\n",
       "      <td>3.801256</td>\n",
       "      <td>5.339056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.952773</td>\n",
       "      <td>2.355582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.586623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.081563</td>\n",
       "      <td>2.457197</td>\n",
       "      <td>2.789500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.800545</td>\n",
       "      <td>1.957896</td>\n",
       "      <td>2.434073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DL_0      DL_1  DL_2      DL_3  DL_4      DL_5      DL_6      DL_7  \\\n",
       "0  6.626980  6.059169   0.0  6.516596   0.0  7.494190  6.364658  6.831047   \n",
       "1  2.374995  1.885042   0.0  2.324354   0.0  2.690286  2.123864  2.248994   \n",
       "2  3.915730  2.613201   0.0  3.844631   0.0  4.583123  3.657589  3.899049   \n",
       "3  5.387104  5.036843   0.0  4.802422   0.0  6.086957  5.229789  5.430710   \n",
       "4  2.952773  2.355582   0.0  2.586623   0.0  3.081563  2.457197  2.789500   \n",
       "\n",
       "   DL_8  DL_9  DL_10  DL_11     DL_12     DL_13     DL_14  DL_15  \n",
       "0   0.0   0.0    0.0    0.0  6.539848  4.856055  6.567194    0.0  \n",
       "1   0.0   0.0    0.0    0.0  2.462363  1.614155  2.299339    0.0  \n",
       "2   0.0   0.0    0.0    0.0  4.058995  2.977775  3.588254    0.0  \n",
       "3   0.0   0.0    0.0    0.0  5.625329  3.801256  5.339056    0.0  \n",
       "4   0.0   0.0    0.0    0.0  2.800545  1.957896  2.434073    0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_extracted_df = extract_features_with_hook_no_labels(\n",
    "    model,\n",
    "    target_layer_name,\n",
    "    sample_loader,\n",
    "    device\n",
    ")\n",
    "sample_extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_extracted_df.to_parquet(f'../../data/dl_features/exp_{experiment_num}_train_extracted.parquet', index=False)\n",
    "val_extracted_df.to_parquet(f'../../data/dl_features/exp_{experiment_num}_val_extracted.parquet', index=False)\n",
    "test_extracted_df.to_parquet(f'../../data/dl_features/exp_{experiment_num}_test_extracted.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
