{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#trying to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/mod_train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_test_data_3d_h5.h5', 'r') as f:\n",
    "    test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')\n",
    "test_y = pd.read_parquet('../../data/3d_array/test_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X, nan=0.0)\n",
    "val_X = np.nan_to_num(val_X, nan=0.0)\n",
    "test_X = np.nan_to_num(test_X, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2018-03-31    289115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_19828\\847019464.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_19828\\847019464.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_19828\\847019464.py:3: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n",
    "test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289110</th>\n",
       "      <td>fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289111</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289112</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289113</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289114</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID end_of_month  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31       0\n",
       "1       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31       0\n",
       "2       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2018-03-31       0\n",
       "3       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2018-03-31       0\n",
       "4       0000f99513770170a1aba690daeeb8a96da4a39f11fc27...   2018-03-31       1\n",
       "...                                                   ...          ...     ...\n",
       "289110  fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...   2018-03-31       1\n",
       "289111  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...   2018-03-31       0\n",
       "289112  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2018-03-31       0\n",
       "289113  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31       0\n",
       "289114  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31       0\n",
       "\n",
       "[289115 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 13, 86), (289115, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32124, 13, 86), (32124, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], dropout_rate=0.2):\n",
    "        \"\"\"\n",
    "        Parallel Convolutional Block that processes input through multiple convolutional paths\n",
    "        with different kernel sizes and concatenates the results.\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Number of input channels\n",
    "            out_channels: Number of output channels\n",
    "            kernel_sizes: List of kernel sizes for parallel convolutions\n",
    "            dropout_rate: Dropout probability\n",
    "        \"\"\"\n",
    "        super(ParallelConvBlock, self).__init__()\n",
    "        \n",
    "        self.n_paths = len(kernel_sizes)\n",
    "        # Calculate channels per path\n",
    "        path_channels = out_channels // self.n_paths\n",
    "        \n",
    "        # Create parallel convolutional paths\n",
    "        self.paths = nn.ModuleList()\n",
    "        for k_size in kernel_sizes:\n",
    "            padding = k_size // 2  # Same padding to maintain sequence length\n",
    "            path = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, path_channels, kernel_size=k_size, padding=padding),\n",
    "                nn.BatchNorm1d(path_channels),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "            self.paths.append(path)\n",
    "            \n",
    "        # Projection layer to ensure output has exactly out_channels\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv1d(path_channels * self.n_paths, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Process input through parallel paths\n",
    "        outputs = [path(x) for path in self.paths]\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        # print(f\"Outputs shape before concatenation: {[out.shape for out in outputs]}\")\n",
    "        x = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        # Apply projection to get final output\n",
    "        x = self.projection(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, pool=True, dropout=0.3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) if pool else None\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        if self.pool:\n",
    "            x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, lstm_hidden_size=64, num_lstm_layers=1, output_size=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of features in the input sequence (feature dimension).\n",
    "            lstm_hidden_size (int): Hidden size for the LSTM layer.\n",
    "            num_lstm_layers (int): Number of layers for the LSTM.\n",
    "            output_size (int): Size of the final output (e.g., 1 for binary classification).\n",
    "        \"\"\"\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "\n",
    "        # --- CNN Path ---\n",
    "        # First convolutional block (Parallel)\n",
    "        # Input channels = input_size (features)\n",
    "        cnn_out_channels_1 = 100\n",
    "        self.parallel_conv = ParallelConvBlock(input_size, cnn_out_channels_1, kernel_sizes=[3, 5, 7, 9], dropout_rate=0.2)\n",
    "\n",
    "        # Second convolutional block\n",
    "        cnn_out_channels_2 = 64\n",
    "        self.block2 = ConvBlock(cnn_out_channels_1, cnn_out_channels_2, dropout=0.2)\n",
    "\n",
    "        # Third convolutional block\n",
    "        self.cnn_final_channels = 32\n",
    "        self.block3 = ConvBlock(cnn_out_channels_2, self.cnn_final_channels, pool=False, dropout=0.2) # No pooling in the last block\n",
    "\n",
    "        # Global pooling for CNN path\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # --- LSTM Path ---\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=lstm_hidden_size,\n",
    "                            num_layers=num_lstm_layers,\n",
    "                            batch_first=True, # Crucial: input shape (batch, seq_len, features)\n",
    "                            bidirectional=False) # Set to True if needed, adjust feature concatenation below\n",
    "\n",
    "        # --- Combined Path ---\n",
    "        # Calculate the combined feature size after CNN pooling and LSTM\n",
    "        combined_features = self.cnn_final_channels + lstm_hidden_size # Add *2 if bidirectional LSTM\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(combined_features, 16) # Input size adjusted\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        self.dropout_fc1 = nn.Dropout(0.3) # Added dropout for FC layer\n",
    "        self.fc2 = nn.Linear(16, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "\n",
    "        # --- CNN Path ---\n",
    "        # For Conv1D: convert to batch_size x features(channels) x time_steps\n",
    "        x_cnn = x.permute(0, 2, 1)\n",
    "        # Pass through convolutional blocks\n",
    "        cnn_out = self.parallel_conv(x_cnn)\n",
    "        cnn_out = self.block2(cnn_out)\n",
    "        cnn_out = self.block3(cnn_out)\n",
    "        # Global pooling to get fixed-size representation for CNN path\n",
    "        cnn_pooled = self.global_avg_pool(cnn_out)\n",
    "        cnn_features = cnn_pooled.view(cnn_pooled.size(0), -1) # Flatten: batch_size x cnn_final_channels\n",
    "\n",
    "        # --- LSTM Path ---\n",
    "        # Input shape expected by LSTM (batch_first=True): batch_size x time_steps x features\n",
    "        # No permutation needed for LSTM path if input is already in this format\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # We typically use the last hidden state\n",
    "        # h_n shape: (num_layers * num_directions, batch_size, lstm_hidden_size)\n",
    "        # Get the hidden state of the last layer\n",
    "        lstm_features = h_n[-1] # Shape: batch_size x lstm_hidden_size (if not bidirectional)\n",
    "        # If bidirectional: h_n shape is (num_layers*2, batch, hidden_size)\n",
    "        # You might want to concatenate the last forward and backward hidden states:\n",
    "        # lstm_features = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1) # If bidirectional\n",
    "\n",
    "        # --- Concatenate Features ---\n",
    "        combined_features = torch.cat((cnn_features, lstm_features), dim=1)\n",
    "\n",
    "        # --- Fully Connected Layers ---\n",
    "        x = self.fc1(combined_features)\n",
    "        x = self.relu_fc1(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=86, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features\n",
    "output_size = 1  # Binary classification\n",
    "lstm_hidden_size = 128\n",
    "num_lstm_layers = 1\n",
    "\n",
    "# Create model instance\n",
    "model = ConvLSTMModel(input_size=input_size, output_size=output_size, lstm_hidden_size=lstm_hidden_size, num_lstm_layers=num_lstm_layers)\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters loaded successfully from ../../models/deep_learning/experiment_25.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_19828\\4247502569.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Define the model path\n",
    "model_path = f'../../models/deep_learning/experiment_{experiment_num}.pth'\n",
    "\n",
    "# Load the model parameters\n",
    "try:\n",
    "    # Load the saved dictionary\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # Extract model parameters from the 'model_state_dict' key\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model parameters loaded successfully from {model_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "    print(\"Please specify the correct path to the model parameters\")\n",
    "except KeyError:\n",
    "    print(f\"'model_state_dict' key not found in the checkpoint file\")\n",
    "    print(\"The file may have been saved with a different structure\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model parameters: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Kernel Shape              Output Shape              Param #\n",
       "============================================================================================================================================\n",
       "ConvLSTMModel                            [2048, 13, 86]            --                        [2048, 1]                 --\n",
       "â”œâ”€ParallelConvBlock: 1-1                 [2048, 86, 13]            --                        [2048, 100, 13]           62,200\n",
       "â”œâ”€ConvBlock: 1-2                         [2048, 100, 13]           --                        [2048, 64, 6]             19,392\n",
       "â”œâ”€ConvBlock: 1-3                         [2048, 64, 6]             --                        [2048, 32, 6]             6,240\n",
       "â”œâ”€AdaptiveAvgPool1d: 1-4                 [2048, 32, 6]             --                        [2048, 32, 1]             --\n",
       "â”œâ”€LSTM: 1-5                              [2048, 13, 86]            --                        [2048, 13, 128]           110,592\n",
       "â”œâ”€Linear: 1-6                            [2048, 160]               --                        [2048, 16]                2,576\n",
       "â”œâ”€ReLU: 1-7                              [2048, 16]                --                        [2048, 16]                --\n",
       "â”œâ”€Dropout: 1-8                           [2048, 16]                --                        [2048, 16]                --\n",
       "â”œâ”€Linear: 1-9                            [2048, 16]                --                        [2048, 1]                 17\n",
       "â”œâ”€Sigmoid: 1-10                          [2048, 1]                 --                        [2048, 1]                 --\n",
       "============================================================================================================================================\n",
       "Total params: 201,017\n",
       "Trainable params: 201,017\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 5.19\n",
       "============================================================================================================================================\n",
       "Input size (MB): 9.16\n",
       "Forward/backward pass size (MB): 146.29\n",
       "Params size (MB): 0.80\n",
       "Estimated Total Size (MB): 156.26\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"kernel_size\",\"output_size\", \"num_params\"], depth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TimeSeriesDataset(test_X, test_y['target'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([0.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([1.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9202    0.9353    0.9276    102026\n",
      "           1     0.8056    0.7678    0.7862     35648\n",
      "\n",
      "    accuracy                         0.8919    137674\n",
      "   macro avg     0.8629    0.8515    0.8569    137674\n",
      "weighted avg     0.8905    0.8919    0.8910    137674\n",
      "\n",
      "Accuracy: 0.8919\n",
      "ROC-AUC Score: 0.9530\n",
      "\n",
      "Confusion Matrix:\n",
      "[[95420  6606]\n",
      " [ 8279 27369]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Check if CUDA is available and move model to the appropriate device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Lists to store predictions and true values\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform inference without gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move inputs and labels to the appropriate device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Store predictions and labels\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Convert predictions to binary (0 or 1) using threshold of 0.5\n",
    "pred_classes = (all_preds > 0.5).astype(int)\n",
    "true_classes = all_labels.astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, pred_classes, digits = 4))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(true_classes, pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print ROC-AUC score\n",
    "auc = roc_auc_score(true_classes, all_preds)\n",
    "print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_classes, pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7502944\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.8597    0.9800    0.9159    102026\n",
      "     Class 1     0.9046    0.5424    0.6782     35648\n",
      "\n",
      "    accuracy                         0.8667    137674\n",
      "   macro avg     0.8822    0.7612    0.7971    137674\n",
      "weighted avg     0.8713    0.8667    0.8544    137674\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7502944469451904"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.eval_helpers import evaluate_model_for_recall\n",
    "evaluate_model_for_recall(target_class=0, desired_recall=0.98, y_true=true_classes, y_pred_proba=all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: '' \t Module Type: ConvLSTMModel\n",
      "Name: 'parallel_conv' \t Module Type: ParallelConvBlock\n",
      "Name: 'parallel_conv.paths' \t Module Type: ModuleList\n",
      "Name: 'parallel_conv.paths.0' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.0.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.0.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.0.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.0.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.1' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.1.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.1.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.1.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.1.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.2' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.2.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.2.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.2.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.2.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.paths.3' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.paths.3.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.paths.3.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.paths.3.2' \t Module Type: ReLU\n",
      "Name: 'parallel_conv.paths.3.3' \t Module Type: Dropout\n",
      "Name: 'parallel_conv.projection' \t Module Type: Sequential\n",
      "Name: 'parallel_conv.projection.0' \t Module Type: Conv1d\n",
      "Name: 'parallel_conv.projection.1' \t Module Type: BatchNorm1d\n",
      "Name: 'parallel_conv.projection.2' \t Module Type: ReLU\n",
      "Name: 'block2' \t Module Type: ConvBlock\n",
      "Name: 'block2.conv' \t Module Type: Conv1d\n",
      "Name: 'block2.bn' \t Module Type: BatchNorm1d\n",
      "Name: 'block2.relu' \t Module Type: ReLU\n",
      "Name: 'block2.pool' \t Module Type: MaxPool1d\n",
      "Name: 'block2.dropout' \t Module Type: Dropout\n",
      "Name: 'block3' \t Module Type: ConvBlock\n",
      "Name: 'block3.conv' \t Module Type: Conv1d\n",
      "Name: 'block3.bn' \t Module Type: BatchNorm1d\n",
      "Name: 'block3.relu' \t Module Type: ReLU\n",
      "Name: 'block3.dropout' \t Module Type: Dropout\n",
      "Name: 'global_avg_pool' \t Module Type: AdaptiveAvgPool1d\n",
      "Name: 'lstm' \t Module Type: LSTM\n",
      "Name: 'fc1' \t Module Type: Linear\n",
      "Name: 'relu_fc1' \t Module Type: ReLU\n",
      "Name: 'dropout_fc1' \t Module Type: Dropout\n",
      "Name: 'fc2' \t Module Type: Linear\n",
      "Name: 'sigmoid' \t Module Type: Sigmoid\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    # 'name' is the hierarchical string name\n",
    "    # 'module' is the actual layer/module object\n",
    "    print(f\"Name: '{name}' \\t Module Type: {module.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch # Make sure torch is imported\n",
    "\n",
    "def extract_features_with_hook(model: nn.Module, target_layer_name: str, data_loader: torch.utils.data.DataLoader, device: torch.device) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs inference using the model and extracts features from a specific layer\n",
    "    using forward hooks, without modifying the model's forward method.\n",
    "\n",
    "    Args:\n",
    "        model: The trained PyTorch model (original version).\n",
    "        target_layer_name: The string name of the layer to extract features from\n",
    "                           (e.g., 'dropout_fc1'). Must be an attribute of the model.\n",
    "        data_loader: DataLoader for the dataset (e.g., validation or test).\n",
    "        device: The device to run inference on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the extracted features and corresponding labels.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    captured_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # --- Hook Function ---\n",
    "    # This function will run every time the target layer computes its output\n",
    "    def hook_fn(module, input, output):\n",
    "        # The hook captures the output tensor of the layer\n",
    "        # Detach from graph, move to CPU, convert to numpy, and append\n",
    "        captured_features.append(output.detach().cpu().numpy())\n",
    "    # --------------------\n",
    "\n",
    "    # --- Find and Register Hook ---\n",
    "    hook_handle = None\n",
    "    target_layer = None\n",
    "    try:\n",
    "        # Access the target layer using its attribute name\n",
    "        target_layer = dict(model.named_modules())[target_layer_name]\n",
    "        # Register the forward hook\n",
    "        hook_handle = target_layer.register_forward_hook(hook_fn)\n",
    "        print(f\"Registered forward hook on layer: {target_layer_name}\")\n",
    "    except KeyError:\n",
    "        print(f\"Error: Layer '{target_layer_name}' not found in the model.\")\n",
    "        # Print available layer names for debugging\n",
    "        print(\"Available named modules:\")\n",
    "        for name, _ in model.named_modules():\n",
    "             print(f\"- {name}\")\n",
    "        return pd.DataFrame() # Return empty DataFrame\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during hook registration: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    # ---------------------------\n",
    "\n",
    "    print(f\"Extracting features using device: {device}\")\n",
    "    with torch.no_grad(): # Disable gradient calculations\n",
    "        pbar = tqdm(data_loader, desc=\"Extracting Features\")\n",
    "        for inputs, labels in pbar:\n",
    "            inputs = inputs.to(device)\n",
    "            original_labels = labels.numpy() # Keep labels on CPU\n",
    "\n",
    "            # Run the forward pass. We don't need the model's return value,\n",
    "            # but running it triggers the forward hook on the target layer.\n",
    "            _ = model(inputs)\n",
    "\n",
    "            all_labels.append(original_labels)\n",
    "\n",
    "    # --- Remove the Hook ---\n",
    "    # IMPORTANT: Always remove hooks when done to avoid memory leaks\n",
    "    if hook_handle:\n",
    "        hook_handle.remove()\n",
    "        print(f\"Removed forward hook from layer: {target_layer_name}\")\n",
    "    # -----------------------\n",
    "\n",
    "    # --- Process Captured Features ---\n",
    "    if not captured_features:\n",
    "        print(\"Warning: No features were captured. Check data_loader and model.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    all_features_np = np.concatenate(captured_features, axis=0)\n",
    "    all_labels_np = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Ensure labels are flattened\n",
    "    if all_labels_np.ndim > 1 and all_labels_np.shape[1] == 1:\n",
    "        all_labels_np = all_labels_np.flatten()\n",
    "\n",
    "    # Create pandas DataFrame\n",
    "    num_features = all_features_np.shape[1]\n",
    "    feature_columns = [f'DL_{i}' for i in range(num_features)]\n",
    "    features_df = pd.DataFrame(all_features_np, columns=feature_columns)\n",
    "    features_df['label'] = all_labels_np\n",
    "\n",
    "    print(f\"Feature extraction complete. DataFrame shape: {features_df.shape}\")\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered forward hook on layer: dropout_fc1\n",
      "Extracting features using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0256c9a17374c9d87c8346a2924cada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed forward hook from layer: dropout_fc1\n",
      "Feature extraction complete. DataFrame shape: (137674, 17)\n"
     ]
    }
   ],
   "source": [
    "target_layer_name = 'dropout_fc1' # Make sure this matches!\n",
    "\n",
    "extracted_df = extract_features_with_hook(\n",
    "    model,\n",
    "    target_layer_name,\n",
    "    test_loader,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DL_0</th>\n",
       "      <th>DL_1</th>\n",
       "      <th>DL_2</th>\n",
       "      <th>DL_3</th>\n",
       "      <th>DL_4</th>\n",
       "      <th>DL_5</th>\n",
       "      <th>DL_6</th>\n",
       "      <th>DL_7</th>\n",
       "      <th>DL_8</th>\n",
       "      <th>DL_9</th>\n",
       "      <th>DL_10</th>\n",
       "      <th>DL_11</th>\n",
       "      <th>DL_12</th>\n",
       "      <th>DL_13</th>\n",
       "      <th>DL_14</th>\n",
       "      <th>DL_15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.035169</td>\n",
       "      <td>5.707216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.636570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.809452</td>\n",
       "      <td>5.764231</td>\n",
       "      <td>6.173485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.153308</td>\n",
       "      <td>4.215621</td>\n",
       "      <td>6.063298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.716325</td>\n",
       "      <td>4.411739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.441925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.319164</td>\n",
       "      <td>4.509210</td>\n",
       "      <td>4.714250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.894351</td>\n",
       "      <td>3.420918</td>\n",
       "      <td>4.600852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.970655</td>\n",
       "      <td>3.554694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.736287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.512755</td>\n",
       "      <td>3.706461</td>\n",
       "      <td>3.885978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.245215</td>\n",
       "      <td>2.843341</td>\n",
       "      <td>3.793341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.287063</td>\n",
       "      <td>4.879447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.274143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.075306</td>\n",
       "      <td>5.021643</td>\n",
       "      <td>5.275514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.387375</td>\n",
       "      <td>3.880430</td>\n",
       "      <td>5.249128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.338976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.966514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.390673</td>\n",
       "      <td>1.96816</td>\n",
       "      <td>2.084374</td>\n",
       "      <td>1.777916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.780722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DL_0      DL_1      DL_2      DL_3      DL_4      DL_5      DL_6  \\\n",
       "0  6.035169  5.707216  0.000000  5.636570  0.000000  6.809452  5.764231   \n",
       "1  4.716325  4.411739  0.000000  4.441925  0.000000  5.319164  4.509210   \n",
       "2  3.970655  3.554694  0.000000  3.736287  0.000000  4.512755  3.706461   \n",
       "3  5.287063  4.879447  0.000000  5.274143  0.000000  6.075306  5.021643   \n",
       "4  0.000000  0.000000  3.338976  0.000000  1.966514  0.000000  0.000000   \n",
       "\n",
       "       DL_7      DL_8     DL_9     DL_10     DL_11     DL_12     DL_13  \\\n",
       "0  6.173485  0.000000  0.00000  0.000000  0.000000  6.153308  4.215621   \n",
       "1  4.714250  0.000000  0.00000  0.000000  0.000000  4.894351  3.420918   \n",
       "2  3.885978  0.000000  0.00000  0.000000  0.000000  4.245215  2.843341   \n",
       "3  5.275514  0.000000  0.00000  0.000000  0.000000  5.387375  3.880430   \n",
       "4  0.000000  2.390673  1.96816  2.084374  1.777916  0.000000  0.000000   \n",
       "\n",
       "      DL_14     DL_15  label  \n",
       "0  6.063298  0.000000    0.0  \n",
       "1  4.600852  0.000000    0.0  \n",
       "2  3.793341  0.000000    0.0  \n",
       "3  5.249128  0.000000    0.0  \n",
       "4  0.000000  1.780722    1.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
