{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import random\n",
    "\n",
    "#trying to ensure reproducibility\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path to load util functions\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parents[1]\n",
    "sys.path.append(os.path.abspath(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/mod_train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/mod_val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "# with h5py.File('../../data/3d_array/test_data_3d_h5.h5', 'r') as f:\n",
    "#     test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.nan_to_num(train_X, nan = 0.0)\n",
    "val_X = np.nan_to_num(val_X, nan = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2018-03-31    289115\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_27520\\639591509.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_27520\\639591509.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2018-03-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2018-03-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289110</th>\n",
       "      <td>fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289111</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289112</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289113</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289114</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289115 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID end_of_month  target\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31       0\n",
       "1       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31       0\n",
       "2       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2018-03-31       0\n",
       "3       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2018-03-31       0\n",
       "4       0000f99513770170a1aba690daeeb8a96da4a39f11fc27...   2018-03-31       1\n",
       "...                                                   ...          ...     ...\n",
       "289110  fffe3ec7cdbc1caac845c884b389ed347bfc1da9d09731...   2018-03-31       1\n",
       "289111  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...   2018-03-31       0\n",
       "289112  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2018-03-31       0\n",
       "289113  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31       0\n",
       "289114  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31       0\n",
       "\n",
       "[289115 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((289115, 13, 86), (289115, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32124, 13, 86), (32124, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3):\n",
    "        super(MDC, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_scales = len(kernel_sizes)\n",
    "        self.num_kernels_per_scale = num_kernels_per_scale\n",
    "        self.total_kernels = self.num_scales * self.num_kernels_per_scale\n",
    "\n",
    "        # Attention mechanism to generate weights for kernels [cite: 142, 143, 145]\n",
    "        self.attention_pool = nn.AdaptiveAvgPool1d(1) # Pool across time dimension\n",
    "        # Conv1d to generate temporal attention map\n",
    "        self.attention_conv = nn.Conv1d(in_channels, self.total_kernels, kernel_size=1, bias=False)\n",
    "        self.attention_gap = nn.AdaptiveAvgPool1d(1) # Pool attention map to get weights\n",
    "        self.attention_activation = nn.Sigmoid()\n",
    "\n",
    "        # Store the kernels for each scale and each instance per scale\n",
    "        self.weights = nn.Parameter(torch.Tensor(self.total_kernels, out_channels, in_channels, 1)) # Use kernel_size=1 here, will expand later\n",
    "        nn.init.kaiming_uniform_(self.weights, a=np.sqrt(5)) # Initialize weights\n",
    "\n",
    "        # Store kernel sizes correctly\n",
    "        self.k_sizes = []\n",
    "        for k in kernel_sizes:\n",
    "            for _ in range(num_kernels_per_scale):\n",
    "                self.k_sizes.append(k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, T = x.size()\n",
    "\n",
    "        # Calculate attention weights [cite: 142, 145]\n",
    "        pooled_x = self.attention_pool(x) # B x C_in x 1\n",
    "        # The paper's diagram (Fig 3) suggests GAP -> Conv -> GAP -> Sigmoid for attention\n",
    "        # Let's follow the diagram logic more closely:\n",
    "        # GAP on input: B x C_in x T -> B x C_in x 1\n",
    "        att_gap1 = self.attention_pool(x)\n",
    "        # Conv1d on pooled input: B x C_in x 1 -> B x total_kernels x 1 (This seems different from Fig 3's BxmxnxT output)\n",
    "        # Let's reinterpret Fig 3: GAP(x) [B,Cin,T]->[B,Cin,1], then Conv [B,Cin,1]->[B,mxn,1] (This doesn't match BxmxnxT)\n",
    "        # Let's try the alternative interpretation from the text (Section 3.2.1, Eq 2 implies GAP -> Conv -> GAP)\n",
    "        # GAP(x) -> B x Cin x 1\n",
    "        # wa * GAP(x) -> B x mxn x 1 (This still feels off from Fig 3 which applies conv before second GAP)\n",
    "\n",
    "        # Let's follow Fig 3 literally (ignoring the first GAP shown before Conv in the Attention block):\n",
    "        # Conv on input x: B x Cin x T -> B x mxn x T [cite: 143]\n",
    "        attention_map = self.attention_conv(x) # B x total_kernels x T\n",
    "        # GAP on attention_map: B x mxn x T -> B x mxn x 1 [cite: 145]\n",
    "        attention_vector = self.attention_gap(attention_map)\n",
    "        # Sigmoid activation: B x mxn x 1 [cite: 145]\n",
    "        attention_weights = self.attention_activation(attention_vector) # Shape: (batch_size, total_kernels, 1)\n",
    "\n",
    "        # Fuse kernels based on attention weights [cite: 140]\n",
    "        # Reshape weights for broadcasting: (batch_size, total_kernels, 1) -> (batch_size, total_kernels, 1, 1, 1)\n",
    "        # Reshape kernels: (total_kernels, out_c, in_c, 1)\n",
    "        # We need to perform convolution dynamically. PyTorch doesn't easily support dynamic kernel *shapes*.\n",
    "        # A common approach is to have fixed-size kernels and combine their *outputs*, or combine *weights* for a fixed kernel size.\n",
    "        # The paper seems to imply combining weights *before* convolution (Eq 1). This requires all kernels w_i^j to have the same size k.\n",
    "        # However, the goal is *multi-scale*.\n",
    "\n",
    "        # Let's implement the multi-scale aspect by having separate convolutions and combining outputs weighted by attention.\n",
    "        # This deviates slightly from Eq 1 but achieves the multi-scale goal.\n",
    "\n",
    "        outputs = []\n",
    "        current_kernel_idx = 0\n",
    "        for k_size in self.kernel_sizes:\n",
    "            padding = k_size // 2\n",
    "            for i in range(self.num_kernels_per_scale):\n",
    "                # Get the weights for this specific kernel instance (across all batches)\n",
    "                # attention_weights shape: B x total_kernels x 1\n",
    "                # kernel_weights shape: B x 1 x out_c x in_c x k_size\n",
    "                kernel_idx = current_kernel_idx + i\n",
    "                kernel_weight = self.weights[kernel_idx] # out_c x in_c x 1\n",
    "                # Manually create the kernel for Conv1d for this size\n",
    "                dynamic_kernel = kernel_weight.repeat(1, 1, k_size) # out_c x in_c x k_size\n",
    "                \n",
    "                # Perform convolution with this specific kernel\n",
    "                output_i = F.conv1d(x, dynamic_kernel, padding=padding) # B x out_c x T\n",
    "                \n",
    "                # Apply attention weight for this kernel\n",
    "                # attention_weights[:, kernel_idx, :] shape: B x 1 x 1\n",
    "                weighted_output = output_i * attention_weights[:, kernel_idx, :].unsqueeze(-1) # B x out_c x T\n",
    "                outputs.append(weighted_output)\n",
    "                \n",
    "            current_kernel_idx += self.num_kernels_per_scale\n",
    "\n",
    "        # Sum the weighted outputs from all kernels\n",
    "        # This is an alternative interpretation to fusing weights first.\n",
    "        out = torch.sum(torch.stack(outputs), dim=0) # B x out_c x T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3, stride=1):\n",
    "        super(MDCResBlock, self).__init__()\n",
    "        \n",
    "        # Use Conv1d for the residual connection if dimensions change\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.mdc1 = MDC(in_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Paper uses PReLU, let's use ReLU for simplicity or add PReLU if needed. Using PReLU as per paper.\n",
    "        self.prelu1 = nn.PReLU(out_channels)\n",
    "\n",
    "        self.mdc2 = MDC(out_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu2 = nn.PReLU(out_channels) # Activation after final BN before adding shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out = self.mdc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "\n",
    "        out = self.mdc2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.prelu2(out) # Final activation after adding shortcut\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, block_channels=[128, 128, 128], kernel_sizes=[3,5,7], num_kernels_per_scale=2, dropout_rate=0.3, reduction=16):\n",
    "        super(MDCNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        current_channels = input_channels\n",
    "        \n",
    "        # Configuration from paper/Figure 2: 3 Blocks [cite: 130]\n",
    "        # Each block: MDC ResBlock -> MaxPool -> SE -> Dropout\n",
    "        for i, channels in enumerate(block_channels):\n",
    "            # Stride only applied if pooling happens, MaxPooling handles stride=2\n",
    "            res_block = MDCResBlock(current_channels, channels, kernel_sizes, num_kernels_per_scale, stride=1)\n",
    "            max_pool = nn.MaxPool1d(kernel_size=2, stride=2) # Halve the length [cite: 132]\n",
    "            se_block = SEBlock(channels, reduction) # SE block [cite: 133]\n",
    "            dropout = nn.Dropout(dropout_rate) # Dropout [cite: 134]\n",
    "            \n",
    "            block = nn.Sequential(\n",
    "                res_block,\n",
    "                max_pool,\n",
    "                se_block,\n",
    "                dropout\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            current_channels = channels # Update channels for next block\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1) # Global Average Pooling [cite: 130]\n",
    "        # The original ConvModel in experiment_10 has FC layers after pooling.\n",
    "        # MDCNet in the paper feeds features to DPNet or directly to Softmax.\n",
    "        # To make it a component usable in the existing structure, we output features before FC layers.\n",
    "        self.output_channels = current_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: B x T x C_in (e.g., B x 10 x 115)\n",
    "        # Conv1D expects B x C_in x T\n",
    "        x = x.permute(0, 2, 1) # B x C_in x T (e.g., B x 115 x 10)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x) # B x C_out x 1\n",
    "        x = x.view(x.size(0), -1) # Flatten: B x C_out\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedConvModel(nn.Module):\n",
    "    def __init__(self, input_size, time_steps, num_classes=1, mdc_block_channels=[64, 64, 64], mdc_kernel_sizes=[3,5,7], mdc_kernels_per_scale=2, dropout_rate=0.2, fc_size=32):\n",
    "        super(ModifiedConvModel, self).__init__()\n",
    "        \n",
    "        # Instantiate MDCNet feature extractor\n",
    "        self.mdc_net = MDCNet(input_channels=input_size,\n",
    "                              num_classes=num_classes, # Not directly used by MDCNet output layer here\n",
    "                              block_channels=mdc_block_channels,\n",
    "                              kernel_sizes=mdc_kernel_sizes,\n",
    "                              num_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                              dropout_rate=dropout_rate)\n",
    "        \n",
    "        # Get the output feature dimension from MDCNet\n",
    "        mdc_output_channels = self.mdc_net.output_channels\n",
    "\n",
    "        # Fully connected layers (similar to original experiment_10)\n",
    "        self.fc1 = nn.Linear(mdc_output_channels, fc_size)\n",
    "        self.relu_fc = nn.ReLU() # Added ReLU after FC1\n",
    "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "        \n",
    "        # Pass through MDCNet feature extractor\n",
    "        features = self.mdc_net(x) # Output: B x mdc_output_channels\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(features)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Modified ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features (115)\n",
    "time_steps = train_X.shape[1]  # Number of time steps (10)\n",
    "output_size = 1  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=86, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# --- MDCNet Hyperparameters ---\n",
    "# Using smaller channels than paper's example for potentially faster training/less memory\n",
    "mdc_block_channels = [16, 16, 16] # Example channel sizes for each block\n",
    "# Using kernel sizes mentioned in paper, and n=2 as found via cross-validation in paper [cite: 242, 243]\n",
    "mdc_kernel_sizes = [3, 5, 7]\n",
    "mdc_kernels_per_scale = 2\n",
    "dropout_rate = 0.2 # Adjusted dropout\n",
    "fc_size = 16 # Adjusted FC size\n",
    "\n",
    "# Create model instance\n",
    "model = ModifiedConvModel(input_size=input_size,\n",
    "                          time_steps=time_steps,\n",
    "                          num_classes=output_size,\n",
    "                          mdc_block_channels=mdc_block_channels,\n",
    "                          mdc_kernel_sizes=mdc_kernel_sizes,\n",
    "                          mdc_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                          dropout_rate=dropout_rate,\n",
    "                          fc_size=fc_size)\n",
    "\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "===========================================================================================================================================================\n",
       "ModifiedConvModel                                       [2048, 13, 86]            [2048, 1]                 --                        --\n",
       "â”œâ”€MDCNet: 1-1                                           [2048, 13, 86]            [2048, 16]                --                        --\n",
       "â”‚    â””â”€ModuleList: 2-1                                  --                        --                        --                        --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-1                             [2048, 86, 13]            [2048, 16, 6]             11,940                    53,256,192\n",
       "â”‚    â”‚    â””â”€Sequential: 3-2                             [2048, 16, 6]             [2048, 16, 3]             3,392                     2,621,440\n",
       "â”‚    â”‚    â””â”€Sequential: 3-3                             [2048, 16, 3]             [2048, 16, 1]             3,392                     1,441,792\n",
       "â”‚    â””â”€AdaptiveAvgPool1d: 2-2                           [2048, 16, 1]             [2048, 16, 1]             --                        --\n",
       "â”œâ”€Linear: 1-2                                           [2048, 16]                [2048, 16]                272                       557,056\n",
       "â”œâ”€ReLU: 1-3                                             [2048, 16]                [2048, 16]                --                        --\n",
       "â”œâ”€Linear: 1-4                                           [2048, 16]                [2048, 1]                 17                        34,816\n",
       "â”œâ”€Sigmoid: 1-5                                          [2048, 1]                 [2048, 1]                 --                        --\n",
       "===========================================================================================================================================================\n",
       "Total params: 19,013\n",
       "Trainable params: 19,013\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 57.91\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 9.16\n",
       "Forward/backward pass size (MB): 35.32\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 44.49\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2048 # Or a smaller representative batch size\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], depth=3) # Increased depth to see inside MDCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([0.]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13, 86]), tensor([1.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8ba45423514d7e80ce013861a10a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09e63eaec9c4cd69dbe807cabcd41e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.4043, Val Loss: 0.2884, Val AUC: 0.9341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546a263c467b46d69d784588c8b16f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e108ef83c5442ad86013e82ee9c5c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.2907, Val Loss: 0.2862, Val AUC: 0.9364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fd95ea78e44fc89d2df2a1aa67d748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e6d2f3e005497f9d276e42a29d2396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.2828, Val Loss: 0.3059, Val AUC: 0.9371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25af87dd5a240bfadb86320c4883f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be94c0f6532f44858fbe28503fabaaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.2748, Val Loss: 0.2797, Val AUC: 0.9445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccb5cc436b846278be3a332e0afd103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b5b365eb244b78a73a65bba96cc880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.2671, Val Loss: 0.2632, Val AUC: 0.9464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753f7f0d18914e7e81ae5017b47a54dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b7c38501164b40bd48136d8467d432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2640, Val Loss: 0.2584, Val AUC: 0.9482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dcea82e7714d9c87886186ae7cba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9114848aa32e4c86980543ebedc1a10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2603, Val Loss: 0.2557, Val AUC: 0.9490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbdb4206b5c4409810cf2dbedb356d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295697f5d7024434b17d02a2bf81ba73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2573, Val Loss: 0.2526, Val AUC: 0.9489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94020feb47424f1baad27e35df7d53ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0da16e48b8747a1b3d69c103612646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.2568, Val Loss: 0.2845, Val AUC: 0.9481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494c6d42ffbe4e78afc6f079ad8a8891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9276f836ec649f8bc59d97e43124551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.2546, Val Loss: 0.2497, Val AUC: 0.9499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0beaeda0e50416988f5219a04c323ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dadb26e68f34f2dbfcfba4c7b16df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.2531, Val Loss: 0.2557, Val AUC: 0.9499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c106e3ef7a0d43e2b8a5ba96384ee926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62798cd270fe40f8ba07b5d56947a087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train Loss: 0.2525, Val Loss: 0.2490, Val AUC: 0.9506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c89303c1c44eccbc320a2dc4161ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2144f0375e8d41fc8a3dcb6887d04654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train Loss: 0.2525, Val Loss: 0.4136, Val AUC: 0.9274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b093bfd54ec414c93aa257de0765528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94033d4339ce4bc1a60abd9509a4dfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train Loss: 0.2515, Val Loss: 0.2487, Val AUC: 0.9507\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97893cfef0f4404b55246bea6831516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871bd764e4b343f2bd62f493f6138930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.2499, Val Loss: 0.2481, Val AUC: 0.9513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845049460bff4199a7dc74ea43726443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded57fe0ed5a47a39d3feda27720b7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train Loss: 0.2487, Val Loss: 0.2465, Val AUC: 0.9512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981e4db1a8b94be8bdf51b6125e37de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf663936d82448b6bf0261f3b2e4e784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train Loss: 0.2483, Val Loss: 0.2468, Val AUC: 0.9511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737c98ba9a794ab48c250c89d473c287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9885ec8b91455caa3e792f0ce5b741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train Loss: 0.2478, Val Loss: 0.2734, Val AUC: 0.9496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a38271d9a2b4361b979bdf72b900d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c9a98646ad451c8a6dbee53ad04116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Train Loss: 0.2471, Val Loss: 0.2465, Val AUC: 0.9509\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ad0b7764eb42b48759d3c6e4a1f2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20 [Train]:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6eb86d0995c4caeae8bc4476ef7aca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20 [Valid]:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train Loss: 0.2467, Val Loss: 0.3752, Val AUC: 0.9139\n",
      "Training completed in 2m 41s\n",
      "Best val loss: 0.2465, Best val AUC: 0.9509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20 # Adjust as needed\n",
    "patience = 3  # Early stopping patience\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_val_auc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Use state_dict()\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# For tracking metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Training on {device}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for inputs, labels in train_pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_val_loss = running_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    all_preds = [p[0] for p in all_preds]\n",
    "    all_labels = [l[0] for l in all_labels]\n",
    "    # Handle case where validation set might only have one class temporarily during testing/debugging\n",
    "    if len(np.unique(all_labels)) > 1:\n",
    "        epoch_val_auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        epoch_val_auc = 0.0 # Or handle as appropriate, e.g., skip AUC calculation\n",
    "    val_aucs.append(epoch_val_auc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "          f\"Val AUC: {epoch_val_auc:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_val_auc = epoch_val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "# Training complete\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "print(f\"Best val loss: {best_val_loss:.4f}, Best val AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/deep_learning\\experiment_12.pth\n",
      "Checkpoint saved to ../../models/deep_learning\\experiment_12.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model weights\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "save_dir = '../../models/deep_learning'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model state dictionary\n",
    "model_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save additional information for later reference\n",
    "checkpoint_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Checkpoint saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation predictions obtained.\n",
      "Target Recall: >= 0.9800 for Class 0\n",
      "Threshold found by Binary Search: 0.7249573\n",
      "Achieved Recall at Threshold: 0.9800\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.8529    0.9800    0.9121     23806\n",
      "     Class 1     0.9002    0.5164    0.6563      8318\n",
      "\n",
      "    accuracy                         0.8599     32124\n",
      "   macro avg     0.8766    0.7482    0.7842     32124\n",
      "weighted avg     0.8652    0.8599    0.8458     32124\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.724957287311554"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize a list to store predictions\n",
    "val_predictions = []\n",
    "\n",
    "# Disable gradient computation for inference\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        val_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Flatten the predictions\n",
    "val_predictions = [p[0] for p in val_predictions]\n",
    "print(\"Validation predictions obtained.\")\n",
    "\n",
    "from utils.eval_helpers import evaluate_model_for_recall\n",
    "evaluate_model_for_recall(target_class=0, desired_recall=0.98, y_true=np.array(all_labels).astype('int'), y_pred_proba=np.array(val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
