{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_num = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "with h5py.File('../../data/3d_array/train_data_3d_h5.h5', 'r') as f:\n",
    "    train_X = f['train_data_3d'][:]\n",
    "with h5py.File('../../data/3d_array/val_data_3d_h5.h5', 'r') as f:\n",
    "    val_X = f['val_data_3d'][:]\n",
    "# with h5py.File('../../data/3d_array/test_data_3d_h5.h5', 'r') as f:\n",
    "#     test_X = f['test_data_3d'][:]\n",
    "\n",
    "train_y = pd.read_parquet('../../data/3d_array/train_targets.parquet')\n",
    "val_y = pd.read_parquet('../../data/3d_array/val_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2017-03-31    270223\n",
       "2017-04-30    270223\n",
       "2017-05-31    270223\n",
       "2017-06-30    270223\n",
       "2017-07-31    270223\n",
       "2017-08-31    270223\n",
       "2017-09-30    270223\n",
       "2017-10-31    270223\n",
       "2017-11-30    270223\n",
       "2017-12-31    270223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_31284\\1552306949.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train_y = train_y[train_y['end_of_month'].isin(['2017-12-31'])]\n",
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_31284\\1552306949.py:2: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  val_y = val_y[val_y['end_of_month'].isin(['2017-12-31'])]\n"
     ]
    }
   ],
   "source": [
    "train_y = train_y[train_y['end_of_month'].isin(['2017-12-31'])]\n",
    "val_y = val_y[val_y['end_of_month'].isin(['2017-12-31'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702189</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702199</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702209</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702219</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702229</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270223 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_ID end_of_month  \\\n",
       "9        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2017-12-31   \n",
       "19       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2017-12-31   \n",
       "29       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...   2017-12-31   \n",
       "39       000084e5023181993c2e1b665ac88dbb1ce9ef621ec537...   2017-12-31   \n",
       "49       000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...   2017-12-31   \n",
       "...                                                    ...          ...   \n",
       "2702189  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...   2017-12-31   \n",
       "2702199  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...   2017-12-31   \n",
       "2702209  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2017-12-31   \n",
       "2702219  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...   2017-12-31   \n",
       "2702229  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...   2017-12-31   \n",
       "\n",
       "         target  \n",
       "9             0  \n",
       "19            0  \n",
       "29            0  \n",
       "39            0  \n",
       "49            0  \n",
       "...         ...  \n",
       "2702189       0  \n",
       "2702199       0  \n",
       "2702209       0  \n",
       "2702219       0  \n",
       "2702229       1  \n",
       "\n",
       "[270223 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sort_values(by=['customer_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270223, 10, 115), (270223, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115811, 10, 115), (115811, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3):\n",
    "        super(MDC, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.num_scales = len(kernel_sizes)\n",
    "        self.num_kernels_per_scale = num_kernels_per_scale\n",
    "        self.total_kernels = self.num_scales * self.num_kernels_per_scale\n",
    "\n",
    "        # Attention mechanism to generate weights for kernels [cite: 142, 143, 145]\n",
    "        self.attention_pool = nn.AdaptiveAvgPool1d(1) # Pool across time dimension\n",
    "        # Conv1d to generate temporal attention map\n",
    "        self.attention_conv = nn.Conv1d(in_channels, self.total_kernels, kernel_size=1, bias=False)\n",
    "        self.attention_gap = nn.AdaptiveAvgPool1d(1) # Pool attention map to get weights\n",
    "        self.attention_activation = nn.Sigmoid()\n",
    "\n",
    "        # Store the kernels for each scale and each instance per scale\n",
    "        self.weights = nn.Parameter(torch.Tensor(self.total_kernels, out_channels, in_channels, 1)) # Use kernel_size=1 here, will expand later\n",
    "        nn.init.kaiming_uniform_(self.weights, a=np.sqrt(5)) # Initialize weights\n",
    "\n",
    "        # Store kernel sizes correctly\n",
    "        self.k_sizes = []\n",
    "        for k in kernel_sizes:\n",
    "            for _ in range(num_kernels_per_scale):\n",
    "                self.k_sizes.append(k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, T = x.size()\n",
    "\n",
    "        # Calculate attention weights [cite: 142, 145]\n",
    "        pooled_x = self.attention_pool(x) # B x C_in x 1\n",
    "        # The paper's diagram (Fig 3) suggests GAP -> Conv -> GAP -> Sigmoid for attention\n",
    "        # Let's follow the diagram logic more closely:\n",
    "        # GAP on input: B x C_in x T -> B x C_in x 1\n",
    "        att_gap1 = self.attention_pool(x)\n",
    "        # Conv1d on pooled input: B x C_in x 1 -> B x total_kernels x 1 (This seems different from Fig 3's BxmxnxT output)\n",
    "        # Let's reinterpret Fig 3: GAP(x) [B,Cin,T]->[B,Cin,1], then Conv [B,Cin,1]->[B,mxn,1] (This doesn't match BxmxnxT)\n",
    "        # Let's try the alternative interpretation from the text (Section 3.2.1, Eq 2 implies GAP -> Conv -> GAP)\n",
    "        # GAP(x) -> B x Cin x 1\n",
    "        # wa * GAP(x) -> B x mxn x 1 (This still feels off from Fig 3 which applies conv before second GAP)\n",
    "\n",
    "        # Let's follow Fig 3 literally (ignoring the first GAP shown before Conv in the Attention block):\n",
    "        # Conv on input x: B x Cin x T -> B x mxn x T [cite: 143]\n",
    "        attention_map = self.attention_conv(x) # B x total_kernels x T\n",
    "        # GAP on attention_map: B x mxn x T -> B x mxn x 1 [cite: 145]\n",
    "        attention_vector = self.attention_gap(attention_map)\n",
    "        # Sigmoid activation: B x mxn x 1 [cite: 145]\n",
    "        attention_weights = self.attention_activation(attention_vector) # Shape: (batch_size, total_kernels, 1)\n",
    "\n",
    "        # Fuse kernels based on attention weights [cite: 140]\n",
    "        # Reshape weights for broadcasting: (batch_size, total_kernels, 1) -> (batch_size, total_kernels, 1, 1, 1)\n",
    "        # Reshape kernels: (total_kernels, out_c, in_c, 1)\n",
    "        # We need to perform convolution dynamically. PyTorch doesn't easily support dynamic kernel *shapes*.\n",
    "        # A common approach is to have fixed-size kernels and combine their *outputs*, or combine *weights* for a fixed kernel size.\n",
    "        # The paper seems to imply combining weights *before* convolution (Eq 1). This requires all kernels w_i^j to have the same size k.\n",
    "        # However, the goal is *multi-scale*.\n",
    "\n",
    "        # Let's implement the multi-scale aspect by having separate convolutions and combining outputs weighted by attention.\n",
    "        # This deviates slightly from Eq 1 but achieves the multi-scale goal.\n",
    "\n",
    "        outputs = []\n",
    "        current_kernel_idx = 0\n",
    "        for k_size in self.kernel_sizes:\n",
    "            padding = k_size // 2\n",
    "            for i in range(self.num_kernels_per_scale):\n",
    "                # Get the weights for this specific kernel instance (across all batches)\n",
    "                # attention_weights shape: B x total_kernels x 1\n",
    "                # kernel_weights shape: B x 1 x out_c x in_c x k_size\n",
    "                kernel_idx = current_kernel_idx + i\n",
    "                kernel_weight = self.weights[kernel_idx] # out_c x in_c x 1\n",
    "                # Manually create the kernel for Conv1d for this size\n",
    "                dynamic_kernel = kernel_weight.repeat(1, 1, k_size) # out_c x in_c x k_size\n",
    "                \n",
    "                # Perform convolution with this specific kernel\n",
    "                output_i = F.conv1d(x, dynamic_kernel, padding=padding) # B x out_c x T\n",
    "                \n",
    "                # Apply attention weight for this kernel\n",
    "                # attention_weights[:, kernel_idx, :] shape: B x 1 x 1\n",
    "                weighted_output = output_i * attention_weights[:, kernel_idx, :].unsqueeze(-1) # B x out_c x T\n",
    "                outputs.append(weighted_output)\n",
    "                \n",
    "            current_kernel_idx += self.num_kernels_per_scale\n",
    "\n",
    "        # Sum the weighted outputs from all kernels\n",
    "        # This is an alternative interpretation to fusing weights first.\n",
    "        out = torch.sum(torch.stack(outputs), dim=0) # B x out_c x T\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], num_kernels_per_scale=3, stride=1):\n",
    "        super(MDCResBlock, self).__init__()\n",
    "        \n",
    "        # Use Conv1d for the residual connection if dimensions change\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "\n",
    "        self.mdc1 = MDC(in_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        # Paper uses PReLU, let's use ReLU for simplicity or add PReLU if needed. Using PReLU as per paper.\n",
    "        self.prelu1 = nn.PReLU(out_channels)\n",
    "\n",
    "        self.mdc2 = MDC(out_channels, out_channels, kernel_sizes, num_kernels_per_scale)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.prelu2 = nn.PReLU(out_channels) # Activation after final BN before adding shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        out = self.mdc1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "\n",
    "        out = self.mdc2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.prelu2(out) # Final activation after adding shortcut\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDCNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, block_channels=[128, 128, 128], kernel_sizes=[3,5,7], num_kernels_per_scale=2, dropout_rate=0.3, reduction=16):\n",
    "        super(MDCNet, self).__init__()\n",
    "        \n",
    "        self.blocks = nn.ModuleList()\n",
    "        current_channels = input_channels\n",
    "        \n",
    "        # Configuration from paper/Figure 2: 3 Blocks [cite: 130]\n",
    "        # Each block: MDC ResBlock -> MaxPool -> SE -> Dropout\n",
    "        for i, channels in enumerate(block_channels):\n",
    "            # Stride only applied if pooling happens, MaxPooling handles stride=2\n",
    "            res_block = MDCResBlock(current_channels, channels, kernel_sizes, num_kernels_per_scale, stride=1)\n",
    "            max_pool = nn.MaxPool1d(kernel_size=2, stride=2) # Halve the length [cite: 132]\n",
    "            se_block = SEBlock(channels, reduction) # SE block [cite: 133]\n",
    "            dropout = nn.Dropout(dropout_rate) # Dropout [cite: 134]\n",
    "            \n",
    "            block = nn.Sequential(\n",
    "                res_block,\n",
    "                max_pool,\n",
    "                se_block,\n",
    "                dropout\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "            current_channels = channels # Update channels for next block\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1) # Global Average Pooling [cite: 130]\n",
    "        # The original ConvModel in experiment_10 has FC layers after pooling.\n",
    "        # MDCNet in the paper feeds features to DPNet or directly to Softmax.\n",
    "        # To make it a component usable in the existing structure, we output features before FC layers.\n",
    "        self.output_channels = current_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input x shape: B x T x C_in (e.g., B x 10 x 115)\n",
    "        # Conv1D expects B x C_in x T\n",
    "        x = x.permute(0, 2, 1) # B x C_in x T (e.g., B x 115 x 10)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.gap(x) # B x C_out x 1\n",
    "        x = x.view(x.size(0), -1) # Flatten: B x C_out\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMMDCModel(nn.Module):\n",
    "    def __init__(self, input_size, time_steps, num_classes=1, \n",
    "                 mdc_block_channels=[64, 64, 64], mdc_kernel_sizes=[3,5,7], \n",
    "                 mdc_kernels_per_scale=2, dropout_rate=0.2, fc_size=32,\n",
    "                 lstm_hidden_size=64, lstm_num_layers=2, lstm_dropout=0.2):\n",
    "        super(LSTMMDCModel, self).__init__()\n",
    "        \n",
    "        # MDCNet branch\n",
    "        self.mdc_net = MDCNet(input_channels=input_size,\n",
    "                              num_classes=num_classes,\n",
    "                              block_channels=mdc_block_channels,\n",
    "                              kernel_sizes=mdc_kernel_sizes,\n",
    "                              num_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                              dropout_rate=dropout_rate)\n",
    "        \n",
    "        # LSTM branch\n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                           hidden_size=lstm_hidden_size,\n",
    "                           num_layers=lstm_num_layers, \n",
    "                           batch_first=True,\n",
    "                           dropout=lstm_dropout if lstm_num_layers > 1 else 0,\n",
    "                           bidirectional=True)\n",
    "        \n",
    "        # Get the output feature dimensions\n",
    "        mdc_output_channels = self.mdc_net.output_channels\n",
    "        lstm_output_channels = lstm_hidden_size * 2  # Bidirectional LSTM\n",
    "        combined_features = mdc_output_channels + lstm_output_channels\n",
    "        \n",
    "        # Fully connected layers for classification\n",
    "        self.fc1 = nn.Linear(combined_features, fc_size)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(fc_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "        \n",
    "        # MDC branch processing\n",
    "        mdc_features = self.mdc_net(x)  # Output: B x mdc_output_channels\n",
    "        \n",
    "        # LSTM branch processing\n",
    "        # x is already in format B x T x F, which is what LSTM expects\n",
    "        lstm_out, _ = self.lstm(x)  # Output: B x T x (hidden_size*2)\n",
    "        \n",
    "        # Take the final time step output from LSTM\n",
    "        lstm_features = lstm_out[:, -1, :]  # B x (hidden_size*2)\n",
    "        \n",
    "        # Combine features from both branches\n",
    "        combined = torch.cat([mdc_features, lstm_features], dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(combined)\n",
    "        x = self.relu_fc(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Output probability\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Modified ConvModel\n",
    "input_size = train_X.shape[2]  # Number of features (115)\n",
    "time_steps = train_X.shape[1]  # Number of time steps (10)\n",
    "output_size = 1  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with input_size=115, output_size=1\n"
     ]
    }
   ],
   "source": [
    "# --- MDCNet Hyperparameters ---\n",
    "# Using smaller channels than paper's example for potentially faster training/less memory\n",
    "mdc_block_channels = [16, 32, 64] # Example channel sizes for each block\n",
    "# Using kernel sizes mentioned in paper, and n=2 as found via cross-validation in paper [cite: 242, 243]\n",
    "mdc_kernel_sizes = [3, 5, 7]\n",
    "mdc_kernels_per_scale = 2\n",
    "dropout_rate = 0.2 # Adjusted dropout\n",
    "fc_size = 16 # Adjusted FC size\n",
    "\n",
    "# LSTM parameters\n",
    "lstm_hidden_size = 32\n",
    "lstm_num_layers = 2\n",
    "lstm_dropout = 0.2\n",
    "\n",
    "# Create model instance\n",
    "model = LSTMMDCModel(input_size=input_size,\n",
    "                     time_steps=time_steps,\n",
    "                     num_classes=output_size,\n",
    "                     mdc_block_channels=mdc_block_channels,\n",
    "                     mdc_kernel_sizes=mdc_kernel_sizes,\n",
    "                     mdc_kernels_per_scale=mdc_kernels_per_scale,\n",
    "                     dropout_rate=dropout_rate,\n",
    "                     fc_size=fc_size,\n",
    "                     lstm_hidden_size=lstm_hidden_size,\n",
    "                     lstm_num_layers=lstm_num_layers,\n",
    "                     lstm_dropout=lstm_dropout)\n",
    "\n",
    "print(f\"Model initialized with input_size={input_size}, output_size={output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "===========================================================================================================================================================\n",
       "LSTMMDCModel                                            [10000, 10, 115]          [10000, 1]                --                        --\n",
       "├─MDCNet: 1-1                                           [10000, 10, 115]          [10000, 64]               --                        --\n",
       "│    └─ModuleList: 2-1                                  --                        --                        --                        --\n",
       "│    │    └─Sequential: 3-1                             [10000, 115, 10]          [10000, 16, 5]            15,362                    264,200,000\n",
       "│    │    └─Sequential: 3-2                             [10000, 16, 5]            [10000, 32, 2]            10,400                    43,840,000\n",
       "│    │    └─Sequential: 3-3                             [10000, 32, 2]            [10000, 64, 1]            40,512                    62,720,000\n",
       "│    └─AdaptiveAvgPool1d: 2-2                           [10000, 64, 1]            [10000, 64, 1]            --                        --\n",
       "├─LSTM: 1-2                                             [10000, 10, 115]          [10000, 10, 64]           63,232                    6,323,200,000\n",
       "├─Linear: 1-3                                           [10000, 128]              [10000, 16]               2,064                     20,640,000\n",
       "├─ReLU: 1-4                                             [10000, 16]               [10000, 16]               --                        --\n",
       "├─Dropout: 1-5                                          [10000, 16]               [10000, 16]               --                        --\n",
       "├─Linear: 1-6                                           [10000, 16]               [10000, 1]                17                        170,000\n",
       "├─Sigmoid: 1-7                                          [10000, 1]                [10000, 1]                --                        --\n",
       "===========================================================================================================================================================\n",
       "Total params: 131,587\n",
       "Trainable params: 131,587\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.71\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 46.00\n",
       "Forward/backward pass size (MB): 293.44\n",
       "Params size (MB): 0.29\n",
       "Estimated Total Size (MB): 339.73\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10000 # Or a smaller representative batch size\n",
    "from torchinfo import summary\n",
    "# try:\n",
    "summary(model, input_size=(batch_size, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], depth=3) # Increased depth to see inside MDCNet\n",
    "# except Exception as e:\n",
    "#     print(f\"Error generating summary, possibly due to dynamic ops or large batch size: {e}\")\n",
    "#     print(\"Trying with smaller batch size for summary...\")\n",
    "#     try:\n",
    "#          summary(model, input_size=(64, train_X.shape[1], train_X.shape[2]), device='cpu',\n",
    "#             col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"], depth=3)\n",
    "#     except Exception as e2:\n",
    "#         print(f\"Summary failed even with smaller batch size: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(train_X, train_y['target'].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TimeSeriesDataset(val_X, val_y['target'].values)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 115]), tensor([0.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)[0].shape, train_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 115]), tensor([0.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.__getitem__(0)[0].shape, val_dataset.__getitem__(0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66ddb6e1345426999e66960d64cba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f14753aa684022b1e0c200227b204e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.6656, Val Loss: 0.4931, Val AUC: 0.9262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb68564fff94f5080b342fda249b755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22701c4f62014224ac457a512d836cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train Loss: 0.3615, Val Loss: 0.2980, Val AUC: 0.9321\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893af1996f134b3fab85c3b869c3d2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9328118cf8e44dae9e9fe9b55c3a6da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train Loss: 0.2883, Val Loss: 0.2837, Val AUC: 0.9340\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9998d20dbf56497f859f6df40145b7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad43526ac50e49db8fb89d8953dfa7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train Loss: 0.2792, Val Loss: 0.2778, Val AUC: 0.9367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02d0d384a5c4f5f9879f5fdd4322302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7164fcff66f74b44b3d7ec9d99b43d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train Loss: 0.2733, Val Loss: 0.2679, Val AUC: 0.9382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663c2409387849838088fe1c68fd0f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c392eee51fa541c184c0fe82e69a6617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train Loss: 0.2702, Val Loss: 0.2704, Val AUC: 0.9392\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d2fed98874495a8962eb5f9f3398ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed38887c3c1246e5a9ae5a872f358103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train Loss: 0.2678, Val Loss: 0.2635, Val AUC: 0.9391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df503051d0354095acbce30534dc8d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a87b4c0b26a4ea6a6f8a1657ef6ee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train Loss: 0.2647, Val Loss: 0.2607, Val AUC: 0.9403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b688ed6b00b84fa6868cacc4dda0e0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d37d0d61ad4c0d8cef6b199e2d3be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train Loss: 0.2636, Val Loss: 0.2615, Val AUC: 0.9408\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c94402c997d4f95b8ab9f095b55b69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a748923c254255b73b2dae0619d69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train Loss: 0.2619, Val Loss: 0.2623, Val AUC: 0.9410\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f48093ad5b48889003e0636b0ea493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Train]:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0272e2d1bffb4bc190a0dd4c08508a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 [Valid]:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.2607, Val Loss: 0.2619, Val AUC: 0.9395\n",
      "Early stopping triggered after 11 epochs\n",
      "Training completed in 1m 42s\n",
      "Best val loss: 0.2607, Best val AUC: 0.9403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 20 # Adjust as needed\n",
    "patience = 3  # Early stopping patience\n",
    "\n",
    "# Initialize variables for early stopping\n",
    "best_val_loss = float('inf')\n",
    "best_val_auc = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) # Use state_dict()\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# For tracking metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_aucs = []\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Training on {device}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
    "    for inputs, labels in train_pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        train_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            val_pbar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_val_loss = running_loss / len(val_dataset)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    all_preds = [p[0] for p in all_preds]\n",
    "    all_labels = [l[0] for l in all_labels]\n",
    "    # Handle case where validation set might only have one class temporarily during testing/debugging\n",
    "    if len(np.unique(all_labels)) > 1:\n",
    "        epoch_val_auc = roc_auc_score(all_labels, all_preds)\n",
    "    else:\n",
    "        epoch_val_auc = 0.0 # Or handle as appropriate, e.g., skip AUC calculation\n",
    "    val_aucs.append(epoch_val_auc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
    "          f\"Val AUC: {epoch_val_auc:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        best_val_auc = epoch_val_auc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "# Training complete\n",
    "time_elapsed = time.time() - start_time\n",
    "print(f\"Training completed in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "print(f\"Best val loss: {best_val_loss:.4f}, Best val AUC: {best_val_auc:.4f}\")\n",
    "\n",
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/deep_learning\\experiment_14.pth\n",
      "Checkpoint saved to ../../models/deep_learning\\experiment_14.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model weights\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "save_dir = '../../models/deep_learning'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save model state dictionary\n",
    "model_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save additional information for later reference\n",
    "checkpoint_path = os.path.join(save_dir, f'experiment_{experiment_num}.pth')\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Checkpoint saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
