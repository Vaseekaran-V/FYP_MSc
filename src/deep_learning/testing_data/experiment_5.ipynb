{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('../../../data/3d_array/test_data_3d_h5.h5', 'r') as f:\n",
    "    test_X = f['test_data_3d'][:]\n",
    "test_y = pd.read_parquet('../../../data/3d_array/test_targets.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "end_of_month\n",
       "2017-06-30    405607\n",
       "2017-07-31    405607\n",
       "2017-08-31    405607\n",
       "2017-09-30    405607\n",
       "2017-10-31    405607\n",
       "2017-11-30    405607\n",
       "2017-12-31    405607\n",
       "2018-01-31    405607\n",
       "2018-02-28    405607\n",
       "2018-03-31    405607\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y['end_of_month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_23132\\204564841.py:1: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]\n"
     ]
    }
   ],
   "source": [
    "test_y = test_y[test_y['end_of_month'].isin(['2018-03-31'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>end_of_month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056029</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056039</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056049</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056059</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056069</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405607 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_ID end_of_month  \\\n",
       "9        0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...   2018-03-31   \n",
       "19       00000fd6641609c6ece5454664794f0340ad84dddce9a2...   2018-03-31   \n",
       "29       00001b22f846c82c51f6e3958ccd81970162bae8b007e8...   2018-03-31   \n",
       "39       000041bdba6ecadd89a52d11886e8eaaec9325906c9723...   2018-03-31   \n",
       "49       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...   2018-03-31   \n",
       "...                                                    ...          ...   \n",
       "4056029  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...   2018-03-31   \n",
       "4056039  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...   2018-03-31   \n",
       "4056049  ffff9984b999fccb2b6127635ed0736dda94e544e67e02...   2018-03-31   \n",
       "4056059  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...   2018-03-31   \n",
       "4056069  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...   2018-03-31   \n",
       "\n",
       "         target  \n",
       "9             0  \n",
       "19            0  \n",
       "29            0  \n",
       "39            0  \n",
       "49            0  \n",
       "...         ...  \n",
       "4056029       0  \n",
       "4056039       0  \n",
       "4056049       0  \n",
       "4056059       1  \n",
       "4056069       0  \n",
       "\n",
       "[405607 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class SmallRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, fc_size, output_size=1, conv_out_channels=32, kernel_size=3):\n",
    "        super(SmallRNNModel, self).__init__()\n",
    "        # Conv1D layer\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=conv_out_channels, kernel_size=kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        # LSTM layer\n",
    "        self.gru = nn.GRU(conv_out_channels, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, fc_size)\n",
    "        self.output = nn.Linear(fc_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: batch_size x time_steps x features\n",
    "        # Conv1D expects: batch_size x features(channels) x time_steps\n",
    "        x = x.permute(0, 2, 1)  # Rearrange for Conv1D\n",
    "        # Apply Conv1D\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        # Rearrange back for GRU: batch_size x time_steps x features\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        # LSTM layer\n",
    "        gru_out, _ = self.gru(x)\n",
    "        # Take the output of the last time step\n",
    "        gru_last_out = gru_out[:, -1, :]\n",
    "        # Fully connected layer\n",
    "        fc_out = self.fc(gru_last_out)\n",
    "        # Final output layer\n",
    "        output = self.output(fc_out)\n",
    "        # Apply sigmoid for binary classification\n",
    "        return self.sigmoid(output)\n",
    "    \n",
    "# Example usage\n",
    "input_size = test_X.shape[2]  # Number of features\n",
    "hidden_size = 64  # Hidden state size for LSTM\n",
    "fc_size = 32  # Size of the fully connected layer\n",
    "conv_out_channels = 32  # Number of output channels for Conv1D\n",
    "kernel_size = 3  # Kernel size for Conv1D\n",
    "\n",
    "model = SmallRNNModel(\n",
    "    input_size=input_size, \n",
    "    hidden_size=hidden_size, \n",
    "    fc_size=fc_size,\n",
    "    conv_out_channels=conv_out_channels,\n",
    "    kernel_size=kernel_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters loaded successfully from ../../../models/deep_learning/experiment_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vaseekaranv\\AppData\\Local\\Temp\\ipykernel_23132\\42421736.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Define the model path\n",
    "model_path = '../../../models/deep_learning/experiment_5.pth'\n",
    "\n",
    "# Load the model parameters\n",
    "try:\n",
    "    # Load the saved dictionary\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    # Extract model parameters from the 'model_state_dict' key\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model parameters loaded successfully from {model_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "    print(\"Please specify the correct path to the model parameters\")\n",
    "except KeyError:\n",
    "    print(f\"'model_state_dict' key not found in the checkpoint file\")\n",
    "    print(\"The file may have been saved with a different structure\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model parameters: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: numpy array of shape (num_ids, time_steps, features)\n",
    "            targets: numpy array of shape (num_ids,)\n",
    "        \"\"\"\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        self.targets = torch.FloatTensor(targets).unsqueeze(1)  # Add dimension for output\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "test_dataset = TimeSeriesDataset(test_X, test_y['target'].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9379    0.9292    0.9336    307381\n",
      "           1     0.7848    0.8075    0.7960     98226\n",
      "\n",
      "    accuracy                         0.8998    405607\n",
      "   macro avg     0.8614    0.8684    0.8648    405607\n",
      "weighted avg     0.9008    0.8998    0.9002    405607\n",
      "\n",
      "Accuracy: 0.8998\n",
      "ROC-AUC Score: 0.9563\n",
      "\n",
      "Confusion Matrix:\n",
      "[[285633  21748]\n",
      " [ 18910  79316]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Check if CUDA is available and move model to the appropriate device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Lists to store predictions and true values\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Perform inference without gradient calculation\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move inputs and labels to the appropriate device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Store predictions and labels\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate all batches\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Convert predictions to binary (0 or 1) using threshold of 0.5\n",
    "pred_classes = (all_preds > 0.5).astype(int)\n",
    "true_classes = all_labels.astype(int)\n",
    "\n",
    "# Generate classification report\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, pred_classes, digits = 4))\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(true_classes, pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print ROC-AUC score\n",
    "auc = roc_auc_score(true_classes, all_preds)\n",
    "print(f\"ROC-AUC Score: {auc:.4f}\")\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_classes, pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
